diff --git a/api/video/video_codec_type.h b/api/video/video_codec_type.h
index 12dcfac1b9..fdbc5187d8 100644
--- a/api/video/video_codec_type.h
+++ b/api/video/video_codec_type.h
@@ -22,6 +22,7 @@ enum VideoCodecType {
   kVideoCodecVP9,
   kVideoCodecAV1,
   kVideoCodecH264,
+  kVideoCodecH265,
   kVideoCodecMultiplex,
 };
 
diff --git a/api/video_codecs/video_codec.cc b/api/video_codecs/video_codec.cc
index d03082b91e..b189795ec5 100644
--- a/api/video_codecs/video_codec.cc
+++ b/api/video_codecs/video_codec.cc
@@ -25,6 +25,7 @@ constexpr char kPayloadNameVp9[] = "VP9";
 // frozen.
 constexpr char kPayloadNameAv1[] = "AV1X";
 constexpr char kPayloadNameH264[] = "H264";
+constexpr char kPayloadNameH265[] = "H265";
 constexpr char kPayloadNameGeneric[] = "Generic";
 constexpr char kPayloadNameMultiplex[] = "Multiplex";
 }  // namespace
@@ -56,6 +57,15 @@ bool VideoCodecH264::operator==(const VideoCodecH264& other) const {
           numberOfTemporalLayers == other.numberOfTemporalLayers);
 }
 
+bool VideoCodecH265::operator==(const VideoCodecH265& other) const {
+  return (frameDroppingOn == other.frameDroppingOn &&
+          keyFrameInterval == other.keyFrameInterval &&
+          vpsLen == other.vpsLen && spsLen == other.spsLen &&
+          ppsLen == other.ppsLen &&
+          (spsLen == 0 || memcmp(spsData, other.spsData, spsLen) == 0) &&
+          (ppsLen == 0 || memcmp(ppsData, other.ppsData, ppsLen) == 0));
+}
+
 bool SpatialLayer::operator==(const SpatialLayer& other) const {
   return (width == other.width && height == other.height &&
           maxFramerate == other.maxFramerate &&
@@ -115,6 +125,16 @@ const VideoCodecH264& VideoCodec::H264() const {
   return codec_specific_.H264;
 }
 
+VideoCodecH265* VideoCodec::H265() {
+  RTC_DCHECK_EQ(codecType, kVideoCodecH265);
+  return &codec_specific_.H265;
+}
+
+const VideoCodecH265& VideoCodec::H265() const {
+  RTC_DCHECK_EQ(codecType, kVideoCodecH265);
+  return codec_specific_.H265;
+}
+
 const char* CodecTypeToPayloadString(VideoCodecType type) {
   switch (type) {
     case kVideoCodecVP8:
@@ -125,6 +145,8 @@ const char* CodecTypeToPayloadString(VideoCodecType type) {
       return kPayloadNameAv1;
     case kVideoCodecH264:
       return kPayloadNameH264;
+    case kVideoCodecH265:
+     return kPayloadNameH265;
     case kVideoCodecMultiplex:
       return kPayloadNameMultiplex;
     case kVideoCodecGeneric:
@@ -141,6 +163,8 @@ VideoCodecType PayloadStringToCodecType(const std::string& name) {
     return kVideoCodecAV1;
   if (absl::EqualsIgnoreCase(name, kPayloadNameH264))
     return kVideoCodecH264;
+  if (absl::EqualsIgnoreCase(name, kPayloadNameH265))
+    return kVideoCodecH265;
   if (absl::EqualsIgnoreCase(name, kPayloadNameMultiplex))
     return kVideoCodecMultiplex;
   return kVideoCodecGeneric;
diff --git a/api/video_codecs/video_codec.h b/api/video_codecs/video_codec.h
index c07fae9b8b..567f6b09ec 100644
--- a/api/video_codecs/video_codec.h
+++ b/api/video_codecs/video_codec.h
@@ -84,6 +84,21 @@ struct VideoCodecH264 {
   uint8_t numberOfTemporalLayers;
 };
 
+struct VideoCodecH265 {
+  bool operator==(const VideoCodecH265& other) const;
+  bool operator!=(const VideoCodecH265& other) const {
+    return !(*this == other);
+  }
+  bool frameDroppingOn;
+  int keyFrameInterval;
+  const uint8_t* vpsData;
+  size_t vpsLen;
+  const uint8_t* spsData;
+  size_t spsLen;
+  const uint8_t* ppsData;
+  size_t ppsLen;
+};
+
 // Translates from name of codec to codec type and vice versa.
 RTC_EXPORT const char* CodecTypeToPayloadString(VideoCodecType type);
 RTC_EXPORT VideoCodecType PayloadStringToCodecType(const std::string& name);
@@ -92,6 +107,7 @@ union VideoCodecUnion {
   VideoCodecVP8 VP8;
   VideoCodecVP9 VP9;
   VideoCodecH264 H264;
+  VideoCodecH265 H265;
 };
 
 enum class VideoCodecMode { kRealtimeVideo, kScreensharing };
@@ -159,6 +175,8 @@ class RTC_EXPORT VideoCodec {
   const VideoCodecVP9& VP9() const;
   VideoCodecH264* H264();
   const VideoCodecH264& H264() const;
+  VideoCodecH265* H265();
+  const VideoCodecH265& H265() const;
 
  private:
   // TODO(hta): Consider replacing the union with a pointer type.
diff --git a/api/video_codecs/video_decoder_software_fallback_wrapper.cc b/api/video_codecs/video_decoder_software_fallback_wrapper.cc
index 128087f207..81a56cfd79 100644
--- a/api/video_codecs/video_decoder_software_fallback_wrapper.cc
+++ b/api/video_codecs/video_decoder_software_fallback_wrapper.cc
@@ -181,6 +181,10 @@ void VideoDecoderSoftwareFallbackWrapper::UpdateFallbackDecoderHistograms() {
       RTC_HISTOGRAM_COUNTS_100000(kFallbackHistogramsUmaPrefix + "H264",
                                   hw_decoded_frames_since_last_fallback_);
       break;
+    case kVideoCodecH265:
+      RTC_HISTOGRAM_COUNTS_100000(kFallbackHistogramsUmaPrefix + "H265",
+                                  hw_decoded_frames_since_last_fallback_);
+      break;
     case kVideoCodecMultiplex:
       RTC_HISTOGRAM_COUNTS_100000(kFallbackHistogramsUmaPrefix + "Multiplex",
                                   hw_decoded_frames_since_last_fallback_);
diff --git a/api/video_codecs/video_encoder.cc b/api/video_codecs/video_encoder.cc
index 4427d6c1f1..1f320e8e95 100644
--- a/api/video_codecs/video_encoder.cc
+++ b/api/video_codecs/video_encoder.cc
@@ -60,6 +60,21 @@ VideoCodecH264 VideoEncoder::GetDefaultH264Settings() {
   return h264_settings;
 }
 
+VideoCodecH265 VideoEncoder::GetDefaultH265Settings() {
+  VideoCodecH265 h265_settings;
+  memset(&h265_settings, 0, sizeof(h265_settings));
+
+  // h265_settings.profile = kProfileBase;
+  h265_settings.frameDroppingOn = true;
+  h265_settings.keyFrameInterval = 3000;
+  h265_settings.spsData = nullptr;
+  h265_settings.spsLen = 0;
+  h265_settings.ppsData = nullptr;
+  h265_settings.ppsLen = 0;
+  
+  return h265_settings;
+}
+
 VideoEncoder::ScalingSettings::ScalingSettings() = default;
 
 VideoEncoder::ScalingSettings::ScalingSettings(KOff) : ScalingSettings() {}
diff --git a/api/video_codecs/video_encoder.h b/api/video_codecs/video_encoder.h
index 064dc8ffb5..1b3bc1bbb8 100644
--- a/api/video_codecs/video_encoder.h
+++ b/api/video_codecs/video_encoder.h
@@ -320,6 +320,7 @@ class RTC_EXPORT VideoEncoder {
   static VideoCodecVP8 GetDefaultVp8Settings();
   static VideoCodecVP9 GetDefaultVp9Settings();
   static VideoCodecH264 GetDefaultH264Settings();
+  static VideoCodecH265 GetDefaultH265Settings();
 
   virtual ~VideoEncoder() {}
 
diff --git a/api/video_codecs/video_encoder_config.cc b/api/video_codecs/video_encoder_config.cc
index 6efcbf2bdd..37ee0a6782 100644
--- a/api/video_codecs/video_encoder_config.cc
+++ b/api/video_codecs/video_encoder_config.cc
@@ -93,6 +93,8 @@ void VideoEncoderConfig::EncoderSpecificSettings::FillEncoderSpecificSettings(
     FillVideoCodecVp8(codec->VP8());
   } else if (codec->codecType == kVideoCodecVP9) {
     FillVideoCodecVp9(codec->VP9());
+  } else if (codec->codecType == kVideoCodecH265) {
+    FillVideoCodecH265(codec->H265());
   } else {
     RTC_NOTREACHED() << "Encoder specifics set/used for unknown codec type.";
   }
@@ -103,6 +105,11 @@ void VideoEncoderConfig::EncoderSpecificSettings::FillVideoCodecH264(
   RTC_NOTREACHED();
 }
 
+void VideoEncoderConfig::EncoderSpecificSettings::FillVideoCodecH265(
+    VideoCodecH265* h265_settings) const {
+  RTC_NOTREACHED();
+}
+
 void VideoEncoderConfig::EncoderSpecificSettings::FillVideoCodecVp8(
     VideoCodecVP8* vp8_settings) const {
   RTC_NOTREACHED();
@@ -122,6 +129,15 @@ void VideoEncoderConfig::H264EncoderSpecificSettings::FillVideoCodecH264(
   *h264_settings = specifics_;
 }
 
+VideoEncoderConfig::H265EncoderSpecificSettings::H265EncoderSpecificSettings(
+    const VideoCodecH265& specifics)
+    : specifics_(specifics) {}
+
+void VideoEncoderConfig::H265EncoderSpecificSettings::FillVideoCodecH265(
+    VideoCodecH265* h265_settings) const {
+  *h265_settings = specifics_;
+}
+
 VideoEncoderConfig::Vp8EncoderSpecificSettings::Vp8EncoderSpecificSettings(
     const VideoCodecVP8& specifics)
     : specifics_(specifics) {}
diff --git a/api/video_codecs/video_encoder_config.h b/api/video_codecs/video_encoder_config.h
index ef8db100a3..03b8564311 100644
--- a/api/video_codecs/video_encoder_config.h
+++ b/api/video_codecs/video_encoder_config.h
@@ -84,6 +84,7 @@ class VideoEncoderConfig {
     virtual void FillVideoCodecVp8(VideoCodecVP8* vp8_settings) const;
     virtual void FillVideoCodecVp9(VideoCodecVP9* vp9_settings) const;
     virtual void FillVideoCodecH264(VideoCodecH264* h264_settings) const;
+    virtual void FillVideoCodecH265(VideoCodecH265* h265_settings) const;
 
    private:
     ~EncoderSpecificSettings() override {}
@@ -99,6 +100,15 @@ class VideoEncoderConfig {
     VideoCodecH264 specifics_;
   };
 
+  class H265EncoderSpecificSettings : public EncoderSpecificSettings {
+   public:
+    explicit H265EncoderSpecificSettings(const VideoCodecH265& specifics);
+    void FillVideoCodecH265(VideoCodecH265* h265_settings) const override;
+  
+   private:
+    VideoCodecH265 specifics_;
+  };
+
   class Vp8EncoderSpecificSettings : public EncoderSpecificSettings {
    public:
     explicit Vp8EncoderSpecificSettings(const VideoCodecVP8& specifics);
diff --git a/call/rtp_payload_params.cc b/call/rtp_payload_params.cc
index 110db2e9fa..045f9cb42e 100644
--- a/call/rtp_payload_params.cc
+++ b/call/rtp_payload_params.cc
@@ -95,6 +95,12 @@ void PopulateRtpWithCodecSpecifics(const CodecSpecificInfo& info,
       rtp->simulcastIdx = spatial_index.value_or(0);
       return;
     }
+    case kVideoCodecH265: {
+      auto h265_header = rtp->video_type_header.emplace<RTPVideoHeaderH265>();
+      h265_header.packetization_mode =
+          info.codecSpecific.H265.packetization_mode;
+      return;
+    }
     case kVideoCodecMultiplex:
     case kVideoCodecGeneric:
       rtp->codec = kVideoCodecGeneric;
@@ -285,6 +291,7 @@ void RtpPayloadParams::SetGeneric(const CodecSpecificInfo* codec_specific_info,
                       is_keyframe, rtp_video_header);
       }
       return;
+    case VideoCodecType::kVideoCodecH265:
     case VideoCodecType::kVideoCodecMultiplex:
       return;
   }
diff --git a/common_video/BUILD.gn b/common_video/BUILD.gn
index 9ae87d242d..698f8666fb 100644
--- a/common_video/BUILD.gn
+++ b/common_video/BUILD.gn
@@ -41,6 +41,17 @@ rtc_library("common_video") {
     "video_render_frames.h",
   ]
 
+  sources += [
+    "h265/h265_common.cc",
+    "h265/h265_common.h",
+    "h265/h265_pps_parser.cc",
+    "h265/h265_pps_parser.h",
+    "h265/h265_sps_parser.cc",
+    "h265/h265_sps_parser.h",
+    "h265/h265_vps_parser.cc",
+    "h265/h265_vps_parser.h",
+  ]
+
   deps = [
     "../api:scoped_refptr",
     "../api/task_queue",
diff --git a/common_video/h265/h265_common.cc b/common_video/h265/h265_common.cc
new file mode 100644
index 0000000000..5c98ea1dfb
--- /dev/null
+++ b/common_video/h265/h265_common.cc
@@ -0,0 +1,110 @@
+/*
+ *  Copyright (c) 2018 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "common_video/h265/h265_common.h"
+
+namespace webrtc {
+namespace H265 {
+
+const uint8_t kNaluTypeMask = 0x7E;
+
+std::vector<NaluIndex> FindNaluIndices(const uint8_t* buffer,
+                                       size_t buffer_size) {
+  // This is sorta like Boyer-Moore, but with only the first optimization step:
+  // given a 3-byte sequence we're looking at, if the 3rd byte isn't 1 or 0,
+  // skip ahead to the next 3-byte sequence. 0s and 1s are relatively rare, so
+  // this will skip the majority of reads/checks.
+  std::vector<NaluIndex> sequences;
+  if (buffer_size < kNaluShortStartSequenceSize)
+    return sequences;
+
+  const size_t end = buffer_size - kNaluShortStartSequenceSize;
+  for (size_t i = 0; i < end;) {
+    if (buffer[i + 2] > 1) {
+      i += 3;
+    } else if (buffer[i + 2] == 1 && buffer[i + 1] == 0 && buffer[i] == 0) {
+      // We found a start sequence, now check if it was a 3 of 4 byte one.
+      NaluIndex index = {i, i + 3, 0};
+      if (index.start_offset > 0 && buffer[index.start_offset - 1] == 0)
+        --index.start_offset;
+
+      // Update length of previous entry.
+      auto it = sequences.rbegin();
+      if (it != sequences.rend())
+        it->payload_size = index.start_offset - it->payload_start_offset;
+
+      sequences.push_back(index);
+
+      i += 3;
+    } else {
+      ++i;
+    }
+  }
+
+  // Update length of last entry, if any.
+  auto it = sequences.rbegin();
+  if (it != sequences.rend())
+    it->payload_size = buffer_size - it->payload_start_offset;
+
+  return sequences;
+}
+
+NaluType ParseNaluType(uint8_t data) {
+  return static_cast<NaluType>((data & kNaluTypeMask) >> 1);
+}
+
+std::vector<uint8_t> ParseRbsp(const uint8_t* data, size_t length) {
+  std::vector<uint8_t> out;
+  out.reserve(length);
+
+  for (size_t i = 0; i < length;) {
+    // Be careful about over/underflow here. byte_length_ - 3 can underflow, and
+    // i + 3 can overflow, but byte_length_ - i can't, because i < byte_length_
+    // above, and that expression will produce the number of bytes left in
+    // the stream including the byte at i.
+    if (length - i >= 3 && !data[i] && !data[i + 1] && data[i + 2] == 3) {
+      // Two rbsp bytes.
+      out.push_back(data[i++]);
+      out.push_back(data[i++]);
+      // Skip the emulation byte.
+      i++;
+    } else {
+      // Single rbsp byte.
+      out.push_back(data[i++]);
+    }
+  }
+  return out;
+}
+
+void WriteRbsp(const uint8_t* bytes, size_t length, rtc::Buffer* destination) {
+  static const uint8_t kZerosInStartSequence = 2;
+  static const uint8_t kEmulationByte = 0x03u;
+  size_t num_consecutive_zeros = 0;
+  destination->EnsureCapacity(destination->size() + length);
+
+  for (size_t i = 0; i < length; ++i) {
+    uint8_t byte = bytes[i];
+    if (byte <= kEmulationByte &&
+        num_consecutive_zeros >= kZerosInStartSequence) {
+      // Need to escape.
+      destination->AppendData(kEmulationByte);
+      num_consecutive_zeros = 0;
+    }
+    destination->AppendData(byte);
+    if (byte == 0) {
+      ++num_consecutive_zeros;
+    } else {
+      num_consecutive_zeros = 0;
+    }
+  }
+}
+
+}  // namespace H265
+}  // namespace webrtc
\ No newline at end of file
diff --git a/common_video/h265/h265_common.h b/common_video/h265/h265_common.h
new file mode 100644
index 0000000000..8e36f962b4
--- /dev/null
+++ b/common_video/h265/h265_common.h
@@ -0,0 +1,100 @@
+/*
+ *  Copyright (c) 2018 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef COMMON_VIDEO_H265_H265_COMMON_H_
+#define COMMON_VIDEO_H265_H265_COMMON_H_
+
+#include <memory>
+#include <vector>
+
+#include "rtc_base/buffer.h"
+
+namespace webrtc {
+
+namespace H265 {
+// The size of a full NALU start sequence {0 0 0 1}, used for the first NALU
+// of an access unit, and for SPS and PPS blocks.
+const size_t kNaluLongStartSequenceSize = 4;
+
+// The size of a shortened NALU start sequence {0 0 1}, that may be used if
+// not the first NALU of an access unit or an SPS or PPS block.
+const size_t kNaluShortStartSequenceSize = 3;
+
+// The size of the NALU type byte (1).
+const size_t kNaluTypeSize = 1;
+
+enum NaluType : uint8_t {
+  kTrailN = 0,
+  kTrailR = 1,
+  kTsaN = 2,
+  kTsaR = 3,
+  kStsaN = 4,
+  kStsaR = 5,
+  kRadlN = 6,
+  kRadlR = 7,
+  kBlaWLp = 16,
+  kBlaWRadl = 17,
+  kBlaNLp = 18,
+  kIdrWRadl = 19,
+  kIdrNLp = 20,
+  kCra = 21,
+  kRsvIrapVcl23 = 23,
+  kVps = 32,
+  kSps = 33,
+  kPps = 34,
+  kAud = 35,
+  kPrefixSei = 39,
+  kSuffixSei = 40,
+  kAP = 48,
+  kFU = 49
+};
+
+enum SliceType : uint8_t { kP = 0, kB = 1, kI = 2, kSp = 3, kSi = 4 };
+
+struct NaluIndex {
+  // Start index of NALU, including start sequence.
+  size_t start_offset;
+  // Start index of NALU payload, typically type header.
+  size_t payload_start_offset;
+  // Length of NALU payload, in bytes, counting from payload_start_offset.
+  size_t payload_size;
+};
+
+// Returns a vector of the NALU indices in the given buffer.
+std::vector<NaluIndex> FindNaluIndices(const uint8_t* buffer,
+                                       size_t buffer_size);
+
+// Get the NAL type from the header byte immediately following start sequence.
+NaluType ParseNaluType(uint8_t data);
+
+// Methods for parsing and writing RBSP. See section 7.4.2 of the H265 spec.
+//
+// The following sequences are illegal, and need to be escaped when encoding:
+// 00 00 00 -> 00 00 03 00
+// 00 00 01 -> 00 00 03 01
+// 00 00 02 -> 00 00 03 02
+// And things in the source that look like the emulation byte pattern (00 00 03)
+// need to have an extra emulation byte added, so it's removed when decoding:
+// 00 00 03 -> 00 00 03 03
+//
+// Decoding is simply a matter of finding any 00 00 03 sequence and removing
+// the 03 emulation byte.
+
+// Parse the given data and remove any emulation byte escaping.
+std::vector<uint8_t> ParseRbsp(const uint8_t* data, size_t length);
+
+// Write the given data to the destination buffer, inserting and emulation
+// bytes in order to escape any data the could be interpreted as a start
+// sequence.
+void WriteRbsp(const uint8_t* bytes, size_t length, rtc::Buffer* destination);
+}  // namespace H265
+}  // namespace webrtc
+
+#endif  // COMMON_VIDEO_H265_H265_COMMON_H_
\ No newline at end of file
diff --git a/common_video/h265/h265_pps_parser.cc b/common_video/h265/h265_pps_parser.cc
new file mode 100644
index 0000000000..f21decae07
--- /dev/null
+++ b/common_video/h265/h265_pps_parser.cc
@@ -0,0 +1,209 @@
+/*
+ *  Copyright (c) 2018 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "common_video/h265/h265_pps_parser.h"
+
+#include <memory>
+#include <vector>
+
+#include "common_video/h264/h264_common.h"
+#include "common_video/h265/h265_common.h"
+#include "rtc_base/bit_buffer.h"
+#include "rtc_base/logging.h"
+
+#define RETURN_EMPTY_ON_FAIL(x) \
+  if (!(x)) {                   \
+    return absl::nullopt;        \
+  }
+
+namespace {
+const int kMaxPicInitQpDeltaValue = 25;
+const int kMinPicInitQpDeltaValue = -26;
+}  // namespace
+
+namespace webrtc {
+
+// General note: this is based off the 02/2018 version of the H.265 standard.
+// You can find it on this page:
+// http://www.itu.int/rec/T-REC-H.265
+
+absl::optional<H265PpsParser::PpsState> H265PpsParser::ParsePps(
+    const uint8_t* data,
+    size_t length) {
+  // First, parse out rbsp, which is basically the source buffer minus emulation
+  // bytes (the last byte of a 0x00 0x00 0x03 sequence). RBSP is defined in
+  // section 7.3.1 of the H.264 standard.
+  std::vector<uint8_t> unpacked_buffer = H264::ParseRbsp(data, length);
+  rtc::BitBuffer bit_buffer(unpacked_buffer.data(), unpacked_buffer.size());
+  return ParseInternal(&bit_buffer);
+}
+
+bool H265PpsParser::ParsePpsIds(const uint8_t* data,
+                                size_t length,
+                                uint32_t* pps_id,
+                                uint32_t* sps_id) {
+  RTC_DCHECK(pps_id);
+  RTC_DCHECK(sps_id);
+  // First, parse out rbsp, which is basically the source buffer minus emulation
+  // bytes (the last byte of a 0x00 0x00 0x03 sequence). RBSP is defined in
+  // section 7.3.1 of the H.265 standard.
+  std::vector<uint8_t> unpacked_buffer = H264::ParseRbsp(data, length);
+  rtc::BitBuffer bit_buffer(unpacked_buffer.data(), unpacked_buffer.size());
+  return ParsePpsIdsInternal(&bit_buffer, pps_id, sps_id);
+}
+
+absl::optional<uint32_t> H265PpsParser::ParsePpsIdFromSliceSegmentLayerRbsp(
+    const uint8_t* data,
+    size_t length,
+    uint8_t nalu_type) {
+  rtc::BitBuffer slice_reader(data, length);
+
+  // first_slice_segment_in_pic_flag: u(1)
+  uint32_t first_slice_segment_in_pic_flag = 0;
+  RETURN_EMPTY_ON_FAIL(
+      slice_reader.ReadBits(&first_slice_segment_in_pic_flag, 1));
+
+  if (nalu_type >= H265::NaluType::kBlaWLp &&
+      nalu_type <= H265::NaluType::kRsvIrapVcl23) {
+    // no_output_of_prior_pics_flag: u(1)
+    RETURN_EMPTY_ON_FAIL(slice_reader.ConsumeBits(1));
+  }
+
+  // slice_pic_parameter_set_id: ue(v)
+  uint32_t slice_pic_parameter_set_id = 0;
+  if (!slice_reader.ReadExponentialGolomb(&slice_pic_parameter_set_id))
+    return absl::nullopt;
+
+  return slice_pic_parameter_set_id;
+}
+
+absl::optional<H265PpsParser::PpsState> H265PpsParser::ParseInternal(
+    rtc::BitBuffer* bit_buffer) {
+  PpsState pps;
+
+  RETURN_EMPTY_ON_FAIL(ParsePpsIdsInternal(bit_buffer, &pps.id, &pps.sps_id));
+
+  uint32_t bits_tmp;
+  uint32_t golomb_ignored;
+  // entropy_coding_mode_flag: u(1)
+  uint32_t entropy_coding_mode_flag;
+  RETURN_EMPTY_ON_FAIL(bit_buffer->ReadBits(&entropy_coding_mode_flag, 1));
+  pps.entropy_coding_mode_flag = entropy_coding_mode_flag != 0;
+  // bottom_field_pic_order_in_frame_present_flag: u(1)
+  uint32_t bottom_field_pic_order_in_frame_present_flag;
+  RETURN_EMPTY_ON_FAIL(
+      bit_buffer->ReadBits(&bottom_field_pic_order_in_frame_present_flag, 1));
+  pps.bottom_field_pic_order_in_frame_present_flag =
+      bottom_field_pic_order_in_frame_present_flag != 0;
+
+  // num_slice_groups_minus1: ue(v)
+  uint32_t num_slice_groups_minus1;
+  RETURN_EMPTY_ON_FAIL(
+      bit_buffer->ReadExponentialGolomb(&num_slice_groups_minus1));
+  if (num_slice_groups_minus1 > 0) {
+    uint32_t slice_group_map_type;
+    // slice_group_map_type: ue(v)
+    RETURN_EMPTY_ON_FAIL(
+        bit_buffer->ReadExponentialGolomb(&slice_group_map_type));
+    if (slice_group_map_type == 0) {
+      for (uint32_t i_group = 0; i_group <= num_slice_groups_minus1;
+           ++i_group) {
+        // run_length_minus1[iGroup]: ue(v)
+        RETURN_EMPTY_ON_FAIL(
+            bit_buffer->ReadExponentialGolomb(&golomb_ignored));
+      }
+    } else if (slice_group_map_type == 1) {
+      // TODO(sprang): Implement support for dispersed slice group map type.
+      // See 8.2.2.2 Specification for dispersed slice group map type.
+    } else if (slice_group_map_type == 2) {
+      for (uint32_t i_group = 0; i_group <= num_slice_groups_minus1;
+           ++i_group) {
+        // top_left[iGroup]: ue(v)
+        RETURN_EMPTY_ON_FAIL(
+            bit_buffer->ReadExponentialGolomb(&golomb_ignored));
+        // bottom_right[iGroup]: ue(v)
+        RETURN_EMPTY_ON_FAIL(
+            bit_buffer->ReadExponentialGolomb(&golomb_ignored));
+      }
+    } else if (slice_group_map_type == 3 || slice_group_map_type == 4 ||
+               slice_group_map_type == 5) {
+      // slice_group_change_direction_flag: u(1)
+      RETURN_EMPTY_ON_FAIL(bit_buffer->ReadBits(&bits_tmp, 1));
+      // slice_group_change_rate_minus1: ue(v)
+      RETURN_EMPTY_ON_FAIL(bit_buffer->ReadExponentialGolomb(&golomb_ignored));
+    } else if (slice_group_map_type == 6) {
+      // pic_size_in_map_units_minus1: ue(v)
+      uint32_t pic_size_in_map_units_minus1;
+      RETURN_EMPTY_ON_FAIL(
+          bit_buffer->ReadExponentialGolomb(&pic_size_in_map_units_minus1));
+      uint32_t slice_group_id_bits = 0;
+      uint32_t num_slice_groups = num_slice_groups_minus1 + 1;
+      // If num_slice_groups is not a power of two an additional bit is required
+      // to account for the ceil() of log2() below.
+      if ((num_slice_groups & (num_slice_groups - 1)) != 0)
+        ++slice_group_id_bits;
+      while (num_slice_groups > 0) {
+        num_slice_groups >>= 1;
+        ++slice_group_id_bits;
+      }
+      for (uint32_t i = 0; i <= pic_size_in_map_units_minus1; i++) {
+        // slice_group_id[i]: u(v)
+        // Represented by ceil(log2(num_slice_groups_minus1 + 1)) bits.
+        RETURN_EMPTY_ON_FAIL(
+            bit_buffer->ReadBits(&bits_tmp, slice_group_id_bits));
+      }
+    }
+  }
+  // num_ref_idx_l0_default_active_minus1: ue(v)
+  RETURN_EMPTY_ON_FAIL(bit_buffer->ReadExponentialGolomb(&golomb_ignored));
+  // num_ref_idx_l1_default_active_minus1: ue(v)
+  RETURN_EMPTY_ON_FAIL(bit_buffer->ReadExponentialGolomb(&golomb_ignored));
+  // weighted_pred_flag: u(1)
+  uint32_t weighted_pred_flag;
+  RETURN_EMPTY_ON_FAIL(bit_buffer->ReadBits(&weighted_pred_flag, 1));
+  pps.weighted_pred_flag = weighted_pred_flag != 0;
+  // weighted_bipred_idc: u(2)
+  RETURN_EMPTY_ON_FAIL(bit_buffer->ReadBits(&pps.weighted_bipred_idc, 2));
+
+  // pic_init_qp_minus26: se(v)
+  RETURN_EMPTY_ON_FAIL(
+      bit_buffer->ReadSignedExponentialGolomb(&pps.pic_init_qp_minus26));
+  // Sanity-check parsed value
+  if (pps.pic_init_qp_minus26 > kMaxPicInitQpDeltaValue ||
+      pps.pic_init_qp_minus26 < kMinPicInitQpDeltaValue) {
+    RETURN_EMPTY_ON_FAIL(false);
+  }
+  // pic_init_qs_minus26: se(v)
+  RETURN_EMPTY_ON_FAIL(bit_buffer->ReadExponentialGolomb(&golomb_ignored));
+  // chroma_qp_index_offset: se(v)
+  RETURN_EMPTY_ON_FAIL(bit_buffer->ReadExponentialGolomb(&golomb_ignored));
+  // deblocking_filter_control_present_flag: u(1)
+  // constrained_intra_pred_flag: u(1)
+  RETURN_EMPTY_ON_FAIL(bit_buffer->ReadBits(&bits_tmp, 2));
+  // redundant_pic_cnt_present_flag: u(1)
+  RETURN_EMPTY_ON_FAIL(
+      bit_buffer->ReadBits(&pps.redundant_pic_cnt_present_flag, 1));
+
+  return pps;
+}
+
+bool H265PpsParser::ParsePpsIdsInternal(rtc::BitBuffer* bit_buffer,
+                                        uint32_t* pps_id,
+                                        uint32_t* sps_id) {
+  // pic_parameter_set_id: ue(v)
+  if (!bit_buffer->ReadExponentialGolomb(pps_id))
+    return false;
+  // seq_parameter_set_id: ue(v)
+  if (!bit_buffer->ReadExponentialGolomb(sps_id))
+    return false;
+  return true;
+}
+
+}  // namespace webrtc
\ No newline at end of file
diff --git a/common_video/h265/h265_pps_parser.h b/common_video/h265/h265_pps_parser.h
new file mode 100644
index 0000000000..b7ddc9627b
--- /dev/null
+++ b/common_video/h265/h265_pps_parser.h
@@ -0,0 +1,64 @@
+/*
+ *  Copyright (c) 2018 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef COMMON_VIDEO_H265_PPS_PARSER_H_
+#define COMMON_VIDEO_H265_PPS_PARSER_H_
+
+#include "absl/types/optional.h"
+
+namespace rtc {
+class BitBuffer;
+}
+
+namespace webrtc {
+
+// A class for parsing out picture parameter set (PPS) data from a H265 NALU.
+class H265PpsParser {
+ public:
+  // The parsed state of the PPS. Only some select values are stored.
+  // Add more as they are actually needed.
+  struct PpsState {
+    PpsState() = default;
+
+    bool bottom_field_pic_order_in_frame_present_flag = false;
+    bool weighted_pred_flag = false;
+    bool entropy_coding_mode_flag = false;
+    uint32_t weighted_bipred_idc = false;
+    uint32_t redundant_pic_cnt_present_flag = 0;
+    int pic_init_qp_minus26 = 0;
+    uint32_t id = 0;
+    uint32_t sps_id = 0;
+  };
+
+  // Unpack RBSP and parse PPS state from the supplied buffer.
+  static absl::optional<PpsState> ParsePps(const uint8_t* data, size_t length);
+
+  static bool ParsePpsIds(const uint8_t* data,
+                          size_t length,
+                          uint32_t* pps_id,
+                          uint32_t* sps_id);
+
+  static absl::optional<uint32_t> ParsePpsIdFromSliceSegmentLayerRbsp(
+      const uint8_t* data,
+      size_t length,
+      uint8_t nalu_type);
+
+ protected:
+  // Parse the PPS state, for a bit buffer where RBSP decoding has already been
+  // performed.
+  static absl::optional<PpsState> ParseInternal(rtc::BitBuffer* bit_buffer);
+  static bool ParsePpsIdsInternal(rtc::BitBuffer* bit_buffer,
+                                  uint32_t* pps_id,
+                                  uint32_t* sps_id);
+};
+
+}  // namespace webrtc
+
+#endif  // COMMON_VIDEO_H265_PPS_PARSER_H_
\ No newline at end of file
diff --git a/common_video/h265/h265_sps_parser.cc b/common_video/h265/h265_sps_parser.cc
new file mode 100644
index 0000000000..d5732cbebe
--- /dev/null
+++ b/common_video/h265/h265_sps_parser.cc
@@ -0,0 +1,192 @@
+/*
+ *  Copyright (c) 2018 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include <memory>
+#include <vector>
+
+#include "common_video/h265/h265_common.h"
+#include "common_video/h265/h265_sps_parser.h"
+#include "rtc_base/bit_buffer.h"
+#include "rtc_base/logging.h"
+
+namespace {
+typedef absl::optional<webrtc::H265SpsParser::SpsState> OptionalSps;
+
+#define RETURN_EMPTY_ON_FAIL(x) \
+  if (!(x)) {                   \
+    return OptionalSps();       \
+  }
+}  // namespace
+
+namespace webrtc {
+
+H265SpsParser::SpsState::SpsState() = default;
+
+// General note: this is based off the 02/2018 version of the H.265 standard.
+// You can find it on this page:
+// http://www.itu.int/rec/T-REC-H.265
+
+// Unpack RBSP and parse SPS state from the supplied buffer.
+absl::optional<H265SpsParser::SpsState> H265SpsParser::ParseSps(
+    const uint8_t* data,
+    size_t length) {
+  std::vector<uint8_t> unpacked_buffer = H265::ParseRbsp(data, length);
+  rtc::BitBuffer bit_buffer(unpacked_buffer.data(), unpacked_buffer.size());
+  return ParseSpsUpToVui(&bit_buffer);
+}
+
+absl::optional<H265SpsParser::SpsState> H265SpsParser::ParseSpsUpToVui(
+    rtc::BitBuffer* buffer) {
+  // Now, we need to use a bit buffer to parse through the actual HEVC SPS
+  // format. See Section 7.3.2.2.1 ("General sequence parameter set data
+  // syntax") of the H.265 standard for a complete description.
+  // Since we only care about resolution, we ignore the majority of fields, but
+  // we still have to actively parse through a lot of the data, since many of
+  // the fields have variable size.
+  // We're particularly interested in:
+  // chroma_format_idc -> affects crop units
+  // pic_{width,height}_* -> resolution of the frame in macroblocks (16x16).
+  // frame_crop_*_offset -> crop information
+
+  SpsState sps;
+
+  // The golomb values we have to read, not just consume.
+  uint32_t golomb_ignored;
+
+  // separate_colour_plane_flag is optional (assumed 0), but has implications
+  // about the ChromaArrayType, which modifies how we treat crop coordinates.
+  uint32_t separate_colour_plane_flag = 0;
+
+  // chroma_format_idc will be ChromaArrayType if separate_colour_plane_flag is
+  // 0. It defaults to 1, when not specified.
+  uint32_t chroma_format_idc = 1;
+
+  // sps_video_parameter_set_id: u(4)
+  uint32_t sps_video_parameter_set_id = 0;
+  RETURN_EMPTY_ON_FAIL(buffer->ReadBits(&sps_video_parameter_set_id, 4));
+  // sps_max_sub_layers_minus1: u(3)
+  uint32_t sps_max_sub_layers_minus1 = 0;
+  RETURN_EMPTY_ON_FAIL(buffer->ReadBits(&sps_max_sub_layers_minus1, 3));
+  // sps_temporal_id_nesting_flag: u(1)
+  RETURN_EMPTY_ON_FAIL(buffer->ConsumeBits(1));
+  // profile_tier_level(1, sps_max_sub_layers_minus1). We are acutally not
+  // using them, so read/skip over it.
+  // general_profile_space+general_tier_flag+general_prfile_idc: u(8)
+  RETURN_EMPTY_ON_FAIL(buffer->ConsumeBytes(1));
+  // general_profile_compatabilitiy_flag[32]
+  RETURN_EMPTY_ON_FAIL(buffer->ConsumeBytes(4));
+  // general_progressive_source_flag + interlaced_source_flag+
+  // non-packed_constraint flag + frame_only_constraint_flag: u(4)
+  RETURN_EMPTY_ON_FAIL(buffer->ConsumeBits(4));
+  // general_profile_idc decided flags or reserved.  u(43)
+  RETURN_EMPTY_ON_FAIL(buffer->ConsumeBits(43));
+  // general_inbld_flag or reserved 0: u(1)
+  RETURN_EMPTY_ON_FAIL(buffer->ConsumeBits(1));
+  // general_level_idc: u(8)
+  RETURN_EMPTY_ON_FAIL(buffer->ConsumeBytes(1));
+  // if max_sub_layers_minus1 >=1, read the sublayer profile information
+  std::vector<uint32_t> sub_layer_profile_present_flags;
+  std::vector<uint32_t> sub_layer_level_present_flags;
+  uint32_t sub_layer_profile_present = 0;
+  uint32_t sub_layer_level_present = 0;
+  for (uint32_t i = 0; i < sps_max_sub_layers_minus1; i++) {
+    // sublayer_profile_present_flag and sublayer_level_presnet_flag:  u(2)
+    RETURN_EMPTY_ON_FAIL(buffer->ReadBits(&sub_layer_profile_present, 1));
+    RETURN_EMPTY_ON_FAIL(buffer->ReadBits(&sub_layer_level_present, 1));
+    sub_layer_profile_present_flags.push_back(sub_layer_profile_present);
+    sub_layer_level_present_flags.push_back(sub_layer_level_present);
+  }
+  if (sps_max_sub_layers_minus1 > 0) {
+    for (uint32_t j = sps_max_sub_layers_minus1; j < 8; j++) {
+      // reserved 2 bits: u(2)
+      RETURN_EMPTY_ON_FAIL(buffer->ConsumeBits(2));
+    }
+  }
+  for (uint32_t k = 0; k < sps_max_sub_layers_minus1; k++) {
+    if (sub_layer_profile_present_flags[k]) {  //
+      // sub_layer profile_space/tier_flag/profile_idc. ignored. u(8)
+      RETURN_EMPTY_ON_FAIL(buffer->ConsumeBytes(1));
+      // profile_compatability_flag:  u(32)
+      RETURN_EMPTY_ON_FAIL(buffer->ConsumeBytes(4));
+      // sub_layer progressive_source_flag/interlaced_source_flag/
+      // non_packed_constraint_flag/frame_only_constraint_flag: u(4)
+      RETURN_EMPTY_ON_FAIL(buffer->ConsumeBits(4));
+      // following 43-bits are profile_idc specific. We simply read/skip it.
+      // u(43)
+      RETURN_EMPTY_ON_FAIL(buffer->ConsumeBits(43));
+      // 1-bit profile_idc specific inbld flag.  We simply read/skip it. u(1)
+      RETURN_EMPTY_ON_FAIL(buffer->ConsumeBits(1));
+    }
+    if (sub_layer_level_present_flags[k]) {
+      // sub_layer_level_idc: u(8)
+      RETURN_EMPTY_ON_FAIL(buffer->ConsumeBytes(1));
+    }
+  }
+  // sps_seq_parameter_set_id: ue(v)
+  RETURN_EMPTY_ON_FAIL(buffer->ReadExponentialGolomb(&golomb_ignored));
+  // chrome_format_idc: ue(v)
+  RETURN_EMPTY_ON_FAIL(buffer->ReadExponentialGolomb(&chroma_format_idc));
+  if (chroma_format_idc == 3) {
+    // seperate_colour_plane_flag: u(1)
+    RETURN_EMPTY_ON_FAIL(buffer->ReadBits(&separate_colour_plane_flag, 1));
+  }
+  uint32_t pic_width_in_luma_samples = 0;
+  uint32_t pic_height_in_luma_samples = 0;
+  // pic_width_in_luma_samples: ue(v)
+  RETURN_EMPTY_ON_FAIL(
+      buffer->ReadExponentialGolomb(&pic_width_in_luma_samples));
+  // pic_height_in_luma_samples: ue(v)
+  RETURN_EMPTY_ON_FAIL(
+      buffer->ReadExponentialGolomb(&pic_height_in_luma_samples));
+  // conformance_window_flag: u(1)
+  uint32_t conformance_window_flag = 0;
+  RETURN_EMPTY_ON_FAIL(buffer->ReadBits(&conformance_window_flag, 1));
+
+  uint32_t conf_win_left_offset = 0;
+  uint32_t conf_win_right_offset = 0;
+  uint32_t conf_win_top_offset = 0;
+  uint32_t conf_win_bottom_offset = 0;
+  if (conformance_window_flag) {
+    // conf_win_left_offset: ue(v)
+    RETURN_EMPTY_ON_FAIL(buffer->ReadExponentialGolomb(&conf_win_left_offset));
+    // conf_win_right_offset: ue(v)
+    RETURN_EMPTY_ON_FAIL(buffer->ReadExponentialGolomb(&conf_win_right_offset));
+    // conf_win_top_offset: ue(v)
+    RETURN_EMPTY_ON_FAIL(buffer->ReadExponentialGolomb(&conf_win_top_offset));
+    // conf_win_bottom_offset: ue(v)
+    RETURN_EMPTY_ON_FAIL(
+        buffer->ReadExponentialGolomb(&conf_win_bottom_offset));
+  }
+
+  // Far enough! We don't use the rest of the SPS.
+
+  sps.vps_id = sps_video_parameter_set_id;
+
+  // Start with the resolution determined by the pic_width/pic_height fields.
+  sps.width = pic_width_in_luma_samples;
+  sps.height = pic_height_in_luma_samples;
+
+  if (conformance_window_flag) {
+    int sub_width_c = ((1 == chroma_format_idc) || (2 == chroma_format_idc)) &&
+                              (0 == separate_colour_plane_flag)
+                          ? 2
+                          : 1;
+    int sub_height_c =
+        (1 == chroma_format_idc) && (0 == separate_colour_plane_flag) ? 2 : 1;
+    // the offset includes the pixel within conformance window. so don't need to
+    // +1 as per spec
+    sps.width -= sub_width_c * (conf_win_right_offset + conf_win_left_offset);
+    sps.height -= sub_height_c * (conf_win_top_offset + conf_win_bottom_offset);
+  }
+
+  return OptionalSps(sps);
+}
+
+}  // namespace webrtc
\ No newline at end of file
diff --git a/common_video/h265/h265_sps_parser.h b/common_video/h265/h265_sps_parser.h
new file mode 100644
index 0000000000..25c1c75cc4
--- /dev/null
+++ b/common_video/h265/h265_sps_parser.h
@@ -0,0 +1,54 @@
+/*
+ *  Copyright (c) 2018 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef COMMON_VIDEO_H265_H265_SPS_PARSER_H_
+#define COMMON_VIDEO_H265_H265_SPS_PARSER_H_
+
+#include "absl/types/optional.h"
+
+namespace rtc {
+class BitBuffer;
+}
+
+namespace webrtc {
+
+// A class for parsing out sequence parameter set (SPS) data from an H265 NALU.
+class H265SpsParser {
+ public:
+  // The parsed state of the SPS. Only some select values are stored.
+  // Add more as they are actually needed.
+  struct SpsState {
+    SpsState();
+
+    uint32_t width = 0;
+    uint32_t height = 0;
+    uint32_t delta_pic_order_always_zero_flag = 0;
+    uint32_t separate_colour_plane_flag = 0;
+    uint32_t frame_mbs_only_flag = 0;
+    uint32_t log2_max_frame_num_minus4 = 0;
+    uint32_t log2_max_pic_order_cnt_lsb_minus4 = 0;
+    uint32_t pic_order_cnt_type = 0;
+    uint32_t max_num_ref_frames = 0;
+    uint32_t vui_params_present = 0;
+    uint32_t id = 0;
+    uint32_t vps_id = 0;
+  };
+
+  // Unpack RBSP and parse SPS state from the supplied buffer.
+  static absl::optional<SpsState> ParseSps(const uint8_t* data, size_t length);
+
+ protected:
+  // Parse the SPS state, up till the VUI part, for a bit buffer where RBSP
+  // decoding has already been performed.
+  static absl::optional<SpsState> ParseSpsUpToVui(rtc::BitBuffer* buffer);
+};
+
+}  // namespace webrtc
+#endif  // COMMON_VIDEO_H265_H265_SPS_PARSER_H_
\ No newline at end of file
diff --git a/common_video/h265/h265_vps_parser.cc b/common_video/h265/h265_vps_parser.cc
new file mode 100644
index 0000000000..59acb9d086
--- /dev/null
+++ b/common_video/h265/h265_vps_parser.cc
@@ -0,0 +1,62 @@
+/*
+ *  Copyright (c) 2018 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include <memory>
+#include <vector>
+
+#include "common_video/h265/h265_common.h"
+#include "common_video/h265/h265_vps_parser.h"
+#include "rtc_base/bit_buffer.h"
+#include "rtc_base/logging.h"
+
+namespace {
+typedef absl::optional<webrtc::H265VpsParser::VpsState> OptionalVps;
+
+#define RETURN_EMPTY_ON_FAIL(x) \
+  if (!(x)) {                   \
+    return OptionalVps();       \
+  }
+}  // namespace
+
+namespace webrtc {
+
+H265VpsParser::VpsState::VpsState() = default;
+
+// General note: this is based off the 02/2018 version of the H.265 standard.
+// You can find it on this page:
+// http://www.itu.int/rec/T-REC-H.265
+
+// Unpack RBSP and parse SPS state from the supplied buffer.
+absl::optional<H265VpsParser::VpsState> H265VpsParser::ParseVps(
+    const uint8_t* data,
+    size_t length) {
+  std::vector<uint8_t> unpacked_buffer = H265::ParseRbsp(data, length);
+  rtc::BitBuffer bit_buffer(unpacked_buffer.data(), unpacked_buffer.size());
+  return ParseInternal(&bit_buffer);
+}
+
+absl::optional<H265VpsParser::VpsState> H265VpsParser::ParseInternal(
+    rtc::BitBuffer* buffer) {
+  // Now, we need to use a bit buffer to parse through the actual HEVC VPS
+  // format. See Section 7.3.2.1 ("Video parameter set RBSP syntax") of the
+  // H.265 standard for a complete description.
+
+  VpsState vps;
+
+  // vps_video_parameter_set_id: u(4)
+  uint32_t vps_video_parameter_set_id = 0;
+  RETURN_EMPTY_ON_FAIL(buffer->ReadBits(&vps_video_parameter_set_id, 4));
+
+  vps.id = vps_video_parameter_set_id;
+  vps.id = 0;
+  return OptionalVps(vps);
+}
+
+}  // namespace webrtc
\ No newline at end of file
diff --git a/common_video/h265/h265_vps_parser.h b/common_video/h265/h265_vps_parser.h
new file mode 100644
index 0000000000..0b7c1af511
--- /dev/null
+++ b/common_video/h265/h265_vps_parser.h
@@ -0,0 +1,43 @@
+/*
+ *  Copyright (c) 2018 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef COMMON_VIDEO_H265_H265_VPS_PARSER_H_
+#define COMMON_VIDEO_H265_H265_VPS_PARSER_H_
+
+#include "absl/types/optional.h"
+
+namespace rtc {
+class BitBuffer;
+}
+
+namespace webrtc {
+
+// A class for parsing out sequence parameter set (VPS) data from an H265 NALU.
+class H265VpsParser {
+ public:
+  // The parsed state of the VPS. Only some select values are stored.
+  // Add more as they are actually needed.
+  struct VpsState {
+    VpsState();
+
+    uint32_t id = 0;
+  };
+
+  // Unpack RBSP and parse VPS state from the supplied buffer.
+  static absl::optional<VpsState> ParseVps(const uint8_t* data, size_t length);
+
+ protected:
+  // Parse the VPS state, for a bit buffer where RBSP decoding has already been
+  // performed.
+  static absl::optional<VpsState> ParseInternal(rtc::BitBuffer* bit_buffer);
+};
+
+}  // namespace webrtc
+#endif  // COMMON_VIDEO_H265_H265_VPS_PARSER_H_
\ No newline at end of file
diff --git a/media/base/media_constants.cc b/media/base/media_constants.cc
index 03679d9627..f8f93f8cd4 100644
--- a/media/base/media_constants.cc
+++ b/media/base/media_constants.cc
@@ -104,6 +104,7 @@ const char kVp8CodecName[] = "VP8";
 const char kVp9CodecName[] = "VP9";
 const char kAv1CodecName[] = "AV1X";
 const char kH264CodecName[] = "H264";
+const char kH265CodecName[] = "H265";
 const char kHEVCCodecName[] = "H265X";
 
 // RFC 6184 RTP Payload Format for H.264 video
@@ -113,6 +114,12 @@ const char kH264FmtpPacketizationMode[] = "packetization-mode";
 const char kH264FmtpSpropParameterSets[] = "sprop-parameter-sets";
 const char kH264ProfileLevelConstrainedBaseline[] = "42e01f";
 
+// RFC 7798 RTP Payload Format for H.265 video
+const char kH265FmtpProfileSpace[] = "profile-space";
+const char kH265FmtpProfileId[] = "profile-id";
+const char kH265FmtpTierFlag[] = "tier-flag";
+const char kH265FmtpLevelId[] = "level-id";
+
 const int kDefaultVideoMaxFramerate = 60;
 
 const size_t kConferenceMaxNumSpatialLayers = 3;
diff --git a/media/base/media_constants.h b/media/base/media_constants.h
index d2bfb36ee9..919af2e262 100644
--- a/media/base/media_constants.h
+++ b/media/base/media_constants.h
@@ -130,6 +130,7 @@ RTC_EXPORT extern const char kVp8CodecName[];
 RTC_EXPORT extern const char kVp9CodecName[];
 RTC_EXPORT extern const char kAv1CodecName[];
 RTC_EXPORT extern const char kH264CodecName[];
+RTC_EXPORT extern const char kH265CodecName[];
 RTC_EXPORT extern const char kHEVCCodecName[];
 
 // RFC 6184 RTP Payload Format for H.264 video
@@ -139,6 +140,12 @@ RTC_EXPORT extern const char kH264FmtpPacketizationMode[];
 extern const char kH264FmtpSpropParameterSets[];
 extern const char kH264ProfileLevelConstrainedBaseline[];
 
+// RFC 7798 RTP Payload Format for H.265 video
+RTC_EXPORT extern const char kH265FmtpProfileSpace[];
+RTC_EXPORT extern const char kH265FmtpProfileId[];
+RTC_EXPORT extern const char kH265FmtpTierFlag[];
+RTC_EXPORT extern const char kH265FmtpLevelId[];
+
 extern const int kDefaultVideoMaxFramerate;
 
 extern const size_t kConferenceMaxNumSpatialLayers;
diff --git a/modules/audio_device/BUILD.gn b/modules/audio_device/BUILD.gn
index 0d1ee81b47..25863d3a73 100644
--- a/modules/audio_device/BUILD.gn
+++ b/modules/audio_device/BUILD.gn
@@ -289,6 +289,7 @@ rtc_library("audio_device_impl") {
         ]
       }
       if (is_mac) {
+        cflags += [ "-Wno-deprecated-declarations" ]
         sources += [
           "mac/audio_device_mac.cc",
           "mac/audio_device_mac.h",
diff --git a/modules/desktop_capture/BUILD.gn b/modules/desktop_capture/BUILD.gn
index e49e8381f6..1818604f7c 100644
--- a/modules/desktop_capture/BUILD.gn
+++ b/modules/desktop_capture/BUILD.gn
@@ -235,6 +235,7 @@ rtc_source_set("desktop_capture") {
 if (is_mac) {
   rtc_library("desktop_capture_objc") {
     visibility = [ ":desktop_capture" ]
+    cflags = [ "-Wno-deprecated-declarations" ]
     sources = [
       "mac/desktop_configuration.mm",
       "mac/desktop_frame_cgimage.h",
diff --git a/modules/rtp_rtcp/BUILD.gn b/modules/rtp_rtcp/BUILD.gn
index 0446799fb7..99cdbe3a92 100644
--- a/modules/rtp_rtcp/BUILD.gn
+++ b/modules/rtp_rtcp/BUILD.gn
@@ -244,6 +244,11 @@ rtc_library("rtp_rtcp") {
     defines = [ "BWE_TEST_LOGGING_COMPILE_TIME_ENABLE=0" ]
   }
 
+  sources += [
+    "source/rtp_format_h265.cc",
+    "source/rtp_format_h265.h",
+  ]
+
   deps = [
     ":rtp_rtcp_format",
     ":rtp_video_header",
diff --git a/modules/rtp_rtcp/source/create_video_rtp_depacketizer.cc b/modules/rtp_rtcp/source/create_video_rtp_depacketizer.cc
index 724ad8c42e..c5ce3ed746 100644
--- a/modules/rtp_rtcp/source/create_video_rtp_depacketizer.cc
+++ b/modules/rtp_rtcp/source/create_video_rtp_depacketizer.cc
@@ -13,6 +13,7 @@
 #include <memory>
 
 #include "api/video/video_codec_type.h"
+#include "modules/rtp_rtcp/source/rtp_format_h265.h"
 #include "modules/rtp_rtcp/source/video_rtp_depacketizer.h"
 #include "modules/rtp_rtcp/source/video_rtp_depacketizer_av1.h"
 #include "modules/rtp_rtcp/source/video_rtp_depacketizer_generic.h"
@@ -27,6 +28,8 @@ std::unique_ptr<VideoRtpDepacketizer> CreateVideoRtpDepacketizer(
   switch (codec) {
     case kVideoCodecH264:
       return std::make_unique<VideoRtpDepacketizerH264>();
+    case kVideoCodecH265:
+      return std::make_unique<VideoRtpDepacketizerH265>();
     case kVideoCodecVP8:
       return std::make_unique<VideoRtpDepacketizerVp8>();
     case kVideoCodecVP9:
diff --git a/modules/rtp_rtcp/source/h265_sps_parser.cc b/modules/rtp_rtcp/source/h265_sps_parser.cc
new file mode 100644
index 0000000000..22c6f9d30c
--- /dev/null
+++ b/modules/rtp_rtcp/source/h265_sps_parser.cc
@@ -0,0 +1,191 @@
+/*
+ * Intel License
+ * See https://01.org/open-webrtc-toolkit
+ * This is released under Apache License 2.0 and it is free for both academic and commercial use.
+ */
+
+#include "webrtc/modules/rtp_rtcp/source/h265_sps_parser.h"
+
+#include "rtc_base/bit_buffer.h"
+#include "rtc_base/byte_buffer.h"
+#include "rtc_base/logging.h"
+
+#include <vector>
+
+#define RETURN_FALSE_ON_FAIL(x) \
+  if (!(x)) {                   \
+    return false;               \
+  }
+
+namespace webrtc {
+
+H265SpsParser::H265SpsParser(const uint8_t* sps, size_t byte_length)
+    : sps_(sps), byte_length_(byte_length), width_(), height_() {
+}
+
+bool H265SpsParser::Parse() {
+  // General note: this is based off the 04/2015 version of the H.265 standard.
+  // You can find it on this page:
+  // http://www.itu.int/rec/T-REC-H.265
+
+  const char* sps_bytes = reinterpret_cast<const char*>(sps_);
+  // First, parse out rbsp, which is basically the source buffer minus emulation
+  // bytes (the last byte of a 0x00 0x00 0x03 sequence). RBSP is defined in
+  // section 7.3.1.1 of the H.265 standard, similar to H264.
+  rtc::ByteBufferWriter rbsp_buffer;
+  for (size_t i = 0; i < byte_length_;) {
+    // Be careful about over/underflow here. byte_length_ - 3 can underflow, and
+    // i + 3 can overflow, but byte_length_ - i can't, because i < byte_length_
+    // above, and that expression will produce the number of bytes left in
+    // the stream including the byte at i.
+    if (byte_length_ - i >= 3 && sps_[i] == 0 && sps_[i + 1] == 0 &&
+        sps_[i + 2] == 3) {
+      // Two rbsp bytes + the emulation byte.
+      rbsp_buffer.WriteBytes(sps_bytes + i, 2);
+      i += 3;
+    } else {
+      // Single rbsp byte.
+      rbsp_buffer.WriteBytes(sps_bytes + i, 1);
+      i++;
+    }
+  }
+
+  // Now, we need to use a bit buffer to parse through the actual HEVC SPS
+  // format. See Section 7.3.2.1.1 ("Sequence parameter set data syntax") of the
+  // H.265 standard for a complete description.
+  // Since we only care about resolution, we ignore the majority of fields, but
+  // we still have to actively parse through a lot of the data, since many of
+  // the fields have variable size.
+  // Unlike H264, for H265, the picture size is indicated by pic_width_in_luma_samples
+  // and pic_height_in_luma_samples,  if conformance_window_flag !=1;
+  // When conformance_window_flag is 1,  the width is adjusted with con_win_xx_offset
+  //
+  rtc::BitBuffer parser(reinterpret_cast<const uint8_t*>(rbsp_buffer.Data()),
+                        rbsp_buffer.Length());
+
+  // The golomb values we have to read, not just consume.
+  uint32_t golomb_ignored;
+
+  // separate_colour_plane_flag is optional (assumed 0), but has implications
+  // about the ChromaArrayType, which modifies how we treat crop coordinates.
+  uint32_t separate_colour_plane_flag = 0;
+  // chroma_format_idc will be ChromaArrayType if separate_colour_plane_flag is
+  // 0. It defaults to 1, when not specified.
+  uint32_t chroma_format_idc = 1;
+
+
+  // sps_video_parameter_set_id: u(4)
+  RETURN_FALSE_ON_FAIL(parser.ConsumeBits(4));
+  // sps_max_sub_layers_minus1: u(3)
+  uint32_t sps_max_sub_layers_minus1 = 0;
+  RETURN_FALSE_ON_FAIL(parser.ReadBits(&sps_max_sub_layers_minus1, 3));
+  // sps_temporal_id_nesting_flag: u(1)
+  RETURN_FALSE_ON_FAIL(parser.ConsumeBits(1));
+  // profile_tier_level(1, sps_max_sub_layers_minus1). We are acutally not
+  // using them, so read/skip over it.
+  // general_profile_space+general_tier_flag+general_prfile_idc: u(8)
+  RETURN_FALSE_ON_FAIL(parser.ConsumeBytes(1));
+  // general_profile_compatabilitiy_flag[32]
+  RETURN_FALSE_ON_FAIL(parser.ConsumeBytes(4));
+  // general_progressive_source_flag + interlaced_source_flag+ non-packed_constraint
+  // flag + frame_only_constraint_flag: u(4)
+  RETURN_FALSE_ON_FAIL(parser.ConsumeBits(4));
+  // general_profile_idc decided flags or reserved.  u(43)
+  RETURN_FALSE_ON_FAIL(parser.ConsumeBits(43));
+  // general_inbld_flag or reserved 0: u(1)
+  RETURN_FALSE_ON_FAIL(parser.ConsumeBits(1));
+  // general_level_idc: u(8)
+  RETURN_FALSE_ON_FAIL(parser.ConsumeBytes(1));
+  // if max_sub_layers_minus1 >=1, read the sublayer profile information
+  std::vector<uint32_t> sub_layer_profile_present_flags;
+  std::vector<uint32_t> sub_layer_level_present_flags;
+  uint32_t sub_layer_profile_present = 0;
+  uint32_t sub_layer_level_present = 0;
+  for (uint32_t i = 0; i < sps_max_sub_layers_minus1; i++) {
+      //sublayer_profile_present_flag and sublayer_level_presnet_flag:  u(2)
+      RETURN_FALSE_ON_FAIL(parser.ReadBits(&sub_layer_profile_present, 1));
+      RETURN_FALSE_ON_FAIL(parser.ReadBits(&sub_layer_level_present, 1));
+      sub_layer_profile_present_flags.push_back(sub_layer_profile_present);
+      sub_layer_level_present_flags.push_back(sub_layer_level_present);
+  }
+  if (sps_max_sub_layers_minus1 > 0) {
+      for (uint32_t j = sps_max_sub_layers_minus1; j < 8; j++) {
+        // reserved 2 bits: u(2)
+          RETURN_FALSE_ON_FAIL(parser.ConsumeBits(2));
+      }
+  }
+  for (uint32_t k = 0; k < sps_max_sub_layers_minus1; k++) {
+      if(sub_layer_profile_present_flags[k]) {//
+        // sub_layer profile_space/tier_flag/profile_idc. ignored. u(8)
+        RETURN_FALSE_ON_FAIL(parser.ConsumeBytes(1));
+        // profile_compatability_flag:  u(32)
+        RETURN_FALSE_ON_FAIL(parser.ConsumeBytes(4));
+        // sub_layer progressive_source_flag/interlaced_source_flag/
+        // non_packed_constraint_flag/frame_only_constraint_flag: u(4)
+        RETURN_FALSE_ON_FAIL(parser.ConsumeBits(4));
+        // following 43-bits are profile_idc specific. We simply read/skip it. u(43)
+        RETURN_FALSE_ON_FAIL(parser.ConsumeBits(43));
+        // 1-bit profile_idc specific inbld flag.  We simply read/skip it. u(1)
+        RETURN_FALSE_ON_FAIL(parser.ConsumeBits(1));
+      }
+      if (sub_layer_level_present_flags[k]) {
+        // sub_layer_level_idc: u(8)
+          RETURN_FALSE_ON_FAIL(parser.ConsumeBytes(1));
+      }
+  }
+  //sps_seq_parameter_set_id: ue(v)
+  RETURN_FALSE_ON_FAIL(parser.ReadExponentialGolomb(&golomb_ignored));
+  // chrome_format_idc: ue(v)
+  RETURN_FALSE_ON_FAIL(parser.ReadExponentialGolomb(&chroma_format_idc));
+  if (chroma_format_idc == 3) {
+    // seperate_colour_plane_flag: u(1)
+    RETURN_FALSE_ON_FAIL(parser.ReadBits(&separate_colour_plane_flag, 1));
+  }
+  uint32_t pic_width_in_luma_samples = 0;
+  uint32_t pic_height_in_luma_samples = 0;
+  // pic_width_in_luma_samples: ue(v)
+  RETURN_FALSE_ON_FAIL(parser.ReadExponentialGolomb(&pic_width_in_luma_samples));
+  // pic_height_in_luma_samples: ue(v)
+  RETURN_FALSE_ON_FAIL(parser.ReadExponentialGolomb(&pic_height_in_luma_samples));
+  // conformance_window_flag: u(1)
+  uint32_t conformance_window_flag = 0;
+  RETURN_FALSE_ON_FAIL(parser.ReadBits(&conformance_window_flag, 1));
+
+  uint32_t conf_win_left_offset = 0;
+  uint32_t conf_win_right_offset = 0;
+  uint32_t conf_win_top_offset = 0;
+  uint32_t conf_win_bottom_offset = 0;
+  if (conformance_window_flag) {
+      // conf_win_left_offset: ue(v)
+      RETURN_FALSE_ON_FAIL(parser.ReadExponentialGolomb(&conf_win_left_offset));
+      // conf_win_right_offset: ue(v)
+      RETURN_FALSE_ON_FAIL(parser.ReadExponentialGolomb(&conf_win_right_offset));
+      // conf_win_top_offset: ue(v)
+      RETURN_FALSE_ON_FAIL(parser.ReadExponentialGolomb(&conf_win_top_offset));
+      // conf_win_bottom_offset: ue(v)
+      RETURN_FALSE_ON_FAIL(parser.ReadExponentialGolomb(&conf_win_bottom_offset));
+  }
+
+  //For enough to get the resolution information. calcaluate according to HEVC spec 7.4.3.2
+  int width = 0;
+  int height = 0;
+
+  width = pic_width_in_luma_samples;
+  height = pic_height_in_luma_samples;
+
+  if (conformance_window_flag) {
+    int sub_width_c = ((1 == chroma_format_idc) || (2 == chroma_format_idc)) &&
+                        (0 == separate_colour_plane_flag) ? 2 : 1;
+    int sub_height_c = (1 == chroma_format_idc) && (0 == separate_colour_plane_flag) ? 2 : 1;
+    //the offset includes the pixel within conformance window. so don't need to +1 as per spec
+    width -= sub_width_c*(conf_win_right_offset + conf_win_left_offset);
+    height -= sub_height_c*(conf_win_top_offset + conf_win_bottom_offset);
+  }
+
+  width_ = width;
+  height_ = height;
+  return true;
+
+}
+
+}  // namespace webrtc
\ No newline at end of file
diff --git a/modules/rtp_rtcp/source/h265_sps_parser.h b/modules/rtp_rtcp/source/h265_sps_parser.h
new file mode 100644
index 0000000000..1e62b58977
--- /dev/null
+++ b/modules/rtp_rtcp/source/h265_sps_parser.h
@@ -0,0 +1,34 @@
+/*
+ *  Intel License
+ * See https://01.org/open-webrtc-toolkit
+ * This is released under Apache License 2.0 and it is free for both academic and commercial use.
+ */
+
+#ifndef WEBRTC_MODULES_RTP_RTCP_SOURCE_H265_SPS_PARSER_H_
+#define WEBRTC_MODULES_RTP_RTCP_SOURCE_H265_SPS_PARSER_H_
+
+#include <stddef.h>
+#include <stdint.h>
+
+namespace webrtc {
+
+// A class for parsing out sequence parameter set (SPS) data from an H265 NALU.
+// Currently, only resolution is read without being ignored.
+class H265SpsParser {
+ public:
+  H265SpsParser(const uint8_t* sps, size_t byte_length);
+  // Parses the SPS to completion. Returns true if the SPS was parsed correctly.
+  bool Parse();
+  uint16_t width() { return width_; }
+  uint16_t height() { return height_; }
+
+ private:
+  const uint8_t* const sps_;
+  const size_t byte_length_;
+
+  uint16_t width_;
+  uint16_t height_;
+};
+
+}  // namespace webrtc
+#endif  // WEBRTC_MODULES_RTP_RTCP_SOURCE_H265_SPS_PARSER_H_
\ No newline at end of file
diff --git a/modules/rtp_rtcp/source/rtp_format.cc b/modules/rtp_rtcp/source/rtp_format.cc
index 28f63f1109..d0bb2353fc 100644
--- a/modules/rtp_rtcp/source/rtp_format.cc
+++ b/modules/rtp_rtcp/source/rtp_format.cc
@@ -14,11 +14,13 @@
 
 #include "absl/types/variant.h"
 #include "modules/rtp_rtcp/source/rtp_format_h264.h"
+#include "modules/rtp_rtcp/source/rtp_format_h265.h"
 #include "modules/rtp_rtcp/source/rtp_format_video_generic.h"
 #include "modules/rtp_rtcp/source/rtp_format_vp8.h"
 #include "modules/rtp_rtcp/source/rtp_format_vp9.h"
 #include "modules/rtp_rtcp/source/rtp_packetizer_av1.h"
 #include "modules/video_coding/codecs/h264/include/h264_globals.h"
+#include "modules/video_coding/codecs/h265/include/h265_globals.h"
 #include "modules/video_coding/codecs/vp8/include/vp8_globals.h"
 #include "modules/video_coding/codecs/vp9/include/vp9_globals.h"
 #include "rtc_base/checks.h"
@@ -45,6 +47,13 @@ std::unique_ptr<RtpPacketizer> RtpPacketizer::Create(
       return std::make_unique<RtpPacketizerH264>(
           payload, limits, h264.packetization_mode, *fragmentation);
     }
+    case kVideoCodecH265: {
+      RTC_CHECK(fragmentation);
+      const auto& h265 =
+          absl::get<RTPVideoHeaderH265>(rtp_video_header.video_type_header);
+      return absl::make_unique<RtpPacketizerH265>(
+          payload, limits, h265.packetization_mode, *fragmentation);
+    }
     case kVideoCodecVP8: {
       const auto& vp8 =
           absl::get<RTPVideoHeaderVP8>(rtp_video_header.video_type_header);
diff --git a/modules/rtp_rtcp/source/rtp_format_h265.cc b/modules/rtp_rtcp/source/rtp_format_h265.cc
new file mode 100644
index 0000000000..19f7104545
--- /dev/null
+++ b/modules/rtp_rtcp/source/rtp_format_h265.cc
@@ -0,0 +1,651 @@
+/*
+ *  Intel License
+ * See https://01.org/open-webrtc-toolkit
+ * This is released under Apache License 2.0 and it is free for both academic and commercial use.
+ */
+
+#include <string.h>
+
+#include "common_video/h264/h264_common.h"
+#include "common_video/h265/h265_common.h"
+#include "common_video/h265/h265_pps_parser.h"
+#include "common_video/h265/h265_sps_parser.h"
+#include "common_video/h265/h265_vps_parser.h"
+#include "modules/include/module_common_types.h"
+#include "modules/rtp_rtcp/source/byte_io.h"
+#include "modules/rtp_rtcp/source/rtp_format_h265.h"
+#include "modules/rtp_rtcp/source/rtp_packet_to_send.h"
+#include "rtc_base/logging.h"
+using namespace rtc;
+
+namespace webrtc {
+namespace {
+
+enum NaluType {
+  kTrailN = 0,
+  kTrailR = 1,
+  kTsaN = 2,
+  kTsaR = 3,
+  kStsaN = 4,
+  kStsaR = 5,
+  kRadlN = 6,
+  kRadlR = 7,
+  kBlaWLp = 16,
+  kBlaWRadl = 17,
+  kBlaNLp = 18,
+  kIdrWRadl = 19,
+  kIdrNLp = 20,
+  kCra = 21,
+  kVps = 32,
+  kHevcSps = 33,
+  kHevcPps = 34,
+  kHevcAud = 35,
+  kPrefixSei = 39,
+  kSuffixSei = 40,
+  kHevcAp = 48,
+  kHevcFu = 49
+};
+
+/*
+   0                   1                   2                   3
+   0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1
+  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+  |    PayloadHdr (Type=49)       |   FU header   | DONL (cond)   |
+  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-|
+*/
+// Unlike H.264, HEVC NAL header is 2-bytes.
+static const size_t kHevcNalHeaderSize = 2;
+// H.265's FU is constructed of 2-byte payload header, and 1-byte FU header
+static const size_t kHevcFuHeaderSize = 1;
+static const size_t kHevcLengthFieldSize = 2;
+static const size_t kHevcApHeaderSize =
+    kHevcNalHeaderSize + kHevcLengthFieldSize;
+
+enum HevcNalHdrMasks {
+  kHevcFBit = 0x80,
+  kHevcTypeMask = 0x7E,
+  kHevcLayerIDHMask = 0x1,
+  kHevcLayerIDLMask = 0xF8,
+  kHevcTIDMask = 0x7,
+  kHevcTypeMaskN = 0x81,
+  kHevcTypeMaskInFuHeader = 0x3F
+};
+
+// Bit masks for FU headers.
+enum HevcFuDefs { kHevcSBit = 0x80, kHevcEBit = 0x40, kHevcFuTypeBit = 0x3F };
+
+// TODO(pbos): Avoid parsing this here as well as inside the jitter buffer.
+bool ParseApStartOffsets(const uint8_t* nalu_ptr,
+                         size_t length_remaining,
+                         std::vector<size_t>* offsets) {
+  size_t offset = 0;
+  while (length_remaining > 0) {
+    // Buffer doesn't contain room for additional nalu length.
+    if (length_remaining < sizeof(uint16_t))
+      return false;
+    uint16_t nalu_size = ByteReader<uint16_t>::ReadBigEndian(nalu_ptr);
+    nalu_ptr += sizeof(uint16_t);
+    length_remaining -= sizeof(uint16_t);
+    if (nalu_size > length_remaining)
+      return false;
+    nalu_ptr += nalu_size;
+    length_remaining -= nalu_size;
+
+    offsets->push_back(offset + kHevcApHeaderSize);
+    offset += kHevcLengthFieldSize + nalu_size;
+  }
+  return true;
+}
+
+}  // namespace
+
+RtpPacketizerH265::RtpPacketizerH265(
+    rtc::ArrayView<const uint8_t> payload,
+    PayloadSizeLimits limits,
+    H265PacketizationMode packetization_mode,
+    const RTPFragmentationHeader& fragmentation)
+    : limits_(limits),
+      num_packets_left_(0) {
+  // Guard against uninitialized memory in packetization_mode.
+  RTC_CHECK(packetization_mode == H265PacketizationMode::NonInterleaved ||
+            packetization_mode == H265PacketizationMode::SingleNalUnit);
+
+  for (size_t i = 0; i < fragmentation.fragmentationVectorSize; ++i) {
+    const uint8_t* fragment =
+        payload.data() + fragmentation.fragmentationOffset[i];
+    const size_t fragment_length = fragmentation.fragmentationLength[i];
+    input_fragments_.push_back(Fragment(fragment, fragment_length));
+  }
+
+  if (!GeneratePackets(packetization_mode)) {
+    // If failed to generate all the packets, discard already generated
+    // packets in case the caller would ignore return value and still try to
+    // call NextPacket().
+    num_packets_left_ = 0;
+    while (!packets_.empty()) {
+      packets_.pop();
+    }
+  }
+}
+
+RtpPacketizerH265::~RtpPacketizerH265() {}
+
+size_t RtpPacketizerH265::NumPackets() const {
+  return num_packets_left_;
+}
+
+RtpPacketizerH265::Fragment::Fragment(const uint8_t* buffer, size_t length)
+    : buffer(buffer), length(length) {}
+RtpPacketizerH265::Fragment::Fragment(const Fragment& fragment)
+    : buffer(fragment.buffer), length(fragment.length) {}
+
+
+bool RtpPacketizerH265::GeneratePackets(
+    H265PacketizationMode packetization_mode) {
+  // For HEVC we follow non-interleaved mode for the packetization,
+  // and don't support single-nalu mode at present.
+  for (size_t i = 0; i < input_fragments_.size();) {
+    int fragment_len = input_fragments_[i].length;
+    int single_packet_capacity = limits_.max_payload_len;
+    if (input_fragments_.size() == 1)
+      single_packet_capacity -= limits_.single_packet_reduction_len;
+    else if (i == 0)
+      single_packet_capacity -= limits_.first_packet_reduction_len;
+    else if (i + 1 == input_fragments_.size()) {
+      // Pretend that last fragment is larger instead of making last packet
+      // smaller.
+      single_packet_capacity -= limits_.last_packet_reduction_len;
+    }
+    if (fragment_len > single_packet_capacity) {
+      PacketizeFu(i);
+      ++i;
+    } else {
+      PacketizeSingleNalu(i);
+      ++i;
+    }
+  }
+  return true;
+}
+
+bool RtpPacketizerH265::PacketizeFu(size_t fragment_index) {
+  // Fragment payload into packets (FU).
+  // Strip out the original header and leave room for the FU header.
+  const Fragment& fragment = input_fragments_[fragment_index];
+  PayloadSizeLimits limits = limits_;
+  limits.max_payload_len -= kHevcFuHeaderSize + kHevcNalHeaderSize;
+
+  // Update single/first/last packet reductions unless it is single/first/last
+  // fragment.
+  if (input_fragments_.size() != 1) {
+    // if this fragment is put into a single packet, it might still be the
+    // first or the last packet in the whole sequence of packets.
+    if (fragment_index == input_fragments_.size() - 1) {
+      limits.single_packet_reduction_len = limits_.last_packet_reduction_len;
+    } else if (fragment_index == 0) {
+      limits.single_packet_reduction_len = limits_.first_packet_reduction_len;
+    } else {
+      limits.single_packet_reduction_len = 0;
+    }
+  }
+  if (fragment_index != 0)
+    limits.first_packet_reduction_len = 0;
+  if (fragment_index != input_fragments_.size() - 1)
+    limits.last_packet_reduction_len = 0;
+
+  // Strip out the original header.
+  size_t payload_left = fragment.length - kHevcNalHeaderSize;
+  int offset = kHevcNalHeaderSize;
+
+  std::vector<int> payload_sizes = SplitAboutEqually(payload_left, limits);
+  if (payload_sizes.empty())
+    return false;
+
+  for (size_t i = 0; i < payload_sizes.size(); ++i) {
+    int packet_length = payload_sizes[i];
+    RTC_CHECK_GT(packet_length, 0);
+    uint16_t header = (fragment.buffer[0] << 8) | fragment.buffer[1];
+    packets_.push(PacketUnit(Fragment(fragment.buffer + offset, packet_length),
+                             /*first_fragment=*/i == 0,
+                             /*last_fragment=*/i == payload_sizes.size() - 1,
+                             false, header));
+    offset += packet_length;
+    payload_left -= packet_length;
+  }
+  num_packets_left_ += payload_sizes.size();
+  RTC_CHECK_EQ(0, payload_left);
+  return true;
+}
+
+
+bool RtpPacketizerH265::PacketizeSingleNalu(size_t fragment_index) {
+  // Add a single NALU to the queue, no aggregation.
+  size_t payload_size_left = limits_.max_payload_len;
+  if (input_fragments_.size() == 1)
+    payload_size_left -= limits_.single_packet_reduction_len;
+  else if (fragment_index == 0)
+    payload_size_left -= limits_.first_packet_reduction_len;
+  else if (fragment_index + 1 == input_fragments_.size())
+    payload_size_left -= limits_.last_packet_reduction_len;
+  const Fragment* fragment = &input_fragments_[fragment_index];
+  if (payload_size_left < fragment->length) {
+    RTC_LOG(LS_ERROR) << "Failed to fit a fragment to packet in SingleNalu "
+                         "packetization mode. Payload size left "
+                      << payload_size_left << ", fragment length "
+                      << fragment->length << ", packet capacity "
+                      << limits_.max_payload_len;
+    return false;
+  }
+  RTC_CHECK_GT(fragment->length, 0u);
+  packets_.push(PacketUnit(*fragment, true /* first */, true /* last */,
+                           false /* aggregated */, fragment->buffer[0]));
+  ++num_packets_left_;
+  return true;
+}
+
+int RtpPacketizerH265::PacketizeAp(size_t fragment_index) {
+  // Aggregate fragments into one packet (STAP-A).
+  size_t payload_size_left = limits_.max_payload_len;
+  if (input_fragments_.size() == 1)
+    payload_size_left -= limits_.single_packet_reduction_len;
+  else if (fragment_index == 0)
+    payload_size_left -= limits_.first_packet_reduction_len;
+  int aggregated_fragments = 0;
+  size_t fragment_headers_length = 0;
+  const Fragment* fragment = &input_fragments_[fragment_index];
+  RTC_CHECK_GE(payload_size_left, fragment->length);
+  ++num_packets_left_;
+
+  auto payload_size_needed = [&] {
+    size_t fragment_size = fragment->length + fragment_headers_length;
+    if (input_fragments_.size() == 1) {
+      // Single fragment, single packet, payload_size_left already adjusted
+      // with limits_.single_packet_reduction_len.
+      return fragment_size;
+    }
+    if (fragment_index == input_fragments_.size() - 1) {
+      // Last fragment, so StrapA might be the last packet.
+      return fragment_size + limits_.last_packet_reduction_len;
+    }
+    return fragment_size;
+  };
+
+  while (payload_size_left >= payload_size_needed()) {
+    RTC_CHECK_GT(fragment->length, 0);
+    packets_.push(PacketUnit(*fragment, aggregated_fragments == 0, false, true,
+                             fragment->buffer[0]));
+    payload_size_left -= fragment->length;
+    payload_size_left -= fragment_headers_length;
+
+    fragment_headers_length = kHevcLengthFieldSize;
+    // If we are going to try to aggregate more fragments into this packet
+    // we need to add the STAP-A NALU header and a length field for the first
+    // NALU of this packet.
+    if (aggregated_fragments == 0)
+      fragment_headers_length += kHevcNalHeaderSize + kHevcLengthFieldSize;
+    ++aggregated_fragments;
+
+    // Next fragment.
+    ++fragment_index;
+    if (fragment_index == input_fragments_.size())
+      break;
+    fragment = &input_fragments_[fragment_index];
+  }
+  RTC_CHECK_GT(aggregated_fragments, 0);
+  packets_.back().last_fragment = true;
+  return fragment_index;
+}
+
+bool RtpPacketizerH265::NextPacket(RtpPacketToSend* rtp_packet) {
+  RTC_DCHECK(rtp_packet);
+
+  if (packets_.empty()) {
+    return false;
+  }
+
+  PacketUnit packet = packets_.front();
+
+  if (packet.first_fragment && packet.last_fragment) {
+    // Single NAL unit packet.
+    size_t bytes_to_send = packet.source_fragment.length;
+    uint8_t* buffer = rtp_packet->AllocatePayload(bytes_to_send);
+    memcpy(buffer, packet.source_fragment.buffer, bytes_to_send);
+    packets_.pop();
+    input_fragments_.pop_front();
+  } else if (packet.aggregated) {
+    bool is_last_packet = num_packets_left_ == 1;
+    NextAggregatePacket(rtp_packet, is_last_packet);
+  } else {
+    NextFragmentPacket(rtp_packet);
+  }
+  rtp_packet->SetMarker(packets_.empty());
+  --num_packets_left_;
+  return true;
+}
+
+void RtpPacketizerH265::NextAggregatePacket(RtpPacketToSend* rtp_packet,
+                                            bool last) {
+  size_t payload_capacity = rtp_packet->FreeCapacity();
+  RTC_CHECK_GE(payload_capacity, kHevcNalHeaderSize);
+  uint8_t* buffer = rtp_packet->AllocatePayload(payload_capacity);
+
+  PacketUnit* packet = &packets_.front();
+  RTC_CHECK(packet->first_fragment);
+  uint8_t payload_hdr_h = packet->header >> 8;
+  uint8_t payload_hdr_l = packet->header & 0xFF;
+  uint8_t layer_id_h = payload_hdr_h & kHevcLayerIDHMask;
+
+  payload_hdr_h =
+      (payload_hdr_h & kHevcTypeMaskN) | (kHevcAp << 1) | layer_id_h;
+
+  buffer[0] = payload_hdr_h;
+  buffer[1] = payload_hdr_l;
+  int index = kHevcNalHeaderSize;
+  bool is_last_fragment = packet->last_fragment;
+  while (packet->aggregated) {
+    // Add NAL unit length field.
+    const Fragment& fragment = packet->source_fragment;
+    ByteWriter<uint16_t>::WriteBigEndian(&buffer[index], fragment.length);
+    index += kHevcLengthFieldSize;
+    // Add NAL unit.
+    memcpy(&buffer[index], fragment.buffer, fragment.length);
+    index += fragment.length;
+    packets_.pop();
+    input_fragments_.pop_front();
+    if (is_last_fragment)
+      break;
+    packet = &packets_.front();
+    is_last_fragment = packet->last_fragment;
+  }
+  RTC_CHECK(is_last_fragment);
+  rtp_packet->SetPayloadSize(index);
+}
+
+void RtpPacketizerH265::NextFragmentPacket(RtpPacketToSend* rtp_packet) {
+  PacketUnit* packet = &packets_.front();
+  // NAL unit fragmented over multiple packets (FU).
+  // We do not send original NALU header, so it will be replaced by the
+  // PayloadHdr of the first packet.
+  uint8_t payload_hdr_h =
+      packet->header >> 8;  // 1-bit F, 6-bit type, 1-bit layerID highest-bit
+  uint8_t payload_hdr_l = packet->header & 0xFF;
+  uint8_t layer_id_h = payload_hdr_h & kHevcLayerIDHMask;
+  uint8_t fu_header = 0;
+  // S | E |6 bit type.
+  fu_header |= (packet->first_fragment ? kHevcSBit : 0);
+  fu_header |= (packet->last_fragment ? kHevcEBit : 0);
+  uint8_t type = (payload_hdr_h & kHevcTypeMask) >> 1;
+  fu_header |= type;
+  // Now update payload_hdr_h with FU type.
+  payload_hdr_h =
+      (payload_hdr_h & kHevcTypeMaskN) | (kHevcFu << 1) | layer_id_h;
+  const Fragment& fragment = packet->source_fragment;
+  uint8_t* buffer = rtp_packet->AllocatePayload(
+      kHevcFuHeaderSize + kHevcNalHeaderSize + fragment.length);
+  buffer[0] = payload_hdr_h;
+  buffer[1] = payload_hdr_l;
+  buffer[2] = fu_header;
+
+  if (packet->last_fragment) {
+    memcpy(buffer + kHevcFuHeaderSize + kHevcNalHeaderSize, fragment.buffer,
+           fragment.length);
+  } else {
+    memcpy(buffer + kHevcFuHeaderSize + kHevcNalHeaderSize, fragment.buffer,
+           fragment.length);
+  }
+  packets_.pop();
+}
+
+absl::optional<VideoRtpDepacketizer::ParsedRtpPayload> VideoRtpDepacketizerH265::Parse(
+                                rtc::CopyOnWriteBuffer rtp_payload) {
+  size_t payload_data_length = rtp_payload.size();
+  if (payload_data_length == 0) {
+    RTC_LOG(LS_ERROR) << "Empty payload.";
+    return absl::nullopt;
+  }
+
+  ParsedRtpPayload parsed_payload;
+
+  uint8_t* payload_data = rtp_payload.data();
+
+  offset_ = 0;
+  length_ = payload_data_length;
+  modified_buffer_.reset();
+
+  uint8_t nal_type = (payload_data[0] & kHevcTypeMask) >> 1;
+  parsed_payload.video_header
+      .video_type_header.emplace<RTPVideoHeaderH265>();
+
+  if (nal_type == H265::NaluType::kFU) {
+    // Fragmented NAL units (FU-A).
+    if (!ParseFuNalu(&parsed_payload, payload_data))
+      return absl::nullopt;
+  } else {
+    // We handle STAP-A and single NALU's the same way here. The jitter buffer
+    // will depacketize the STAP-A into NAL units later.
+    // TODO(sprang): Parse STAP-A offsets here and store in fragmentation vec.
+    if (!ProcessApOrSingleNalu(&parsed_payload, payload_data))
+      return absl::nullopt;
+  }
+
+  const uint8_t* payload =
+      modified_buffer_ ? modified_buffer_->data() : payload_data;
+
+  parsed_payload.video_payload = { payload + offset_, length_ };
+  return parsed_payload;
+}
+
+bool VideoRtpDepacketizerH265::ProcessApOrSingleNalu(
+    ParsedRtpPayload* parsed_payload,
+    const uint8_t* payload_data) {
+  parsed_payload->video_header.width = 0;
+  parsed_payload->video_header.height = 0;
+  parsed_payload->video_header.codec = kVideoCodecH265;
+  parsed_payload->video_header.is_first_packet_in_frame = true;
+  auto& h265_header = absl::get<RTPVideoHeaderH265>(
+      parsed_payload->video_header.video_type_header);
+
+  const uint8_t* nalu_start = payload_data + kHevcNalHeaderSize;
+  const size_t nalu_length = length_ - kHevcNalHeaderSize;
+  uint8_t nal_type = (payload_data[0] & kHevcTypeMask) >> 1;
+  std::vector<size_t> nalu_start_offsets;
+  if (nal_type == H265::NaluType::kAP) {
+    // Skip the StapA header (StapA NAL type + length).
+    if (length_ <= kHevcApHeaderSize) {
+      RTC_LOG(LS_ERROR) << "AP header truncated.";
+      return false;
+    }
+
+    if (!ParseApStartOffsets(nalu_start, nalu_length, &nalu_start_offsets)) {
+      RTC_LOG(LS_ERROR) << "AP packet with incorrect NALU packet lengths.";
+      return false;
+    }
+
+    h265_header.packetization_type = kH265AP;
+    // nal_type = (payload_data[kHevcApHeaderSize] & kHevcTypeMask) >> 1;
+  } else {
+    h265_header.packetization_type = kH265SingleNalu;
+    nalu_start_offsets.push_back(0);
+  }
+  h265_header.nalu_type = nal_type;
+  parsed_payload->video_header.frame_type = VideoFrameType::kVideoFrameDelta;
+
+  nalu_start_offsets.push_back(length_ + kHevcLengthFieldSize);  // End offset.
+  for (size_t i = 0; i < nalu_start_offsets.size() - 1; ++i) {
+    size_t start_offset = nalu_start_offsets[i];
+    // End offset is actually start offset for next unit, excluding length field
+    // so remove that from this units length.
+    size_t end_offset = nalu_start_offsets[i + 1] - kHevcLengthFieldSize;
+    if (end_offset - start_offset < kHevcNalHeaderSize) {  // Same as H.264.
+      RTC_LOG(LS_ERROR) << "AP packet too short";
+      return false;
+    }
+
+    H265NaluInfo nalu;
+    nalu.type = (payload_data[start_offset] & kHevcTypeMask) >> 1;
+    nalu.vps_id = -1;
+    nalu.sps_id = -1;
+    nalu.pps_id = -1;
+    start_offset += kHevcNalHeaderSize;
+    switch (nalu.type) {
+      case H265::NaluType::kVps: {
+        absl::optional<H265VpsParser::VpsState> vps = H265VpsParser::ParseVps(
+            &payload_data[start_offset], end_offset - start_offset);
+        if (vps) {
+          nalu.vps_id = vps->id;
+        } else {
+          RTC_LOG(LS_WARNING) << "Failed to parse VPS id from VPS slice.";
+        }
+        break;
+      }
+      case H265::NaluType::kSps: {
+        // Check if VUI is present in SPS and if it needs to be modified to
+        // avoid excessive decoder latency.
+
+        // Copy any previous data first (likely just the first header).
+        std::unique_ptr<rtc::Buffer> output_buffer(new rtc::Buffer());
+        if (start_offset)
+          output_buffer->AppendData(payload_data, start_offset);
+
+        absl::optional<H265SpsParser::SpsState> sps = H265SpsParser::ParseSps(
+            &payload_data[start_offset], end_offset - start_offset);
+
+        if (sps) {
+          parsed_payload->video_header.width = sps->width;
+          parsed_payload->video_header.height = sps->height;
+          nalu.sps_id = sps->id;
+          nalu.vps_id = sps->vps_id;
+        } else {
+          RTC_LOG(LS_WARNING)
+              << "Failed to parse SPS and VPS id from SPS slice.";
+        }
+        parsed_payload->video_header.frame_type = VideoFrameType::kVideoFrameKey;
+        break;
+      }
+      case H265::NaluType::kPps: {
+        uint32_t pps_id;
+        uint32_t sps_id;
+        if (H265PpsParser::ParsePpsIds(&payload_data[start_offset],
+                                       end_offset - start_offset, &pps_id,
+                                       &sps_id)) {
+          nalu.pps_id = pps_id;
+          nalu.sps_id = sps_id;
+        } else {
+          RTC_LOG(LS_WARNING)
+              << "Failed to parse PPS id and SPS id from PPS slice.";
+        }
+        break;
+      }
+      case H265::NaluType::kIdrWRadl:
+      case H265::NaluType::kIdrNLp:
+      case H265::NaluType::kCra:
+        parsed_payload->video_header.frame_type = VideoFrameType::kVideoFrameKey;
+        ABSL_FALLTHROUGH_INTENDED;
+      case H265::NaluType::kTrailN:
+      case H265::NaluType::kTrailR: {
+        absl::optional<uint32_t> pps_id =
+            H265PpsParser::ParsePpsIdFromSliceSegmentLayerRbsp(
+                &payload_data[start_offset], end_offset - start_offset,
+                nalu.type);
+        if (pps_id) {
+          nalu.pps_id = *pps_id;
+        } else {
+          RTC_LOG(LS_WARNING) << "Failed to parse PPS id from slice of type: "
+                              << static_cast<int>(nalu.type);
+        }
+        break;
+      }
+      // Slices below don't contain SPS or PPS ids.
+      case H265::NaluType::kAud:
+      case H265::NaluType::kTsaN:
+      case H265::NaluType::kTsaR:
+      case H265::NaluType::kStsaN:
+      case H265::NaluType::kStsaR:
+      case H265::NaluType::kRadlN:
+      case H265::NaluType::kRadlR:
+      case H265::NaluType::kBlaWLp:
+      case H265::NaluType::kBlaWRadl:
+      case H265::NaluType::kPrefixSei:
+      case H265::NaluType::kSuffixSei:
+        break;
+      case H265::NaluType::kAP:
+      case H265::NaluType::kFU:
+        RTC_LOG(LS_WARNING) << "Unexpected AP or FU received.";
+        return false;
+    }
+
+    if (h265_header.nalus_length == kMaxNalusPerPacket) {
+      RTC_LOG(LS_WARNING)
+          << "Received packet containing more than " << kMaxNalusPerPacket
+          << " NAL units. Will not keep track sps and pps ids for all of them.";
+    } else {
+      h265_header.nalus[h265_header.nalus_length++] = nalu;
+    }
+  }
+  return true;
+}
+
+bool VideoRtpDepacketizerH265::ParseFuNalu(
+    ParsedRtpPayload* parsed_payload,
+    const uint8_t* payload_data) {
+  if (length_ < kHevcFuHeaderSize + kHevcNalHeaderSize) {
+    RTC_LOG(LS_ERROR) << "FU NAL units truncated.";
+    return false;
+  }
+  uint8_t f = payload_data[0] & kHevcFBit;
+  uint8_t layer_id_h = payload_data[0] & kHevcLayerIDHMask;
+  uint8_t layer_id_l_unshifted = payload_data[1] & kHevcLayerIDLMask;
+  uint8_t tid = payload_data[1] & kHevcTIDMask;
+
+  uint8_t original_nal_type = payload_data[2] & kHevcTypeMaskInFuHeader;
+  bool first_fragment = payload_data[2] & kHevcSBit;
+  H265NaluInfo nalu;
+  nalu.type = original_nal_type;
+  nalu.vps_id = -1;
+  nalu.sps_id = -1;
+  nalu.pps_id = -1;
+  if (first_fragment) {
+    offset_ = 1;
+    length_ -= 1;
+    absl::optional<uint32_t> pps_id =
+        H265PpsParser::ParsePpsIdFromSliceSegmentLayerRbsp(
+            payload_data + kHevcNalHeaderSize + kHevcFuHeaderSize,
+            length_ - kHevcFuHeaderSize, nalu.type);
+    if (pps_id) {
+      nalu.pps_id = *pps_id;
+    } else {
+      RTC_LOG(LS_WARNING)
+          << "Failed to parse PPS from first fragment of FU NAL "
+             "unit with original type: "
+          << static_cast<int>(nalu.type);
+    }
+    uint8_t* payload = const_cast<uint8_t*>(payload_data + offset_);
+    payload[0] = f | original_nal_type << 1 | layer_id_h;
+    payload[1] = layer_id_l_unshifted | tid;
+  } else {
+    offset_ = kHevcNalHeaderSize + kHevcFuHeaderSize;
+    length_ -= (kHevcNalHeaderSize + kHevcFuHeaderSize);
+  }
+
+  if (original_nal_type == H265::NaluType::kIdrWRadl
+      || original_nal_type == H265::NaluType::kIdrNLp
+      || original_nal_type == H265::NaluType::kCra) {
+    parsed_payload->video_header.frame_type = VideoFrameType::kVideoFrameKey;
+  } else {
+    parsed_payload->video_header.frame_type = VideoFrameType::kVideoFrameDelta;
+  }
+  parsed_payload->video_header.width = 0;
+  parsed_payload->video_header.height = 0;
+  parsed_payload->video_header.codec = kVideoCodecH265;
+  parsed_payload->video_header.is_first_packet_in_frame = first_fragment;
+  auto& h265_header = absl::get<RTPVideoHeaderH265>(
+      parsed_payload->video_header.video_type_header);
+  h265_header.packetization_type = kH265FU;
+  h265_header.nalu_type = original_nal_type;
+  if (first_fragment) {
+    h265_header.nalus[h265_header.nalus_length] = nalu;
+    h265_header.nalus_length = 1;
+  }
+  return true;
+}
+
+}  // namespace webrtc
\ No newline at end of file
diff --git a/modules/rtp_rtcp/source/rtp_format_h265.h b/modules/rtp_rtcp/source/rtp_format_h265.h
new file mode 100644
index 0000000000..6bf0d80bec
--- /dev/null
+++ b/modules/rtp_rtcp/source/rtp_format_h265.h
@@ -0,0 +1,131 @@
+/*
+ *  Intel License
+ * See https://01.org/open-webrtc-toolkit
+ * This is released under Apache License 2.0 and it is free for both academic and commercial use.
+ */
+
+#ifndef WEBRTC_MODULES_RTP_RTCP_SOURCE_RTP_FORMAT_H265_H_
+#define WEBRTC_MODULES_RTP_RTCP_SOURCE_RTP_FORMAT_H265_H_
+
+#include <queue>
+#include <string>
+#include "api/array_view.h"
+#include "modules/include/module_common_types.h"
+#include "modules/rtp_rtcp/source/rtp_format.h"
+#include "modules/rtp_rtcp/source/rtp_packet_to_send.h"
+#include "modules/rtp_rtcp/source/rtp_format.h"
+#include "modules/rtp_rtcp/source/video_rtp_depacketizer.h"
+#include "modules/video_coding/codecs/h265/include/h265_globals.h"
+#include "rtc_base/buffer.h"
+#include "rtc_base/constructor_magic.h"
+
+namespace webrtc {
+
+class RtpPacketizerH265 : public RtpPacketizer {
+ public:
+  // Initialize with payload from encoder.
+  // The payload_data must be exactly one encoded H.265 frame.
+  RtpPacketizerH265(rtc::ArrayView<const uint8_t> payload,
+                    PayloadSizeLimits limits,
+                    H265PacketizationMode packetization_mode,
+                    const RTPFragmentationHeader& fragmentation);
+
+   ~RtpPacketizerH265() override;
+
+  size_t NumPackets() const override;
+
+  // Get the next payload with H.265 payload header.
+  // buffer is a pointer to where the output will be written.
+  // bytes_to_send is an output variable that will contain number of bytes
+  // written to buffer. The parameter last_packet is true for the last packet of
+  // the frame, false otherwise (i.e., call the function again to get the
+  // next packet).
+  // Returns true on success or false if there was no payload to packetize.
+  bool NextPacket(RtpPacketToSend* rtp_packet) override;
+
+ private:
+  struct Packet {
+    Packet(size_t offset,
+           size_t size,
+           bool first_fragment,
+           bool last_fragment,
+           bool aggregated,
+           uint16_t header)
+        : offset(offset),
+          size(size),
+          first_fragment(first_fragment),
+          last_fragment(last_fragment),
+          aggregated(aggregated),
+          header(header) {}
+
+    size_t offset;
+    size_t size;
+    bool first_fragment;
+    bool last_fragment;
+    bool aggregated;
+    uint16_t header;  // Different from H264
+  };
+  struct Fragment {
+    Fragment(const uint8_t* buffer, size_t length);
+    explicit Fragment(const Fragment& fragment);
+    const uint8_t* buffer = nullptr;
+    size_t length = 0;
+    std::unique_ptr<rtc::Buffer> tmp_buffer;
+  };
+  struct PacketUnit {
+    PacketUnit(const Fragment& source_fragment,
+               bool first_fragment,
+               bool last_fragment,
+               bool aggregated,
+               uint16_t header)
+        : source_fragment(source_fragment),
+          first_fragment(first_fragment),
+          last_fragment(last_fragment),
+          aggregated(aggregated),
+          header(header) {}
+
+    const Fragment source_fragment;
+    bool first_fragment;
+    bool last_fragment;
+    bool aggregated;
+    uint16_t header;
+  };
+  typedef std::queue<Packet> PacketQueue;
+  std::deque<Fragment> input_fragments_;
+  std::queue<PacketUnit> packets_;
+
+  bool GeneratePackets(H265PacketizationMode packetization_mode);
+  bool PacketizeFu(size_t fragment_index);
+  int PacketizeAp(size_t fragment_index);
+  bool PacketizeSingleNalu(size_t fragment_index);
+
+  void NextAggregatePacket(RtpPacketToSend* rtp_packet, bool last);
+  void NextFragmentPacket(RtpPacketToSend* rtp_packet);
+
+  const PayloadSizeLimits limits_;
+  size_t num_packets_left_;
+  RTPFragmentationHeader fragmentation_;
+
+  RTC_DISALLOW_COPY_AND_ASSIGN(RtpPacketizerH265);
+};
+
+// Depacketizer for H.265.
+class VideoRtpDepacketizerH265 : public VideoRtpDepacketizer {
+ public:
+  virtual ~VideoRtpDepacketizerH265() {}
+
+  absl::optional<ParsedRtpPayload> Parse(
+             rtc::CopyOnWriteBuffer rtp_payload) override;
+
+ private:
+  bool ParseFuNalu(ParsedRtpPayload* parsed_payload,
+                   const uint8_t* payload_data);
+  bool ProcessApOrSingleNalu(ParsedRtpPayload* parsed_payload,
+                             const uint8_t* payload_data);
+
+  size_t offset_;
+  size_t length_;
+  std::unique_ptr<rtc::Buffer> modified_buffer_;
+};
+}  // namespace webrtc
+#endif  // WEBRTC_MODULES_RTP_RTCP_SOURCE_RTP_FORMAT_H265_H_
\ No newline at end of file
diff --git a/modules/rtp_rtcp/source/rtp_sender_video.cc b/modules/rtp_rtcp/source/rtp_sender_video.cc
index 58a8699688..39aa82db6f 100644
--- a/modules/rtp_rtcp/source/rtp_sender_video.cc
+++ b/modules/rtp_rtcp/source/rtp_sender_video.cc
@@ -723,6 +723,7 @@ uint8_t RTPSenderVideo::GetTemporalId(const RTPVideoHeader& header) {
       return vp9.temporal_idx;
     }
     uint8_t operator()(const RTPVideoHeaderH264&) { return kNoTemporalIdx; }
+    uint8_t operator()(const RTPVideoHeaderH265&) { return kNoTemporalIdx; }
     uint8_t operator()(const RTPVideoHeaderLegacyGeneric&) {
       return kNoTemporalIdx;
     }
diff --git a/modules/rtp_rtcp/source/rtp_video_header.h b/modules/rtp_rtcp/source/rtp_video_header.h
index 514340add6..af1e225a6b 100644
--- a/modules/rtp_rtcp/source/rtp_video_header.h
+++ b/modules/rtp_rtcp/source/rtp_video_header.h
@@ -24,6 +24,7 @@
 #include "api/video/video_timing.h"
 #include "common_types.h"  // NOLINT(build/include_directory)
 #include "modules/video_coding/codecs/h264/include/h264_globals.h"
+#include "modules/video_coding/codecs/h265/include/h265_globals.h"
 #include "modules/video_coding/codecs/vp8/include/vp8_globals.h"
 #include "modules/video_coding/codecs/vp9/include/vp9_globals.h"
 
@@ -39,6 +40,7 @@ using RTPVideoTypeHeader = absl::variant<absl::monostate,
                                          RTPVideoHeaderVP8,
                                          RTPVideoHeaderVP9,
                                          RTPVideoHeaderH264,
+                                         RTPVideoHeaderH265,
                                          RTPVideoHeaderLegacyGeneric>;
 
 struct RTPVideoHeader {
diff --git a/modules/third_party/portaudio/BUILD.gn b/modules/third_party/portaudio/BUILD.gn
index c49c544e9d..a43f8a9e6a 100644
--- a/modules/third_party/portaudio/BUILD.gn
+++ b/modules/third_party/portaudio/BUILD.gn
@@ -10,6 +10,7 @@ import("../../../webrtc.gni")
 
 rtc_library("mac_portaudio") {
   visibility = [ "../../audio_device:*" ]
+  cflags = [ "-Wno-deprecated-declarations" ]
   sources = [
     "pa_memorybarrier.h",
     "pa_ringbuffer.c",
diff --git a/modules/video_coding/BUILD.gn b/modules/video_coding/BUILD.gn
index e92649d4e6..b28bbf5428 100644
--- a/modules/video_coding/BUILD.gn
+++ b/modules/video_coding/BUILD.gn
@@ -15,6 +15,12 @@ rtc_library("encoded_frame") {
     "encoded_frame.cc",
     "encoded_frame.h",
   ]
+
+  sources += [
+    "h265_vps_sps_pps_tracker.cc",
+    "h265_vps_sps_pps_tracker.h",
+  ]
+
   deps = [
     ":codec_globals_headers",
     ":video_codec_interface",
diff --git a/modules/video_coding/codecs/h265/include/h265_globals.h b/modules/video_coding/codecs/h265/include/h265_globals.h
new file mode 100644
index 0000000000..ad511d11d5
--- /dev/null
+++ b/modules/video_coding/codecs/h265/include/h265_globals.h
@@ -0,0 +1,62 @@
+/*
+ *  Copyright (c) 2018 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+// This file contains codec dependent definitions that are needed in
+// order to compile the WebRTC codebase, even if this codec is not used.
+
+#ifndef MODULES_VIDEO_CODING_CODECS_H265_INCLUDE_H265_GLOBALS_H_
+#define MODULES_VIDEO_CODING_CODECS_H265_INCLUDE_H265_GLOBALS_H_
+
+#ifndef DISABLE_H265
+
+#include "modules/video_coding/codecs/h264/include/h264_globals.h"
+
+namespace webrtc {
+
+// The packetization types that we support: single, aggregated, and fragmented.
+enum H265PacketizationTypes {
+  kH265SingleNalu,  // This packet contains a single NAL unit.
+  kH265AP,          // This packet contains aggregation Packet.
+                    // If this packet has an associated NAL unit type,
+                    // it'll be for the first such aggregated packet.
+  kH265FU,          // This packet contains a FU (fragmentation
+                    // unit) packet, meaning it is a part of a frame
+                    // that was too large to fit into a single packet.
+};
+
+struct H265NaluInfo {
+  uint8_t type;
+  int vps_id;
+  int sps_id;
+  int pps_id;
+};
+
+enum class H265PacketizationMode {
+  NonInterleaved = 0,  // Mode 1 - STAP-A, FU-A is allowed
+  SingleNalUnit        // Mode 0 - only single NALU allowed
+};
+
+struct RTPVideoHeaderH265 {
+  // The NAL unit type. If this is a header for a fragmented packet, it's the
+  // NAL unit type of the original data. If this is the header for an aggregated
+  // packet, it's the NAL unit type of the first NAL unit in the packet.
+  uint8_t nalu_type;
+  H265PacketizationTypes packetization_type;
+  H265NaluInfo nalus[kMaxNalusPerPacket];
+  size_t nalus_length;
+  // The packetization type of this buffer - single, aggregated or fragmented.
+  H265PacketizationMode packetization_mode;
+};
+
+}  // namespace webrtc
+
+#endif
+
+#endif  // MODULES_VIDEO_CODING_CODECS_H265_INCLUDE_H265_GLOBALS_H_
\ No newline at end of file
diff --git a/modules/video_coding/encoded_frame.cc b/modules/video_coding/encoded_frame.cc
index 3de62da9f5..b1183a70c5 100644
--- a/modules/video_coding/encoded_frame.cc
+++ b/modules/video_coding/encoded_frame.cc
@@ -137,6 +137,10 @@ void VCMEncodedFrame::CopyCodecSpecific(const RTPVideoHeader* header) {
         _codecSpecificInfo.codecType = kVideoCodecH264;
         break;
       }
+      case kVideoCodecH265: {
+        _codecSpecificInfo.codecType = kVideoCodecH265;
+        break;
+      }
       default: {
         _codecSpecificInfo.codecType = kVideoCodecGeneric;
         break;
diff --git a/modules/video_coding/h265_vps_sps_pps_tracker.cc b/modules/video_coding/h265_vps_sps_pps_tracker.cc
new file mode 100644
index 0000000000..ce77cebfc4
--- /dev/null
+++ b/modules/video_coding/h265_vps_sps_pps_tracker.cc
@@ -0,0 +1,312 @@
+/*
+ *  Copyright (c) 2018 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/video_coding/h265_vps_sps_pps_tracker.h"
+
+#include <string>
+#include <utility>
+
+#include "common_video/h264/h264_common.h"
+#include "common_video/h265/h265_common.h"
+#include "common_video/h265/h265_pps_parser.h"
+#include "common_video/h265/h265_sps_parser.h"
+#include "common_video/h265/h265_vps_parser.h"
+#include "modules/video_coding/codecs/h264/include/h264_globals.h"
+#include "modules/video_coding/codecs/h265/include/h265_globals.h"
+#include "modules/video_coding/frame_object.h"
+#include "modules/video_coding/packet_buffer.h"
+#include "rtc_base/checks.h"
+#include "rtc_base/logging.h"
+
+namespace webrtc {
+namespace video_coding {
+
+namespace {
+const uint8_t start_code_h265[] = {0, 0, 0, 1};
+}  // namespace
+
+H265VpsSpsPpsTracker::FixedBitstream H265VpsSpsPpsTracker::CopyAndFixBitstream(rtc::ArrayView<const uint8_t> bitstream,
+                                   RTPVideoHeader* video_header_pointer) {
+  const uint8_t* data = bitstream.data();
+  const size_t data_size = bitstream.size();
+  RTPVideoHeader& video_header = *video_header_pointer;
+  RTC_DCHECK(video_header.codec == kVideoCodecH264);
+
+  auto& h265_header =
+      absl::get<RTPVideoHeaderH265>(video_header.video_type_header);
+
+  bool append_vps_sps_pps = false;
+  auto vps = vps_data_.end();
+  auto sps = sps_data_.end();
+  auto pps = pps_data_.end();
+
+  for (size_t i = 0; i < h265_header.nalus_length; ++i) {
+    const H265NaluInfo& nalu = h265_header.nalus[i];
+    switch (nalu.type) {
+      case H265::NaluType::kVps: {
+        vps_data_[nalu.vps_id].size = 0;
+        break;
+      }
+      case H265::NaluType::kSps: {
+        sps_data_[nalu.sps_id].vps_id = nalu.vps_id;
+        sps_data_[nalu.sps_id].width = video_header.width;
+        sps_data_[nalu.sps_id].height = video_header.height;
+        break;
+      }
+      case H265::NaluType::kPps: {
+        pps_data_[nalu.pps_id].sps_id = nalu.sps_id;
+        break;
+      }
+      case H265::NaluType::kIdrWRadl:
+      case H265::NaluType::kIdrNLp:
+      case H265::NaluType::kCra: {
+        // If this is the first packet of an IDR, make sure we have the required
+        // SPS/PPS and also calculate how much extra space we need in the buffer
+        // to prepend the SPS/PPS to the bitstream with start codes.
+        if (video_header.is_first_packet_in_frame) {
+          if (nalu.pps_id == -1) {
+            RTC_LOG(LS_WARNING) << "No PPS id in IDR nalu.";
+            return {kRequestKeyframe};
+          }
+
+          pps = pps_data_.find(nalu.pps_id);
+          if (pps == pps_data_.end()) {
+            RTC_LOG(LS_WARNING)
+                << "No PPS with id " << nalu.pps_id << " received";
+            return {kRequestKeyframe};
+          }
+
+          sps = sps_data_.find(pps->second.sps_id);
+          if (sps == sps_data_.end()) {
+            RTC_LOG(LS_WARNING)
+                << "No SPS with id << " << pps->second.sps_id << " received";
+            return {kRequestKeyframe};
+          }
+
+          vps = vps_data_.find(sps->second.vps_id);
+          if (vps == vps_data_.end()) {
+            RTC_LOG(LS_WARNING)
+                << "No VPS with id " << sps->second.vps_id << " received";
+            return {kRequestKeyframe};
+          }
+
+          // Since the first packet of every keyframe should have its width and
+          // height set we set it here in the case of it being supplied out of
+          // band.
+          video_header.width = sps->second.width;
+          video_header.height = sps->second.height;
+
+          // If the VPS/SPS/PPS was supplied out of band then we will have saved
+          // the actual bitstream in |data|.
+          // This branch is not verified.
+          if (vps->second.data && sps->second.data && pps->second.data) {
+            RTC_DCHECK_GT(vps->second.size, 0);
+            RTC_DCHECK_GT(sps->second.size, 0);
+            RTC_DCHECK_GT(pps->second.size, 0);
+            append_vps_sps_pps = true;
+          }
+        }
+        break;
+      }
+      default:
+        break;
+    }
+  }
+
+  RTC_CHECK(!append_vps_sps_pps ||
+            (sps != sps_data_.end() && pps != pps_data_.end()));
+
+  // Calculate how much space we need for the rest of the bitstream.
+  size_t required_size = 0;
+
+  if (append_vps_sps_pps) {
+    required_size += vps->second.size + sizeof(start_code_h265);
+    required_size += sps->second.size + sizeof(start_code_h265);
+    required_size += pps->second.size + sizeof(start_code_h265);
+  }
+
+  if (h265_header.packetization_type == kH265AP) {
+    const uint8_t* nalu_ptr = data + 1;
+    while (nalu_ptr < data + data_size) {
+      RTC_DCHECK(video_header.is_first_packet_in_frame);
+      required_size += sizeof(start_code_h265);
+
+      // The first two bytes describe the length of a segment.
+      uint16_t segment_length = nalu_ptr[0] << 8 | nalu_ptr[1];
+      nalu_ptr += 2;
+
+      required_size += segment_length;
+      nalu_ptr += segment_length;
+    }
+  } else {
+    if (video_header.is_first_packet_in_frame)
+      required_size += sizeof(start_code_h265);
+    required_size += data_size;
+  }
+
+  // Then we copy to the new buffer.
+  FixedBitstream fixed;
+  fixed.bitstream.EnsureCapacity(required_size);
+
+  if (append_vps_sps_pps) {
+    // Insert VPS.
+    fixed.bitstream.AppendData(start_code_h265);
+    fixed.bitstream.AppendData(vps->second.data.get(), vps->second.size);
+
+    // Insert SPS.
+    fixed.bitstream.AppendData(start_code_h265);
+    fixed.bitstream.AppendData(sps->second.data.get(), sps->second.size);
+
+    // Insert PPS.
+    fixed.bitstream.AppendData(start_code_h265);
+    fixed.bitstream.AppendData(pps->second.data.get(), pps->second.size);
+
+    // Update codec header to reflect the newly added SPS and PPS.
+    H265NaluInfo vps_info;
+    vps_info.type = H265::NaluType::kVps;
+    vps_info.vps_id = vps->first;
+    vps_info.sps_id = -1;
+    vps_info.pps_id = -1;
+    H265NaluInfo sps_info;
+    sps_info.type = H265::NaluType::kSps;
+    sps_info.vps_id = vps->first;
+    sps_info.sps_id = sps->first;
+    sps_info.pps_id = -1;
+    H265NaluInfo pps_info;
+    pps_info.type = H265::NaluType::kPps;
+    pps_info.vps_id = vps->first;
+    pps_info.sps_id = sps->first;
+    pps_info.pps_id = pps->first;
+    if (h265_header.nalus_length + 2 <= kMaxNalusPerPacket) {
+      h265_header.nalus[h265_header.nalus_length++] = vps_info;
+      h265_header.nalus[h265_header.nalus_length++] = sps_info;
+      h265_header.nalus[h265_header.nalus_length++] = pps_info;
+    } else {
+      RTC_LOG(LS_WARNING) << "Not enough space in H.265 codec header to insert "
+                             "SPS/PPS provided out-of-band.";
+    }
+  }
+
+  // Copy the rest of the bitstream and insert start codes.
+  if (h265_header.packetization_type == kH265AP) {
+    const uint8_t* nalu_ptr = data + 1;
+    while (nalu_ptr < data + data_size) {
+      fixed.bitstream.AppendData(start_code_h265);
+
+      // The first two bytes describe the length of a segment.
+      uint16_t segment_length = nalu_ptr[0] << 8 | nalu_ptr[1];
+      nalu_ptr += 2;
+
+      size_t copy_end = nalu_ptr - data + segment_length;
+      if (copy_end > data_size) {
+        return {kDrop};
+      }
+
+      fixed.bitstream.AppendData(nalu_ptr, segment_length);
+      nalu_ptr += segment_length;
+    }
+  } else {
+    if (video_header.is_first_packet_in_frame) {
+      fixed.bitstream.AppendData(start_code_h265);
+    }
+    fixed.bitstream.AppendData(bitstream.data(), bitstream.size());
+  }
+
+  fixed.action = kInsert;
+  return fixed;
+}
+
+void H265VpsSpsPpsTracker::InsertVpsSpsPpsNalus(
+    const std::vector<uint8_t>& vps,
+    const std::vector<uint8_t>& sps,
+    const std::vector<uint8_t>& pps) {
+  constexpr size_t kNaluHeaderOffset = 1;
+  if (vps.size() < kNaluHeaderOffset) {
+    RTC_LOG(LS_WARNING) << "VPS size  " << vps.size() << " is smaller than "
+                        << kNaluHeaderOffset;
+    return;
+  }
+  if ((vps[0] & 0x7e) >> 1 != H265::NaluType::kSps) {
+    RTC_LOG(LS_WARNING) << "SPS Nalu header missing";
+    return;
+  }
+  if (sps.size() < kNaluHeaderOffset) {
+    RTC_LOG(LS_WARNING) << "SPS size  " << sps.size() << " is smaller than "
+                        << kNaluHeaderOffset;
+    return;
+  }
+  if ((sps[0] & 0x7e) >> 1 != H265::NaluType::kSps) {
+    RTC_LOG(LS_WARNING) << "SPS Nalu header missing";
+    return;
+  }
+  if (pps.size() < kNaluHeaderOffset) {
+    RTC_LOG(LS_WARNING) << "PPS size  " << pps.size() << " is smaller than "
+                        << kNaluHeaderOffset;
+    return;
+  }
+  if ((pps[0] & 0x7e) >> 1 != H265::NaluType::kPps) {
+    RTC_LOG(LS_WARNING) << "SPS Nalu header missing";
+    return;
+  }
+  absl::optional<H265VpsParser::VpsState> parsed_vps = H265VpsParser::ParseVps(
+      vps.data() + kNaluHeaderOffset, vps.size() - kNaluHeaderOffset);
+  absl::optional<H265SpsParser::SpsState> parsed_sps = H265SpsParser::ParseSps(
+      sps.data() + kNaluHeaderOffset, sps.size() - kNaluHeaderOffset);
+  absl::optional<H265PpsParser::PpsState> parsed_pps = H265PpsParser::ParsePps(
+      pps.data() + kNaluHeaderOffset, pps.size() - kNaluHeaderOffset);
+
+  if (!parsed_vps) {
+    RTC_LOG(LS_WARNING) << "Failed to parse VPS.";
+  }
+
+  if (!parsed_sps) {
+    RTC_LOG(LS_WARNING) << "Failed to parse SPS.";
+  }
+
+  if (!parsed_pps) {
+    RTC_LOG(LS_WARNING) << "Failed to parse PPS.";
+  }
+
+  if (!parsed_vps || !parsed_pps || !parsed_sps) {
+    return;
+  }
+
+  VpsInfo vps_info;
+  vps_info.size = vps.size();
+  uint8_t* vps_data = new uint8_t[vps_info.size];
+  memcpy(vps_data, vps.data(), vps_info.size);
+  vps_info.data.reset(vps_data);
+  vps_data_[parsed_vps->id] = std::move(vps_info);
+
+  SpsInfo sps_info;
+  sps_info.size = sps.size();
+  sps_info.width = parsed_sps->width;
+  sps_info.height = parsed_sps->height;
+  sps_info.vps_id = parsed_sps->vps_id;
+  uint8_t* sps_data = new uint8_t[sps_info.size];
+  memcpy(sps_data, sps.data(), sps_info.size);
+  sps_info.data.reset(sps_data);
+  sps_data_[parsed_sps->id] = std::move(sps_info);
+
+  PpsInfo pps_info;
+  pps_info.size = pps.size();
+  pps_info.sps_id = parsed_pps->sps_id;
+  uint8_t* pps_data = new uint8_t[pps_info.size];
+  memcpy(pps_data, pps.data(), pps_info.size);
+  pps_info.data.reset(pps_data);
+  pps_data_[parsed_pps->id] = std::move(pps_info);
+
+  RTC_LOG(LS_INFO) << "Inserted SPS id " << parsed_sps->id << " and PPS id "
+                   << parsed_pps->id << " (referencing SPS "
+                   << parsed_pps->sps_id << ")";
+}
+
+}  // namespace video_coding
+}  // namespace webrtc
\ No newline at end of file
diff --git a/modules/video_coding/h265_vps_sps_pps_tracker.h b/modules/video_coding/h265_vps_sps_pps_tracker.h
new file mode 100644
index 0000000000..252403eaa1
--- /dev/null
+++ b/modules/video_coding/h265_vps_sps_pps_tracker.h
@@ -0,0 +1,74 @@
+/*
+ *  Copyright (c) 2018 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef MODULES_VIDEO_CODING_H265_VPS_SPS_PPS_TRACKER_H_
+#define MODULES_VIDEO_CODING_H265_VPS_SPS_PPS_TRACKER_H_
+
+#include <cstdint>
+#include <map>
+#include <memory>
+#include <vector>
+
+#include "api/array_view.h"
+#include "modules/include/module_common_types.h"
+#include "modules/rtp_rtcp/source/rtp_video_header.h"
+#include "rtc_base/copy_on_write_buffer.h"
+
+namespace webrtc {
+
+class VCMPacket;
+
+namespace video_coding {
+
+class H265VpsSpsPpsTracker {
+ public:
+  enum PacketAction { kInsert, kDrop, kRequestKeyframe };
+  struct FixedBitstream {
+    PacketAction action;
+    rtc::CopyOnWriteBuffer bitstream;
+  };
+
+  // Returns fixed bitstream and modifies |video_header|.
+  FixedBitstream CopyAndFixBitstream(rtc::ArrayView<const uint8_t> bitstream,
+                                     RTPVideoHeader* video_header);
+
+  void InsertVpsSpsPpsNalus(const std::vector<uint8_t>& vps,
+                            const std::vector<uint8_t>& sps,
+                            const std::vector<uint8_t>& pps);
+
+ private:
+  struct VpsInfo {
+    size_t size = 0;
+    std::unique_ptr<uint8_t[]> data;
+  };
+
+  struct PpsInfo {
+    int sps_id = -1;
+    size_t size = 0;
+    std::unique_ptr<uint8_t[]> data;
+  };
+
+  struct SpsInfo {
+    int vps_id = -1;
+    size_t size = 0;
+    int width = -1;
+    int height = -1;
+    std::unique_ptr<uint8_t[]> data;
+  };
+
+  std::map<uint32_t, VpsInfo> vps_data_;
+  std::map<uint32_t, PpsInfo> pps_data_;
+  std::map<uint32_t, SpsInfo> sps_data_;
+};
+
+}  // namespace video_coding
+}  // namespace webrtc
+
+#endif  // MODULES_VIDEO_CODING_H264_SPS_PPS_TRACKER_H_
\ No newline at end of file
diff --git a/modules/video_coding/include/video_codec_interface.h b/modules/video_coding/include/video_codec_interface.h
index c7b116f4ae..6f58f72b9b 100644
--- a/modules/video_coding/include/video_codec_interface.h
+++ b/modules/video_coding/include/video_codec_interface.h
@@ -20,6 +20,7 @@
 #include "common_video/generic_frame_descriptor/generic_frame_info.h"
 #include "modules/include/module_common_types.h"
 #include "modules/video_coding/codecs/h264/include/h264_globals.h"
+#include "modules/video_coding/codecs/h265/include/h265_globals.h"
 #include "modules/video_coding/codecs/vp9/include/vp9_globals.h"
 #include "modules/video_coding/include/video_error_codes.h"
 #include "rtc_base/system/rtc_export.h"
@@ -92,10 +93,17 @@ struct CodecSpecificInfoH264 {
 };
 static_assert(std::is_pod<CodecSpecificInfoH264>::value, "");
 
+struct CodecSpecificInfoH265 {
+  H265PacketizationMode packetization_mode;
+  bool idr_frame;
+};
+// (check:tnoho)
+
 union CodecSpecificInfoUnion {
   CodecSpecificInfoVP8 VP8;
   CodecSpecificInfoVP9 VP9;
   CodecSpecificInfoH264 H264;
+  CodecSpecificInfoH265 H265;
 };
 static_assert(std::is_pod<CodecSpecificInfoUnion>::value, "");
 
diff --git a/modules/video_coding/jitter_buffer_common.h b/modules/video_coding/jitter_buffer_common.h
index 6ccfe39199..cd85127699 100644
--- a/modules/video_coding/jitter_buffer_common.h
+++ b/modules/video_coding/jitter_buffer_common.h
@@ -54,6 +54,7 @@ enum VCMFrameBufferStateEnum {
 };
 
 enum { kH264StartCodeLengthBytes = 4 };
+enum { kH265StartCodeLengthBytes = 4 };
 }  // namespace webrtc
 
 #endif  // MODULES_VIDEO_CODING_JITTER_BUFFER_COMMON_H_
diff --git a/modules/video_coding/packet.cc b/modules/video_coding/packet.cc
index 0c4a658b8f..cb7c7dc468 100644
--- a/modules/video_coding/packet.cc
+++ b/modules/video_coding/packet.cc
@@ -44,7 +44,7 @@ VCMPacket::VCMPacket(const uint8_t* ptr,
       markerBit(rtp_header.markerBit),
       timesNacked(-1),
       completeNALU(kNaluIncomplete),
-      insertStartCode(videoHeader.codec == kVideoCodecH264 &&
+      insertStartCode((videoHeader.codec == kVideoCodecH264 || videoHeader.codec == kVideoCodecH265) &&
                       videoHeader.is_first_packet_in_frame),
       video_header(videoHeader),
       packet_info(rtp_header, receive_time_ms) {
diff --git a/modules/video_coding/packet_buffer.cc b/modules/video_coding/packet_buffer.cc
index 7da8a1c301..9d28c58215 100644
--- a/modules/video_coding/packet_buffer.cc
+++ b/modules/video_coding/packet_buffer.cc
@@ -23,10 +23,12 @@
 #include "api/rtp_packet_info.h"
 #include "api/video/video_frame_type.h"
 #include "common_video/h264/h264_common.h"
+#include "common_video/h265/h265_common.h"
 #include "modules/rtp_rtcp/source/rtp_header_extensions.h"
 #include "modules/rtp_rtcp/source/rtp_packet_received.h"
 #include "modules/rtp_rtcp/source/rtp_video_header.h"
 #include "modules/video_coding/codecs/h264/include/h264_globals.h"
+#include "modules/video_coding/codecs/h265/include/h265_globals.h"
 #include "rtc_base/checks.h"
 #include "rtc_base/logging.h"
 #include "rtc_base/numerics/mod_ops.h"
@@ -275,12 +277,17 @@ std::vector<std::unique_ptr<PacketBuffer::Packet>> PacketBuffer::FindFrames(
       bool has_h264_pps = false;
       bool has_h264_idr = false;
       bool is_h264_keyframe = false;
+      bool is_h265 = buffer_[start_index]->codec() == kVideoCodecH265;
+      bool has_h265_sps = false;
+      bool has_h265_pps = false;
+      bool has_h265_idr = false;
+      bool is_h265_keyframe = false;
       int idr_width = -1;
       int idr_height = -1;
       while (true) {
         ++tested_packets;
 
-        if (!is_h264 && buffer_[start_index]->is_first_packet_in_frame())
+        if (!is_h264 && !is_h265 && buffer_[start_index]->is_first_packet_in_frame())
           break;
 
         if (is_h264) {
@@ -314,6 +321,27 @@ std::vector<std::unique_ptr<PacketBuffer::Packet>> PacketBuffer::FindFrames(
           }
         }
 
+        if (is_h265 && !is_h265_keyframe) {
+          const auto* h265_header = absl::get_if<RTPVideoHeaderH265>(
+              &buffer_[start_index]->video_header.video_type_header);
+          if (!h265_header || h265_header->nalus_length >= kMaxNalusPerPacket)
+            return found_frames;
+          for (size_t j = 0; j < h265_header->nalus_length; ++j) {
+            if (h265_header->nalus[j].type == H265::NaluType::kSps) {
+              has_h265_sps = true;
+            } else if (h265_header->nalus[j].type == H265::NaluType::kPps) {
+              has_h265_pps = true;
+            } else if (h265_header->nalus[j].type == H265::NaluType::kIdrWRadl
+                       || h265_header->nalus[j].type == H265::NaluType::kIdrNLp
+                       || h265_header->nalus[j].type == H265::NaluType::kCra) {
+              has_h265_idr = true;
+            }
+          }
+          if ((has_h265_sps && has_h265_pps) || has_h265_idr) {
+            is_h265_keyframe = true;
+          }
+        }
+
         if (tested_packets == buffer_.size())
           break;
 
@@ -325,7 +353,7 @@ std::vector<std::unique_ptr<PacketBuffer::Packet>> PacketBuffer::FindFrames(
         // the timestamp of that packet is the same as this one. This may cause
         // the PacketBuffer to hand out incomplete frames.
         // See: https://bugs.chromium.org/p/webrtc/issues/detail?id=7106
-        if (is_h264 && (buffer_[start_index] == nullptr ||
+        if ((is_h264 || is_h265) && (buffer_[start_index] == nullptr ||
                         buffer_[start_index]->timestamp != frame_timestamp)) {
           break;
         }
@@ -371,6 +399,44 @@ std::vector<std::unique_ptr<PacketBuffer::Packet>> PacketBuffer::FindFrames(
         }
       }
 
+      if (is_h265) {
+        // Warn if this is an unsafe frame.
+        if (has_h265_idr && (!has_h265_sps || !has_h265_pps)) {
+          std::stringstream ss;
+          ss << "Received H.265-IDR frame "
+             << "(SPS: " << has_h265_sps << ", PPS: " << has_h265_pps << "). ";
+          ss << "Treating as delta frame since "
+                "WebRTC-SpsPpsIdrIsH265Keyframe is always enabled.";
+          RTC_LOG(LS_WARNING) << ss.str();
+        }
+
+        // Now that we have decided whether to treat this frame as a key frame
+        // or delta frame in the frame buffer, we update the field that
+        // determines if the RtpFrameObject is a key frame or delta frame.
+        const size_t first_packet_index = start_seq_num % buffer_.size();
+        RTC_CHECK_LT(first_packet_index, buffer_.size());
+        if (is_h265_keyframe) {
+          buffer_[first_packet_index]->video_header.frame_type = VideoFrameType::kVideoFrameKey;
+        } else {
+          buffer_[first_packet_index]->video_header.frame_type = VideoFrameType::kVideoFrameDelta;
+        }
+
+        // If this is not a key frame, make sure there are no gaps in the
+        // packet sequence numbers up until this point.
+        if (!is_h265_keyframe && missing_packets_.upper_bound(start_seq_num) !=
+                                     missing_packets_.begin()) {
+          uint16_t stop_index = (index + 1) % buffer_.size();
+          while (start_index != stop_index) {
+            // FIXME: find what it does.
+            //sequence_buffer_[start_index].frame_created = false;
+            start_index = (start_index + 1) % buffer_.size();
+          }
+
+          return found_frames;
+        }
+      }
+      // (check:tnoho)
+
       const uint16_t end_seq_num = seq_num + 1;
       // Use uint16_t type to handle sequence number wrap around case.
       uint16_t num_packets = end_seq_num - start_seq_num;
diff --git a/modules/video_coding/session_info.cc b/modules/video_coding/session_info.cc
index 07b9a9d6b5..dcbf3c8175 100644
--- a/modules/video_coding/session_info.cc
+++ b/modules/video_coding/session_info.cc
@@ -147,6 +147,20 @@ std::vector<NaluInfo> VCMSessionInfo::GetNaluInfos() const {
   return nalu_infos;
 }
 
+std::vector<H265NaluInfo> VCMSessionInfo::GetH265NaluInfos() const {
+  if (packets_.empty() || packets_.front().video_header.codec != kVideoCodecH265)
+    return std::vector<H265NaluInfo>();
+  std::vector<H265NaluInfo> nalu_infos;
+  for (const VCMPacket& packet : packets_) {
+    const auto& h265 =
+        absl::get<RTPVideoHeaderH265>(packet.video_header.video_type_header);
+    for (size_t i = 0; i < h265.nalus_length; ++i) {
+      nalu_infos.push_back(h265.nalus[i]);
+    }
+  }
+  return nalu_infos;
+}
+
 void VCMSessionInfo::SetGofInfo(const GofInfoVP9& gof_info, size_t idx) {
   if (packets_.empty())
     return;
@@ -206,6 +220,9 @@ size_t VCMSessionInfo::InsertBuffer(uint8_t* frame_buffer,
   // header supplied by the H264 depacketizer.
   const size_t kH264NALHeaderLengthInBytes = 1;
   const size_t kLengthFieldLength = 2;
+  const size_t kH265NALHeaderLengthInBytes = 2;
+  const auto* h265 =
+      absl::get_if<RTPVideoHeaderH265>(&packet.video_header.video_type_header);
   const auto* h264 =
       absl::get_if<RTPVideoHeaderH264>(&packet.video_header.video_type_header);
   if (h264 && h264->packetization_type == kH264StapA) {
@@ -230,6 +247,34 @@ size_t VCMSessionInfo::InsertBuffer(uint8_t* frame_buffer,
     packet.sizeBytes = required_length;
     return packet.sizeBytes;
   }
+  else if (h265 && h265->packetization_type == kH265AP) {
+    // Similar to H264, for H265 aggregation packets, we rely on jitter buffer
+    // to remove the two length bytes between each NAL unit, and potentially add
+    // start codes.
+    size_t required_length = 0;
+    const uint8_t* nalu_ptr =
+        packet_buffer + kH265NALHeaderLengthInBytes;  // skip payloadhdr
+    while (nalu_ptr < packet_buffer + packet.sizeBytes) {
+      size_t length = BufferToUWord16(nalu_ptr);
+      required_length +=
+          length + (packet.insertStartCode ? kH265StartCodeLengthBytes : 0);
+      nalu_ptr += kLengthFieldLength + length;
+    }
+    ShiftSubsequentPackets(packet_it, required_length);
+    nalu_ptr = packet_buffer + kH265NALHeaderLengthInBytes;
+    uint8_t* frame_buffer_ptr = frame_buffer + offset;
+    while (nalu_ptr < packet_buffer + packet.sizeBytes) {
+      size_t length = BufferToUWord16(nalu_ptr);
+      nalu_ptr += kLengthFieldLength;
+      // since H265 shares the same start code as H264, use the same Insert
+      // function to handle start code.
+      frame_buffer_ptr += Insert(nalu_ptr, length, packet.insertStartCode,
+                                 const_cast<uint8_t*>(frame_buffer_ptr));
+      nalu_ptr += length;
+    }
+    packet.sizeBytes = required_length;
+    return packet.sizeBytes;
+  }
   ShiftSubsequentPackets(
       packet_it, packet.sizeBytes +
                      (packet.insertStartCode ? kH264StartCodeLengthBytes : 0));
@@ -456,6 +501,18 @@ int VCMSessionInfo::InsertPacket(const VCMPacket& packet,
          IsNewerSequenceNumber(packet.seqNum, last_packet_seq_num_))) {
       last_packet_seq_num_ = packet.seqNum;
     }
+  } else if (packet.codec() == kVideoCodecH265) {
+    frame_type_ = packet.video_header.frame_type;
+    if (packet.is_first_packet_in_frame() &&
+        (first_packet_seq_num_ == -1 ||
+         IsNewerSequenceNumber(first_packet_seq_num_, packet.seqNum))) {
+      first_packet_seq_num_ = packet.seqNum;
+    }
+    if (packet.markerBit &&
+        (last_packet_seq_num_ == -1 ||
+         IsNewerSequenceNumber(packet.seqNum, last_packet_seq_num_))) {
+      last_packet_seq_num_ = packet.seqNum;
+    }
   } else {
     // Only insert media packets between first and last packets (when
     // available).
diff --git a/modules/video_coding/session_info.h b/modules/video_coding/session_info.h
index 06a348ef72..5ad8a6e91d 100644
--- a/modules/video_coding/session_info.h
+++ b/modules/video_coding/session_info.h
@@ -65,6 +65,7 @@ class VCMSessionInfo {
   int Tl0PicId() const;
 
   std::vector<NaluInfo> GetNaluInfos() const;
+  std::vector<H265NaluInfo> GetH265NaluInfos() const;
 
   void SetGofInfo(const GofInfoVP9& gof_info, size_t idx);
 
diff --git a/rtc_base/experiments/min_video_bitrate_experiment.cc b/rtc_base/experiments/min_video_bitrate_experiment.cc
index 11450d0849..bc86d35965 100644
--- a/rtc_base/experiments/min_video_bitrate_experiment.cc
+++ b/rtc_base/experiments/min_video_bitrate_experiment.cc
@@ -100,6 +100,7 @@ absl::optional<DataRate> GetExperimentalMinVideoBitrate(VideoCodecType type) {
         return min_bitrate_av1.GetOptional();
       case kVideoCodecH264:
         return min_bitrate_h264.GetOptional();
+      case kVideoCodecH265:
       case kVideoCodecGeneric:
       case kVideoCodecMultiplex:
         return absl::nullopt;
diff --git a/sdk/BUILD.gn b/sdk/BUILD.gn
index dc9b265155..9a988143b9 100644
--- a/sdk/BUILD.gn
+++ b/sdk/BUILD.gn
@@ -586,6 +586,11 @@ if (is_ios || is_mac) {
         "objc/components/video_codec/RTCCodecSpecificInfoH264.mm",
         "objc/components/video_codec/RTCH264ProfileLevelId.h",
         "objc/components/video_codec/RTCH264ProfileLevelId.mm",
+        "objc/components/video_codec/RTCCodecSpecificInfoH265+Private.h",
+        "objc/components/video_codec/RTCCodecSpecificInfoH265.h",
+        "objc/components/video_codec/RTCCodecSpecificInfoH265.mm",
+        "objc/components/video_codec/RTCH265ProfileLevelId.h",
+        "objc/components/video_codec/RTCH265ProfileLevelId.mm",
       ]
       if (is_ios) {
         sources += [
@@ -1000,6 +1005,7 @@ if (is_ios || is_mac) {
         "objc/Framework/Headers/WebRTC/RTCFileLogger.h",
         "objc/Framework/Headers/WebRTC/RTCFileVideoCapturer.h",
         "objc/Framework/Headers/WebRTC/RTCH264ProfileLevelId.h",
+        "objc/Framework/Headers/WebRTC/RTCH265ProfileLevelId.h",
         "objc/Framework/Headers/WebRTC/RTCIceCandidate.h",
         "objc/Framework/Headers/WebRTC/RTCIceServer.h",
         "objc/Framework/Headers/WebRTC/RTCLegacyStatsReport.h",
@@ -1032,6 +1038,7 @@ if (is_ios || is_mac) {
         "objc/Framework/Headers/WebRTC/RTCVideoCodec.h",
         "objc/Framework/Headers/WebRTC/RTCVideoCodecFactory.h",
         "objc/Framework/Headers/WebRTC/RTCVideoCodecH264.h",
+        "objc/Framework/Headers/WebRTC/RTCVideoCodecH265.h",
         "objc/Framework/Headers/WebRTC/RTCVideoCodecInfo.h",
         "objc/Framework/Headers/WebRTC/RTCVideoDecoderVP8.h",
         "objc/Framework/Headers/WebRTC/RTCVideoDecoderVP9.h",
@@ -1270,13 +1277,17 @@ if (is_ios || is_mac) {
           "objc/components/renderer/opengl/RTCEAGLVideoView.h",
           "objc/components/renderer/opengl/RTCVideoViewShading.h",
           "objc/components/video_codec/RTCCodecSpecificInfoH264.h",
+          "objc/components/video_codec/RTCCodecSpecificInfoH265.h",
           "objc/components/video_codec/RTCDefaultVideoDecoderFactory.h",
           "objc/components/video_codec/RTCDefaultVideoEncoderFactory.h",
           "objc/components/video_codec/RTCH264ProfileLevelId.h",
+          "objc/components/video_codec/RTCH265ProfileLevelId.h",
           "objc/components/video_codec/RTCVideoDecoderFactoryH264.h",
           "objc/components/video_codec/RTCVideoDecoderH264.h",
+          "objc/components/video_codec/RTCVideoDecoderH265.h",
           "objc/components/video_codec/RTCVideoEncoderFactoryH264.h",
           "objc/components/video_codec/RTCVideoEncoderH264.h",
+          "objc/components/video_codec/RTCVideoEncoderH265.h",
           "objc/components/video_frame_buffer/RTCCVPixelBuffer.h",
           "objc/helpers/RTCCameraPreviewView.h",
           "objc/helpers/RTCDispatcher.h",
@@ -1458,13 +1469,17 @@ if (is_ios || is_mac) {
           "objc/components/renderer/opengl/RTCNSGLVideoView.h",
           "objc/components/renderer/opengl/RTCVideoViewShading.h",
           "objc/components/video_codec/RTCCodecSpecificInfoH264.h",
+          "objc/components/video_codec/RTCCodecSpecificInfoH265.h",
           "objc/components/video_codec/RTCDefaultVideoDecoderFactory.h",
           "objc/components/video_codec/RTCDefaultVideoEncoderFactory.h",
           "objc/components/video_codec/RTCH264ProfileLevelId.h",
+          "objc/components/video_codec/RTCH265ProfileLevelId.h",
           "objc/components/video_codec/RTCVideoDecoderFactoryH264.h",
           "objc/components/video_codec/RTCVideoDecoderH264.h",
+          "objc/components/video_codec/RTCVideoDecoderH265.h",
           "objc/components/video_codec/RTCVideoEncoderFactoryH264.h",
           "objc/components/video_codec/RTCVideoEncoderH264.h",
+          "objc/components/video_codec/RTCVideoEncoderH265.h",
           "objc/components/video_frame_buffer/RTCCVPixelBuffer.h",
           "objc/helpers/RTCDispatcher.h",
         ]
@@ -1648,6 +1663,10 @@ if (is_ios || is_mac) {
         "objc/components/video_codec/RTCVideoEncoderFactoryH264.m",
         "objc/components/video_codec/RTCVideoEncoderH264.h",
         "objc/components/video_codec/RTCVideoEncoderH264.mm",
+        "objc/components/video_codec/RTCVideoDecoderH265.h",
+        "objc/components/video_codec/RTCVideoDecoderH265.mm",
+        "objc/components/video_codec/RTCVideoEncoderH265.h",
+        "objc/components/video_codec/RTCVideoEncoderH265.mm",
       ]
 
       configs += [
diff --git a/sdk/objc/Framework/Headers/WebRTC/RTCH265ProfileLevelId.h b/sdk/objc/Framework/Headers/WebRTC/RTCH265ProfileLevelId.h
new file mode 100644
index 0000000000..4c80d2327a
--- /dev/null
+++ b/sdk/objc/Framework/Headers/WebRTC/RTCH265ProfileLevelId.h
@@ -0,0 +1,11 @@
+/*
+ *  Copyright 2017 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#import "components/video_codec/RTCH265ProfileLevelId.h"
diff --git a/sdk/objc/Framework/Headers/WebRTC/RTCVideoCodecH265.h b/sdk/objc/Framework/Headers/WebRTC/RTCVideoCodecH265.h
new file mode 100644
index 0000000000..3402390f90
--- /dev/null
+++ b/sdk/objc/Framework/Headers/WebRTC/RTCVideoCodecH265.h
@@ -0,0 +1,16 @@
+/*
+ *  Copyright 2017 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#import "components/video_codec/RTCCodecSpecificInfoH265.h"
+#import "components/video_codec/RTCH265ProfileLevelId.h"
+#import "components/video_codec/RTCVideoDecoderFactoryH265.h"
+#import "components/video_codec/RTCVideoDecoderH265.h"
+#import "components/video_codec/RTCVideoEncoderFactoryH265.h"
+#import "components/video_codec/RTCVideoEncoderH265.h"
diff --git a/sdk/objc/components/video_codec/RTCCodecSpecificInfoH265+Private.h b/sdk/objc/components/video_codec/RTCCodecSpecificInfoH265+Private.h
new file mode 100644
index 0000000000..ca179f34cb
--- /dev/null
+++ b/sdk/objc/components/video_codec/RTCCodecSpecificInfoH265+Private.h
@@ -0,0 +1,26 @@
+/*
+ *  Copyright 2017 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+/* This file is borrowed from sdk/objc/components/video_codec/RTCCodecSpecificInfoH264+Private.h */
+
+#import "RTCCodecSpecificInfoH265.h"
+
+#include "modules/video_coding/include/video_codec_interface.h"
+
+NS_ASSUME_NONNULL_BEGIN
+
+/* Interfaces for converting to/from internal C++ formats. */
+@interface RTC_OBJC_TYPE (RTCCodecSpecificInfoH265)
+()
+
+    - (webrtc::CodecSpecificInfo)nativeCodecSpecificInfo;
+
+@end
+
+NS_ASSUME_NONNULL_END
diff --git a/sdk/objc/components/video_codec/RTCCodecSpecificInfoH265.h b/sdk/objc/components/video_codec/RTCCodecSpecificInfoH265.h
new file mode 100644
index 0000000000..38f0bce31c
--- /dev/null
+++ b/sdk/objc/components/video_codec/RTCCodecSpecificInfoH265.h
@@ -0,0 +1,28 @@
+/*
+ *  Copyright 2017 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+/* This file is borrowed from sdk/objc/components/video_codec/RTCCodecSpecificInfoH264.h. */
+
+#import <Foundation/Foundation.h>
+
+#import "RTCCodecSpecificInfo.h"
+#import "RTCMacros.h"
+
+/** Class for H265 specific config. */
+typedef NS_ENUM(NSUInteger, RTCH265PacketizationMode) {
+  RTCH265PacketizationModeNonInterleaved = 0,  // Mode 1 - STAP-A, FU-A is allowed
+  RTCH265PacketizationModeSingleNalUnit        // Mode 0 - only single NALU allowed
+};
+
+RTC_OBJC_EXPORT
+@interface RTC_OBJC_TYPE (RTCCodecSpecificInfoH265) : NSObject <RTC_OBJC_TYPE(RTCCodecSpecificInfo)>
+
+@property(nonatomic, assign) RTCH265PacketizationMode packetizationMode;
+
+@end
\ No newline at end of file
diff --git a/sdk/objc/components/video_codec/RTCCodecSpecificInfoH265.mm b/sdk/objc/components/video_codec/RTCCodecSpecificInfoH265.mm
new file mode 100644
index 0000000000..dc52eaca36
--- /dev/null
+++ b/sdk/objc/components/video_codec/RTCCodecSpecificInfoH265.mm
@@ -0,0 +1,29 @@
+/*
+ *  Copyright 2017 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#import "RTCCodecSpecificInfoH265+Private.h"
+
+#import "RTCH264ProfileLevelId.h"
+
+// H264 specific settings.
+@implementation RTC_OBJC_TYPE (RTCCodecSpecificInfoH265)
+
+@synthesize packetizationMode = _packetizationMode;
+
+- (webrtc::CodecSpecificInfo)nativeCodecSpecificInfo {
+  webrtc::CodecSpecificInfo codecSpecificInfo;
+  codecSpecificInfo.codecType = webrtc::kVideoCodecH265;
+  codecSpecificInfo.codecSpecific.H265.packetization_mode =
+      (webrtc::H265PacketizationMode)_packetizationMode;
+
+  return codecSpecificInfo;
+}
+
+@end
diff --git a/sdk/objc/components/video_codec/RTCDefaultVideoDecoderFactory.m b/sdk/objc/components/video_codec/RTCDefaultVideoDecoderFactory.m
index 4046cfedbe..f15ac48836 100644
--- a/sdk/objc/components/video_codec/RTCDefaultVideoDecoderFactory.m
+++ b/sdk/objc/components/video_codec/RTCDefaultVideoDecoderFactory.m
@@ -11,7 +11,9 @@
 #import "RTCDefaultVideoDecoderFactory.h"
 
 #import "RTCH264ProfileLevelId.h"
+#import "RTCH265ProfileLevelId.h"
 #import "RTCVideoDecoderH264.h"
+#import "RTCVideoDecoderH265.h"
 #import "api/video_codec/RTCVideoCodecConstants.h"
 #import "api/video_codec/RTCVideoDecoderVP8.h"
 #import "base/RTCVideoCodecInfo.h"
@@ -43,6 +45,9 @@ @implementation RTC_OBJC_TYPE (RTCDefaultVideoDecoderFactory)
   RTC_OBJC_TYPE(RTCVideoCodecInfo) *vp8Info =
       [[RTC_OBJC_TYPE(RTCVideoCodecInfo) alloc] initWithName:kRTCVideoCodecVp8Name];
 
+ RTC_OBJC_TYPE(RTCVideoCodecInfo) *h265Info = 
+      [[RTC_OBJC_TYPE(RTCVideoCodecInfo) alloc] initWithName:kRTCVideoCodecH265Name];
+
 #if defined(RTC_ENABLE_VP9)
   RTC_OBJC_TYPE(RTCVideoCodecInfo) *vp9Info =
       [[RTC_OBJC_TYPE(RTCVideoCodecInfo) alloc] initWithName:kRTCVideoCodecVp9Name];
@@ -51,6 +56,7 @@ @implementation RTC_OBJC_TYPE (RTCDefaultVideoDecoderFactory)
   return @[
     constrainedHighInfo,
     constrainedBaselineInfo,
+    h265Info,
     vp8Info,
 #if defined(RTC_ENABLE_VP9)
     vp9Info,
@@ -63,6 +69,8 @@ @implementation RTC_OBJC_TYPE (RTCDefaultVideoDecoderFactory)
     return [[RTC_OBJC_TYPE(RTCVideoDecoderH264) alloc] init];
   } else if ([info.name isEqualToString:kRTCVideoCodecVp8Name]) {
     return [RTC_OBJC_TYPE(RTCVideoDecoderVP8) vp8Decoder];
+  } else if ([info.name isEqualToString:kRTCVideoCodecH265Name]) {
+    return [[RTC_OBJC_TYPE(RTCVideoDecoderH265) alloc] init];
 #if defined(RTC_ENABLE_VP9)
   } else if ([info.name isEqualToString:kRTCVideoCodecVp9Name]) {
     return [RTC_OBJC_TYPE(RTCVideoDecoderVP9) vp9Decoder];
diff --git a/sdk/objc/components/video_codec/RTCDefaultVideoEncoderFactory.m b/sdk/objc/components/video_codec/RTCDefaultVideoEncoderFactory.m
index 35a1407f38..0fd03008d3 100644
--- a/sdk/objc/components/video_codec/RTCDefaultVideoEncoderFactory.m
+++ b/sdk/objc/components/video_codec/RTCDefaultVideoEncoderFactory.m
@@ -11,7 +11,9 @@
 #import "RTCDefaultVideoEncoderFactory.h"
 
 #import "RTCH264ProfileLevelId.h"
+#import "RTCH265ProfileLevelId.h"
 #import "RTCVideoEncoderH264.h"
+#import "RTCVideoEncoderH265.h"
 #import "api/video_codec/RTCVideoCodecConstants.h"
 #import "api/video_codec/RTCVideoEncoderVP8.h"
 #import "base/RTCVideoCodecInfo.h"
@@ -45,6 +47,9 @@ @implementation RTC_OBJC_TYPE (RTCDefaultVideoEncoderFactory)
   RTC_OBJC_TYPE(RTCVideoCodecInfo) *vp8Info =
       [[RTC_OBJC_TYPE(RTCVideoCodecInfo) alloc] initWithName:kRTCVideoCodecVp8Name];
 
+  RTC_OBJC_TYPE(RTCVideoCodecInfo) *h265Info =
+      [[RTC_OBJC_TYPE(RTCVideoCodecInfo) alloc] initWithName:kRTCVideoCodecH265Name];
+
 #if defined(RTC_ENABLE_VP9)
   RTC_OBJC_TYPE(RTCVideoCodecInfo) *vp9Info =
       [[RTC_OBJC_TYPE(RTCVideoCodecInfo) alloc] initWithName:kRTCVideoCodecVp9Name];
@@ -53,6 +58,7 @@ @implementation RTC_OBJC_TYPE (RTCDefaultVideoEncoderFactory)
   return @[
     constrainedHighInfo,
     constrainedBaselineInfo,
+    h265Info,
     vp8Info,
 #if defined(RTC_ENABLE_VP9)
     vp9Info,
@@ -69,6 +75,8 @@ @implementation RTC_OBJC_TYPE (RTCDefaultVideoEncoderFactory)
   } else if ([info.name isEqualToString:kRTCVideoCodecVp9Name]) {
     return [RTC_OBJC_TYPE(RTCVideoEncoderVP9) vp9Encoder];
 #endif
+  } else if ([info.name isEqualToString:kRTCVideoCodecH265Name]) {
+    return [[RTCVideoEncoderH265 alloc] initWithCodecInfo:info];
   }
 
   return nil;
diff --git a/sdk/objc/components/video_codec/RTCH265ProfileLevelId.h b/sdk/objc/components/video_codec/RTCH265ProfileLevelId.h
new file mode 100644
index 0000000000..17bc34f226
--- /dev/null
+++ b/sdk/objc/components/video_codec/RTCH265ProfileLevelId.h
@@ -0,0 +1,16 @@
+/*
+ *  Copyright 2017 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#import <Foundation/Foundation.h>
+
+#import "RTCMacros.h"
+
+RTC_OBJC_EXPORT extern NSString *const kRTCVideoCodecH265Name;
+RTC_OBJC_EXPORT extern NSString *const kRTCLevel31Main;
\ No newline at end of file
diff --git a/sdk/objc/components/video_codec/RTCH265ProfileLevelId.mm b/sdk/objc/components/video_codec/RTCH265ProfileLevelId.mm
new file mode 100644
index 0000000000..fe9c6330c1
--- /dev/null
+++ b/sdk/objc/components/video_codec/RTCH265ProfileLevelId.mm
@@ -0,0 +1,18 @@
+/*
+ *  Copyright 2018 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ *
+ */
+
+#import "RTCH265ProfileLevelId.h"
+
+#include "media/base/media_constants.h"
+
+NSString *const kRTCVideoCodecH265Name = @"H265";
+// TODO(jianjunz): This is value is not correct.
+NSString *const kRTCLevel31Main = @"4d001f";
\ No newline at end of file
diff --git a/sdk/objc/components/video_codec/RTCVideoDecoderFactoryH265.h b/sdk/objc/components/video_codec/RTCVideoDecoderFactoryH265.h
deleted file mode 100644
index e69de29bb2..0000000000
diff --git a/sdk/objc/components/video_codec/RTCVideoDecoderFactoryH265.m b/sdk/objc/components/video_codec/RTCVideoDecoderFactoryH265.m
deleted file mode 100644
index e69de29bb2..0000000000
diff --git a/sdk/objc/components/video_codec/RTCVideoDecoderH265.h b/sdk/objc/components/video_codec/RTCVideoDecoderH265.h
new file mode 100644
index 0000000000..e5a097a59d
--- /dev/null
+++ b/sdk/objc/components/video_codec/RTCVideoDecoderH265.h
@@ -0,0 +1,21 @@
+/*
+ *  Copyright 2017 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#import <Foundation/Foundation.h>
+
+#import "RTCMacros.h"
+#import "RTCVideoDecoder.h"
+
+RTC_OBJC_EXPORT
+@interface RTC_OBJC_TYPE (RTCVideoDecoderH265) : NSObject <RTC_OBJC_TYPE(RTCVideoDecoder)>
+- (NSInteger)decodeData:(const uint8_t *)data
+    size:(size_t)size
+    timeStamp:(uint32_t)timeStamp;
+@end
diff --git a/sdk/objc/components/video_codec/RTCVideoDecoderH265.mm b/sdk/objc/components/video_codec/RTCVideoDecoderH265.mm
new file mode 100644
index 0000000000..614f1df4ba
--- /dev/null
+++ b/sdk/objc/components/video_codec/RTCVideoDecoderH265.mm
@@ -0,0 +1,273 @@
+/*
+ *  Copyright (c) 2018 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ *
+ */
+
+#import "RTCVideoDecoderH265.h"
+
+#import <VideoToolbox/VideoToolbox.h>
+
+#import "base/RTCVideoFrame.h"
+#import "base/RTCVideoFrameBuffer.h"
+#import "components/video_frame_buffer/RTCCVPixelBuffer.h"
+#import "helpers.h"
+#import "helpers/scoped_cftyperef.h"
+
+#include "modules/video_coding/include/video_error_codes.h"
+#include "rtc_base/checks.h"
+#include "rtc_base/logging.h"
+#include "rtc_base/time_utils.h"
+#include "sdk/objc/components/video_codec/nalu_rewriter.h"
+
+// Struct that we pass to the decoder per frame to decode. We receive it again
+// in the decoder callback.
+struct RTCH265FrameDecodeParams {
+  RTCH265FrameDecodeParams(RTCVideoDecoderCallback cb, int64_t ts)
+      : callback(cb), timestamp(ts) {}
+  RTCVideoDecoderCallback callback;
+  int64_t timestamp;
+};
+
+// This is the callback function that VideoToolbox calls when decode is
+// complete.
+void h265DecompressionOutputCallback(void* decoder,
+                                     void* params,
+                                     OSStatus status,
+                                     VTDecodeInfoFlags infoFlags,
+                                     CVImageBufferRef imageBuffer,
+                                     CMTime timestamp,
+                                     CMTime duration) {
+  std::unique_ptr<RTCH265FrameDecodeParams> decodeParams(
+      reinterpret_cast<RTCH265FrameDecodeParams*>(params));
+  if (status != noErr) {
+    RTC_LOG(LS_ERROR) << "Failed to decode frame. Status: " << status;
+    return;
+  }
+  // TODO(tkchin): Handle CVO properly.
+  RTC_OBJC_TYPE(RTCCVPixelBuffer)* frameBuffer =
+      [[RTC_OBJC_TYPE(RTCCVPixelBuffer) alloc] initWithPixelBuffer:imageBuffer];
+  RTC_OBJC_TYPE(RTCVideoFrame)* decodedFrame = [[RTC_OBJC_TYPE(RTCVideoFrame) alloc]
+      initWithBuffer:frameBuffer
+            rotation:RTCVideoRotation_0
+         timeStampNs:CMTimeGetSeconds(timestamp) * rtc::kNumNanosecsPerSec];
+  decodedFrame.timeStamp = decodeParams->timestamp;
+  decodeParams->callback(decodedFrame);
+}
+
+// Decoder.
+@implementation RTC_OBJC_TYPE (RTCVideoDecoderH265) {
+  CMVideoFormatDescriptionRef _videoFormat;
+  VTDecompressionSessionRef _decompressionSession;
+  RTCVideoDecoderCallback _callback;
+  OSStatus _error;
+}
+
+- (instancetype)init {
+  if (self = [super init]) {
+  }
+
+  return self;
+}
+
+- (void)dealloc {
+  [self destroyDecompressionSession];
+  [self setVideoFormat:nullptr];
+}
+
+- (NSInteger)startDecodeWithNumberOfCores:(int)numberOfCores {
+  return WEBRTC_VIDEO_CODEC_OK;
+}
+
+- (NSInteger)decode:(RTC_OBJC_TYPE(RTCEncodedImage) *)inputImage
+          missingFrames:(BOOL)missingFrames
+      codecSpecificInfo:(__nullable id<RTC_OBJC_TYPE(RTCCodecSpecificInfo)>)info
+           renderTimeMs:(int64_t)renderTimeMs {
+  RTC_DCHECK(inputImage.buffer);
+  return [self decodeData: (uint8_t *)inputImage.buffer.bytes size: inputImage.buffer.length timeStamp: inputImage.timeStamp];
+}
+
+- (NSInteger)decodeData:(const uint8_t *)data size:(size_t)size timeStamp:(uint32_t)timeStamp {
+  if (_error != noErr) {
+    RTC_LOG(LS_WARNING) << "Last frame decode failed.";
+    _error = noErr;
+    return WEBRTC_VIDEO_CODEC_ERROR;
+  }
+
+  rtc::ScopedCFTypeRef<CMVideoFormatDescriptionRef> inputFormat =
+      rtc::ScopedCF(webrtc::CreateH265VideoFormatDescription(
+          (uint8_t*)data, size));
+  if (inputFormat) {
+    CMVideoDimensions dimensions =
+        CMVideoFormatDescriptionGetDimensions(inputFormat.get());
+    RTC_LOG(LS_INFO) << "Resolution: " << dimensions.width << " x "
+                     << dimensions.height;
+    // Check if the video format has changed, and reinitialize decoder if
+    // needed.
+    if (!CMFormatDescriptionEqual(inputFormat.get(), _videoFormat)) {
+      [self setVideoFormat:inputFormat.get()];
+      int resetDecompressionSessionError = [self resetDecompressionSession];
+      if (resetDecompressionSessionError != WEBRTC_VIDEO_CODEC_OK) {
+        return resetDecompressionSessionError;
+      }
+    }
+  }
+  if (!_videoFormat) {
+    // We received a frame but we don't have format information so we can't
+    // decode it.
+    // This can happen after backgrounding. We need to wait for the next
+    // sps/pps before we can resume so we request a keyframe by returning an
+    // error.
+    RTC_LOG(LS_WARNING) << "Missing video format. Frame with sps/pps required.";
+    return WEBRTC_VIDEO_CODEC_ERROR;
+  }
+  CMSampleBufferRef sampleBuffer = nullptr;
+  if (!webrtc::H265AnnexBBufferToCMSampleBuffer(
+          (uint8_t*)data, size,
+          _videoFormat, &sampleBuffer)) {
+    return WEBRTC_VIDEO_CODEC_ERROR;
+  }
+  RTC_DCHECK(sampleBuffer);
+  VTDecodeFrameFlags decodeFlags =
+      kVTDecodeFrame_EnableAsynchronousDecompression;
+  std::unique_ptr<RTCH265FrameDecodeParams> frameDecodeParams;
+  frameDecodeParams.reset(
+      new RTCH265FrameDecodeParams(_callback, timeStamp));
+  OSStatus status = VTDecompressionSessionDecodeFrame(
+      _decompressionSession, sampleBuffer, decodeFlags,
+      frameDecodeParams.release(), nullptr);
+#if defined(WEBRTC_IOS)
+  // Re-initialize the decoder if we have an invalid session while the app is
+  // active and retry the decode request.
+  if (status == kVTInvalidSessionErr &&
+      [self resetDecompressionSession] == WEBRTC_VIDEO_CODEC_OK) {
+    frameDecodeParams.reset(
+        new RTCH265FrameDecodeParams(_callback, timeStamp));
+    status = VTDecompressionSessionDecodeFrame(
+        _decompressionSession, sampleBuffer, decodeFlags,
+        frameDecodeParams.release(), nullptr);
+  }
+#endif
+  CFRelease(sampleBuffer);
+  if (status != noErr) {
+    RTC_LOG(LS_ERROR) << "Failed to decode frame with code: " << status;
+    return WEBRTC_VIDEO_CODEC_ERROR;
+  }
+  return WEBRTC_VIDEO_CODEC_OK;
+}
+
+- (void)setCallback:(RTCVideoDecoderCallback)callback {
+  _callback = callback;
+}
+
+- (NSInteger)releaseDecoder {
+  // Need to invalidate the session so that callbacks no longer occur and it
+  // is safe to null out the callback.
+  [self destroyDecompressionSession];
+  [self setVideoFormat:nullptr];
+  _callback = nullptr;
+  return WEBRTC_VIDEO_CODEC_OK;
+}
+
+#pragma mark - Private
+
+- (int)resetDecompressionSession {
+  [self destroyDecompressionSession];
+
+  // Need to wait for the first SPS to initialize decoder.
+  if (!_videoFormat) {
+    return WEBRTC_VIDEO_CODEC_OK;
+  }
+
+  // Set keys for OpenGL and IOSurface compatibilty, which makes the encoder
+  // create pixel buffers with GPU backed memory. The intent here is to pass
+  // the pixel buffers directly so we avoid a texture upload later during
+  // rendering. This currently is moot because we are converting back to an
+  // I420 frame after decode, but eventually we will be able to plumb
+  // CVPixelBuffers directly to the renderer.
+  // TODO(tkchin): Maybe only set OpenGL/IOSurface keys if we know that that
+  // we can pass CVPixelBuffers as native handles in decoder output.
+  static size_t const attributesSize = 3;
+  CFTypeRef keys[attributesSize] = {
+#if defined(WEBRTC_IOS)
+    kCVPixelBufferOpenGLESCompatibilityKey,
+#elif defined(WEBRTC_MAC)
+    kCVPixelBufferOpenGLCompatibilityKey,
+#endif
+    kCVPixelBufferIOSurfacePropertiesKey,
+    kCVPixelBufferPixelFormatTypeKey
+  };
+  CFDictionaryRef ioSurfaceValue = CreateCFTypeDictionary(nullptr, nullptr, 0);
+  int64_t nv12type = kCVPixelFormatType_420YpCbCr8BiPlanarFullRange;
+  CFNumberRef pixelFormat =
+      CFNumberCreate(nullptr, kCFNumberLongType, &nv12type);
+  CFTypeRef values[attributesSize] = {kCFBooleanTrue, ioSurfaceValue,
+                                      pixelFormat};
+  CFDictionaryRef attributes =
+      CreateCFTypeDictionary(keys, values, attributesSize);
+  if (ioSurfaceValue) {
+    CFRelease(ioSurfaceValue);
+    ioSurfaceValue = nullptr;
+  }
+  if (pixelFormat) {
+    CFRelease(pixelFormat);
+    pixelFormat = nullptr;
+  }
+  VTDecompressionOutputCallbackRecord record = {
+      h265DecompressionOutputCallback,
+      nullptr,
+  };
+  OSStatus status =
+      VTDecompressionSessionCreate(nullptr, _videoFormat, nullptr, attributes,
+                                   &record, &_decompressionSession);
+  CFRelease(attributes);
+  if (status != noErr) {
+    [self destroyDecompressionSession];
+    return WEBRTC_VIDEO_CODEC_ERROR;
+  }
+  [self configureDecompressionSession];
+
+  return WEBRTC_VIDEO_CODEC_OK;
+}
+
+- (void)configureDecompressionSession {
+  RTC_DCHECK(_decompressionSession);
+#if defined(WEBRTC_IOS)
+  VTSessionSetProperty(_decompressionSession, kVTDecompressionPropertyKey_RealTime, kCFBooleanTrue);
+#endif
+}
+
+- (void)destroyDecompressionSession {
+  if (_decompressionSession) {
+#if defined(WEBRTC_IOS)
+    VTDecompressionSessionWaitForAsynchronousFrames(_decompressionSession);
+#endif
+    VTDecompressionSessionInvalidate(_decompressionSession);
+    CFRelease(_decompressionSession);
+    _decompressionSession = nullptr;
+  }
+}
+
+- (void)setVideoFormat:(CMVideoFormatDescriptionRef)videoFormat {
+  if (_videoFormat == videoFormat) {
+    return;
+  }
+  if (_videoFormat) {
+    CFRelease(_videoFormat);
+  }
+  _videoFormat = videoFormat;
+  if (_videoFormat) {
+    CFRetain(_videoFormat);
+  }
+}
+
+- (NSString*)implementationName {
+  return @"VideoToolbox";
+}
+
+@end
\ No newline at end of file
diff --git a/sdk/objc/components/video_codec/RTCVideoEncoderFactoryH265.h b/sdk/objc/components/video_codec/RTCVideoEncoderFactoryH265.h
deleted file mode 100644
index e69de29bb2..0000000000
diff --git a/sdk/objc/components/video_codec/RTCVideoEncoderFactoryH265.m b/sdk/objc/components/video_codec/RTCVideoEncoderFactoryH265.m
deleted file mode 100644
index e69de29bb2..0000000000
diff --git a/sdk/objc/components/video_codec/RTCVideoEncoderH265.h b/sdk/objc/components/video_codec/RTCVideoEncoderH265.h
new file mode 100644
index 0000000000..3f5f438a5f
--- /dev/null
+++ b/sdk/objc/components/video_codec/RTCVideoEncoderH265.h
@@ -0,0 +1,22 @@
+/*
+ *  Copyright 2017 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#import <Foundation/Foundation.h>
+
+#import "RTCMacros.h"
+#import "RTCVideoCodecInfo.h"
+#import "RTCVideoEncoder.h"
+
+RTC_OBJC_EXPORT
+@interface RTC_OBJC_TYPE (RTCVideoEncoderH265) : NSObject <RTC_OBJC_TYPE(RTCVideoEncoder)>
+
+- (instancetype)initWithCodecInfo:(RTC_OBJC_TYPE(RTCVideoCodecInfo) *)codecInfo;
+
+@end
diff --git a/sdk/objc/components/video_codec/RTCVideoEncoderH265.mm b/sdk/objc/components/video_codec/RTCVideoEncoderH265.mm
new file mode 100644
index 0000000000..9dbfd3e2ef
--- /dev/null
+++ b/sdk/objc/components/video_codec/RTCVideoEncoderH265.mm
@@ -0,0 +1,585 @@
+/*
+ *  Copyright (c) 2018 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ *
+ */
+
+#import "RTCVideoEncoderH265.h"
+
+#import <VideoToolbox/VideoToolbox.h>
+#include <vector>
+
+#import "RTCCodecSpecificInfoH265.h"
+#import "api/peerconnection/RTCRtpFragmentationHeader+Private.h"
+#import "api/peerconnection/RTCVideoCodecInfo+Private.h"
+#import "base/RTCI420Buffer.h"
+#import "base/RTCVideoFrame.h"
+#import "base/RTCVideoFrameBuffer.h"
+#import "components/video_frame_buffer/RTCCVPixelBuffer.h"
+#import "helpers.h"
+#if defined(WEBRTC_IOS)
+#import "helpers/UIDevice+RTCDevice.h"
+#endif
+
+#include "common_video/include/bitrate_adjuster.h"
+#include "libyuv/convert_from.h"
+#include "modules/include/module_common_types.h"
+#include "modules/video_coding/include/video_error_codes.h"
+#include "rtc_base/buffer.h"
+#include "rtc_base/logging.h"
+#include "rtc_base/time_utils.h"
+#include "sdk/objc/Framework/Classes/VideoToolbox/nalu_rewriter.h"
+#include "system_wrappers/include/clock.h"
+
+@interface RTC_OBJC_TYPE (RTCVideoEncoderH265) ()
+
+- (void)frameWasEncoded:(OSStatus)status
+                  flags:(VTEncodeInfoFlags)infoFlags
+           sampleBuffer:(CMSampleBufferRef)sampleBuffer
+                  width:(int32_t)width
+                 height:(int32_t)height
+           renderTimeMs:(int64_t)renderTimeMs
+              timestamp:(uint32_t)timestamp
+               rotation:(RTCVideoRotation)rotation;
+
+@end
+
+namespace {  // anonymous namespace
+
+// The ratio between kVTCompressionPropertyKey_DataRateLimits and
+// kVTCompressionPropertyKey_AverageBitRate. The data rate limit is set higher
+// than the average bit rate to avoid undershooting the target.
+const float kLimitToAverageBitRateFactor = 1.5f;
+// These thresholds deviate from the default h265 QP thresholds, as they
+// have been found to work better on devices that support VideoToolbox
+const int kLowh265QpThreshold = 28;
+const int kHighh265QpThreshold = 39;
+
+// Struct that we pass to the encoder per frame to encode. We receive it again
+// in the encoder callback.
+struct RTCFrameEncodeParams {
+  RTCFrameEncodeParams(RTC_OBJC_TYPE(RTCVideoEncoderH265) * e,
+                       int32_t w,
+                       int32_t h,
+                       int64_t rtms,
+                       uint32_t ts,
+                       RTCVideoRotation r)
+      : encoder(e),
+        width(w),
+        height(h),
+        render_time_ms(rtms),
+        timestamp(ts),
+        rotation(r) {}
+
+  RTC_OBJC_TYPE(RTCVideoEncoderH265) * encoder;
+  int32_t width;
+  int32_t height;
+  int64_t render_time_ms;
+  uint32_t timestamp;
+  RTCVideoRotation rotation;
+};
+
+// We receive I420Frames as input, but we need to feed CVPixelBuffers into the
+// encoder. This performs the copy and format conversion.
+// TODO(tkchin): See if encoder will accept i420 frames and compare performance.
+bool CopyVideoFrameToPixelBuffer(id<RTC_OBJC_TYPE(RTCI420Buffer)> frameBuffer,
+                                 CVPixelBufferRef pixelBuffer) {
+  RTC_DCHECK(pixelBuffer);
+  RTC_DCHECK_EQ(CVPixelBufferGetPixelFormatType(pixelBuffer),
+                kCVPixelFormatType_420YpCbCr8BiPlanarFullRange);
+  RTC_DCHECK_EQ(CVPixelBufferGetHeightOfPlane(pixelBuffer, 0),
+                frameBuffer.height);
+  RTC_DCHECK_EQ(CVPixelBufferGetWidthOfPlane(pixelBuffer, 0),
+                frameBuffer.width);
+
+  CVReturn cvRet = CVPixelBufferLockBaseAddress(pixelBuffer, 0);
+  if (cvRet != kCVReturnSuccess) {
+    RTC_LOG(LS_ERROR) << "Failed to lock base address: " << cvRet;
+    return false;
+  }
+
+  uint8_t* dstY = reinterpret_cast<uint8_t*>(
+      CVPixelBufferGetBaseAddressOfPlane(pixelBuffer, 0));
+  int dstStrideY = CVPixelBufferGetBytesPerRowOfPlane(pixelBuffer, 0);
+  uint8_t* dstUV = reinterpret_cast<uint8_t*>(
+      CVPixelBufferGetBaseAddressOfPlane(pixelBuffer, 1));
+  int dstStrideUV = CVPixelBufferGetBytesPerRowOfPlane(pixelBuffer, 1);
+  // Convert I420 to NV12.
+  int ret = libyuv::I420ToNV12(
+      frameBuffer.dataY, frameBuffer.strideY, frameBuffer.dataU,
+      frameBuffer.strideU, frameBuffer.dataV, frameBuffer.strideV, dstY,
+      dstStrideY, dstUV, dstStrideUV, frameBuffer.width, frameBuffer.height);
+  CVPixelBufferUnlockBaseAddress(pixelBuffer, 0);
+  if (ret) {
+    RTC_LOG(LS_ERROR) << "Error converting I420 VideoFrame to NV12 :" << ret;
+    return false;
+  }
+  return true;
+}
+
+CVPixelBufferRef CreatePixelBuffer(CVPixelBufferPoolRef pixel_buffer_pool) {
+  if (!pixel_buffer_pool) {
+    RTC_LOG(LS_ERROR) << "Failed to get pixel buffer pool.";
+    return nullptr;
+  }
+  CVPixelBufferRef pixel_buffer;
+  CVReturn ret = CVPixelBufferPoolCreatePixelBuffer(nullptr, pixel_buffer_pool,
+                                                    &pixel_buffer);
+  if (ret != kCVReturnSuccess) {
+    RTC_LOG(LS_ERROR) << "Failed to create pixel buffer: " << ret;
+    // We probably want to drop frames here, since failure probably means
+    // that the pool is empty.
+    return nullptr;
+  }
+  return pixel_buffer;
+}
+
+// This is the callback function that VideoToolbox calls when encode is
+// complete. From inspection this happens on its own queue.
+void compressionOutputCallback(void* encoder,
+                               void* params,
+                               OSStatus status,
+                               VTEncodeInfoFlags infoFlags,
+                               CMSampleBufferRef sampleBuffer)
+    API_AVAILABLE(ios(11.0)) {
+  RTC_CHECK(params);
+  std::unique_ptr<RTCFrameEncodeParams> encodeParams(
+      reinterpret_cast<RTCFrameEncodeParams*>(params));
+  RTC_CHECK(encodeParams->encoder);
+  [encodeParams->encoder frameWasEncoded:status
+                                   flags:infoFlags
+                            sampleBuffer:sampleBuffer
+                                   width:encodeParams->width
+                                  height:encodeParams->height
+                            renderTimeMs:encodeParams->render_time_ms
+                               timestamp:encodeParams->timestamp
+                                rotation:encodeParams->rotation];
+}
+}  // namespace
+
+@implementation RTC_OBJC_TYPE(RTCVideoEncoderH265) {
+  RTC_OBJC_TYPE(RTCVideoCodecInfo) * _codecInfo;
+  std::unique_ptr<webrtc::BitrateAdjuster> _bitrateAdjuster;
+  uint32_t _targetBitrateBps;
+  uint32_t _encoderBitrateBps;
+  CFStringRef _profile;
+  RTCVideoEncoderCallback _callback;
+  int32_t _width;
+  int32_t _height;
+  VTCompressionSessionRef _compressionSession;
+  RTCVideoCodecMode _mode;
+  int framesLeft;
+
+  std::vector<uint8_t> _nv12ScaleBuffer;
+}
+
+// .5 is set as a mininum to prevent overcompensating for large temporary
+// overshoots. We don't want to degrade video quality too badly.
+// .95 is set to prevent oscillations. When a lower bitrate is set on the
+// encoder than previously set, its output seems to have a brief period of
+// drastically reduced bitrate, so we want to avoid that. In steady state
+// conditions, 0.95 seems to give us better overall bitrate over long periods
+// of time.
+- (instancetype)initWithCodecInfo:(RTC_OBJC_TYPE(RTCVideoCodecInfo) *)codecInfo {
+  if (self = [super init]) {
+    _codecInfo = codecInfo;
+    _bitrateAdjuster.reset(new webrtc::BitrateAdjuster(.5, .95));
+    RTC_CHECK([codecInfo.name isEqualToString:@"H265"]);
+  }
+  return self;
+}
+
+- (void)dealloc {
+  [self destroyCompressionSession];
+}
+
+- (NSInteger)startEncodeWithSettings:(RTC_OBJC_TYPE(RTCVideoEncoderSettings) *)settings
+                       numberOfCores:(int)numberOfCores {
+  RTC_DCHECK(settings);
+  RTC_DCHECK([settings.name isEqualToString:@"H265"]);
+
+  _width = settings.width;
+  _height = settings.height;
+  _mode = settings.mode;
+
+  // We can only set average bitrate on the HW encoder.
+  _targetBitrateBps = settings.startBitrate;
+  _bitrateAdjuster->SetTargetBitrateBps(_targetBitrateBps);
+
+  return [self resetCompressionSession];
+}
+
+- (NSInteger)encode:(RTC_OBJC_TYPE(RTCVideoFrame) *)frame
+    codecSpecificInfo:(nullable id<RTC_OBJC_TYPE(RTCCodecSpecificInfo)>)codecSpecificInfo
+           frameTypes:(NSArray<NSNumber*>*)frameTypes {
+  RTC_DCHECK_EQ(frame.width, _width);
+  RTC_DCHECK_EQ(frame.height, _height);
+  if (!_callback || !_compressionSession) {
+    return WEBRTC_VIDEO_CODEC_UNINITIALIZED;
+  }
+  BOOL isKeyframeRequired = NO;
+
+  // Get a pixel buffer from the pool and copy frame data over.
+  CVPixelBufferPoolRef pixelBufferPool =
+      VTCompressionSessionGetPixelBufferPool(_compressionSession);
+
+#if defined(WEBRTC_IOS)
+  if (!pixelBufferPool) {
+    // Kind of a hack. On backgrounding, the compression session seems to get
+    // invalidated, which causes this pool call to fail when the application
+    // is foregrounded and frames are being sent for encoding again.
+    // Resetting the session when this happens fixes the issue.
+    // In addition we request a keyframe so video can recover quickly.
+    [self resetCompressionSession];
+    pixelBufferPool =
+        VTCompressionSessionGetPixelBufferPool(_compressionSession);
+    isKeyframeRequired = YES;
+    RTC_LOG(LS_INFO) << "Resetting compression session due to invalid pool.";
+  }
+#endif
+
+  CVPixelBufferRef pixelBuffer = nullptr;
+  if ([frame.buffer isKindOfClass:[RTC_OBJC_TYPE(RTCCVPixelBuffer) class]]) {
+    // Native frame buffer
+    RTC_OBJC_TYPE(RTCCVPixelBuffer) *rtcPixelBuffer =
+        (RTC_OBJC_TYPE(RTCCVPixelBuffer) *)frame.buffer;
+    if (![rtcPixelBuffer requiresCropping]) {
+      // This pixel buffer might have a higher resolution than what the
+      // compression session is configured to. The compression session can
+      // handle that and will output encoded frames in the configured
+      // resolution regardless of the input pixel buffer resolution.
+      pixelBuffer = rtcPixelBuffer.pixelBuffer;
+      CVBufferRetain(pixelBuffer);
+    } else {
+      // Cropping required, we need to crop and scale to a new pixel buffer.
+      pixelBuffer = CreatePixelBuffer(pixelBufferPool);
+      if (!pixelBuffer) {
+        return WEBRTC_VIDEO_CODEC_ERROR;
+      }
+      int dstWidth = CVPixelBufferGetWidth(pixelBuffer);
+      int dstHeight = CVPixelBufferGetHeight(pixelBuffer);
+      if ([rtcPixelBuffer requiresScalingToWidth:dstWidth height:dstHeight]) {
+        int size =
+            [rtcPixelBuffer bufferSizeForCroppingAndScalingToWidth:dstWidth
+                                                            height:dstHeight];
+        _nv12ScaleBuffer.resize(size);
+      } else {
+        _nv12ScaleBuffer.clear();
+      }
+      _nv12ScaleBuffer.shrink_to_fit();
+      if (![rtcPixelBuffer cropAndScaleTo:pixelBuffer
+                           withTempBuffer:_nv12ScaleBuffer.data()]) {
+        return WEBRTC_VIDEO_CODEC_ERROR;
+      }
+    }
+  }
+
+  if (!pixelBuffer) {
+    // We did not have a native frame buffer
+    pixelBuffer = CreatePixelBuffer(pixelBufferPool);
+    if (!pixelBuffer) {
+      return WEBRTC_VIDEO_CODEC_ERROR;
+    }
+    RTC_DCHECK(pixelBuffer);
+    if (!CopyVideoFrameToPixelBuffer([frame.buffer toI420], pixelBuffer)) {
+      RTC_LOG(LS_ERROR) << "Failed to copy frame data.";
+      CVBufferRelease(pixelBuffer);
+      return WEBRTC_VIDEO_CODEC_ERROR;
+    }
+  }
+
+  // Check if we need a keyframe.
+  if (!isKeyframeRequired && frameTypes) {
+    for (NSNumber* frameType in frameTypes) {
+      if ((RTCFrameType)frameType.intValue == RTCFrameTypeVideoFrameKey) {
+        isKeyframeRequired = YES;
+        break;
+      }
+    }
+  }
+
+  CMTime presentationTimeStamp =
+      CMTimeMake(frame.timeStampNs / rtc::kNumNanosecsPerMillisec, 1000);
+  CFDictionaryRef frameProperties = nullptr;
+  if (isKeyframeRequired) {
+    CFTypeRef keys[] = {kVTEncodeFrameOptionKey_ForceKeyFrame};
+    CFTypeRef values[] = {kCFBooleanTrue};
+    frameProperties = CreateCFTypeDictionary(keys, values, 1);
+  }
+
+  std::unique_ptr<RTCFrameEncodeParams> encodeParams;
+  encodeParams.reset(new RTCFrameEncodeParams(
+      self, _width, _height, frame.timeStampNs / rtc::kNumNanosecsPerMillisec,
+      frame.timeStamp, frame.rotation));
+
+  // Update the bitrate if needed.
+  [self setBitrateBps:_bitrateAdjuster->GetAdjustedBitrateBps()];
+
+  OSStatus status = VTCompressionSessionEncodeFrame(
+      _compressionSession, pixelBuffer, presentationTimeStamp, kCMTimeInvalid,
+      frameProperties, encodeParams.release(), nullptr);
+  if (frameProperties) {
+    CFRelease(frameProperties);
+  }
+  if (pixelBuffer) {
+    CVBufferRelease(pixelBuffer);
+  }
+  if (status != noErr) {
+    RTC_LOG(LS_ERROR) << "Failed to encode frame with code: " << status;
+    return WEBRTC_VIDEO_CODEC_ERROR;
+  }
+  return WEBRTC_VIDEO_CODEC_OK;
+}
+
+- (void)setCallback:(RTCVideoEncoderCallback)callback {
+  _callback = callback;
+}
+
+- (int)setBitrate:(uint32_t)bitrateKbit framerate:(uint32_t)framerate {
+  _targetBitrateBps = 1000 * bitrateKbit;
+  _bitrateAdjuster->SetTargetBitrateBps(_targetBitrateBps);
+  [self setBitrateBps:_bitrateAdjuster->GetAdjustedBitrateBps()];
+  return WEBRTC_VIDEO_CODEC_OK;
+}
+
+#pragma mark - Private
+
+- (NSInteger)releaseEncoder {
+  // Need to destroy so that the session is invalidated and won't use the
+  // callback anymore. Do not remove callback until the session is invalidated
+  // since async encoder callbacks can occur until invalidation.
+  [self destroyCompressionSession];
+  _callback = nullptr;
+  return WEBRTC_VIDEO_CODEC_OK;
+}
+
+- (int)resetCompressionSession {
+  [self destroyCompressionSession];
+
+  // Set source image buffer attributes. These attributes will be present on
+  // buffers retrieved from the encoder's pixel buffer pool.
+  const size_t attributesSize = 3;
+  CFTypeRef keys[attributesSize] = {
+#if defined(WEBRTC_IOS)
+    kCVPixelBufferOpenGLESCompatibilityKey,
+#elif defined(WEBRTC_MAC)
+    kCVPixelBufferOpenGLCompatibilityKey,
+#endif
+    kCVPixelBufferIOSurfacePropertiesKey,
+    kCVPixelBufferPixelFormatTypeKey
+  };
+  CFDictionaryRef ioSurfaceValue = CreateCFTypeDictionary(nullptr, nullptr, 0);
+  int64_t nv12type = kCVPixelFormatType_420YpCbCr8BiPlanarFullRange;
+  CFNumberRef pixelFormat =
+      CFNumberCreate(nullptr, kCFNumberLongType, &nv12type);
+  CFTypeRef values[attributesSize] = {kCFBooleanTrue, ioSurfaceValue,
+                                      pixelFormat};
+  CFDictionaryRef sourceAttributes =
+      CreateCFTypeDictionary(keys, values, attributesSize);
+  if (ioSurfaceValue) {
+    CFRelease(ioSurfaceValue);
+    ioSurfaceValue = nullptr;
+  }
+  if (pixelFormat) {
+    CFRelease(pixelFormat);
+    pixelFormat = nullptr;
+  }
+  CFMutableDictionaryRef encoder_specs = CFDictionaryCreateMutable(nullptr, 2, &kCFTypeDictionaryKeyCallBacks, &kCFTypeDictionaryValueCallBacks);
+#if defined(WEBRTC_MAC) && !defined(WEBRTC_IOS)
+  CFDictionarySetValue(encoder_specs, kVTVideoEncoderSpecification_EnableHardwareAcceleratedVideoEncoder, kCFBooleanTrue);
+#endif
+  OSStatus status = VTCompressionSessionCreate(
+      nullptr,  // use default allocator
+      _width, _height, kCMVideoCodecType_HEVC,
+      encoder_specs,  // use hardware accelerated encoder if available
+      sourceAttributes,
+      nullptr,  // use default compressed data allocator
+      compressionOutputCallback, nullptr, &_compressionSession);
+  if (sourceAttributes) {
+    CFRelease(sourceAttributes);
+    sourceAttributes = nullptr;
+  }
+  if (encoder_specs) {
+    CFRelease(encoder_specs);
+    encoder_specs = nullptr;
+  }
+  if (status != noErr) {
+    RTC_LOG(LS_ERROR) << "Failed to create compression session: " << status;
+    return WEBRTC_VIDEO_CODEC_ERROR;
+  }
+#if defined(WEBRTC_MAC) && !defined(WEBRTC_IOS)
+  CFBooleanRef hwaccl_enabled = nullptr;
+  status = VTSessionCopyProperty(
+      _compressionSession,
+      kVTCompressionPropertyKey_UsingHardwareAcceleratedVideoEncoder, nullptr,
+      &hwaccl_enabled);
+  if (status == noErr && (CFBooleanGetValue(hwaccl_enabled))) {
+    RTC_LOG(LS_INFO) << "Compression session created with hw accl enabled";
+  } else {
+    RTC_LOG(LS_INFO) << "Compression session created with hw accl disabled";
+  }
+#endif
+  [self configureCompressionSession];
+  return WEBRTC_VIDEO_CODEC_OK;
+}
+
+- (void)configureCompressionSession {
+  RTC_DCHECK(_compressionSession);
+  SetVTSessionProperty(_compressionSession, kVTCompressionPropertyKey_RealTime, false);
+  // (check:tnoho)
+  // SetVTSessionProperty(_compressionSession,
+  // kVTCompressionPropertyKey_ProfileLevel, _profile);
+  SetVTSessionProperty(_compressionSession, kVTCompressionPropertyKey_AllowFrameReordering, false);
+  [self setEncoderBitrateBps:_targetBitrateBps];
+
+  // Set a relatively large value for keyframe emission (7200 frames or 4 minutes).
+  SetVTSessionProperty(_compressionSession, kVTCompressionPropertyKey_MaxKeyFrameInterval, 7200);
+  SetVTSessionProperty(
+      _compressionSession, kVTCompressionPropertyKey_MaxKeyFrameIntervalDuration, 240);
+  OSStatus status =
+      VTCompressionSessionPrepareToEncodeFrames(_compressionSession);
+  if (status != noErr) {
+    RTC_LOG(LS_ERROR) << "Compression session failed to prepare encode frames.";
+  }
+}
+
+- (void)destroyCompressionSession {
+  if (_compressionSession) {
+    VTCompressionSessionInvalidate(_compressionSession);
+    CFRelease(_compressionSession);
+    _compressionSession = nullptr;
+  }
+}
+
+- (NSString*)implementationName {
+  return @"VideoToolbox";
+}
+
+- (void)setBitrateBps:(uint32_t)bitrateBps {
+  if (_encoderBitrateBps != bitrateBps) {
+    [self setEncoderBitrateBps:bitrateBps];
+  }
+}
+
+- (void)setEncoderBitrateBps:(uint32_t)bitrateBps {
+  if (_compressionSession) {
+    SetVTSessionProperty(_compressionSession, kVTCompressionPropertyKey_AverageBitRate, bitrateBps);
+
+    // TODO(tkchin): Add a helper method to set array value.
+    int64_t dataLimitBytesPerSecondValue =
+        static_cast<int64_t>(bitrateBps * kLimitToAverageBitRateFactor / 8);
+    CFNumberRef bytesPerSecond =
+        CFNumberCreate(kCFAllocatorDefault, kCFNumberSInt64Type,
+                       &dataLimitBytesPerSecondValue);
+    int64_t oneSecondValue = 1;
+    CFNumberRef oneSecond = CFNumberCreate(
+        kCFAllocatorDefault, kCFNumberSInt64Type, &oneSecondValue);
+    const void* nums[2] = {bytesPerSecond, oneSecond};
+    CFArrayRef dataRateLimits =
+        CFArrayCreate(nullptr, nums, 2, &kCFTypeArrayCallBacks);
+    OSStatus status = VTSessionSetProperty(
+        _compressionSession, kVTCompressionPropertyKey_DataRateLimits,
+        dataRateLimits);
+    if (bytesPerSecond) {
+      CFRelease(bytesPerSecond);
+    }
+    if (oneSecond) {
+      CFRelease(oneSecond);
+    }
+    if (dataRateLimits) {
+      CFRelease(dataRateLimits);
+    }
+    if (status != noErr) {
+      RTC_LOG(LS_ERROR) << "Failed to set data rate limit";
+    }
+
+    _encoderBitrateBps = bitrateBps;
+  }
+}
+
+- (void)frameWasEncoded:(OSStatus)status
+                  flags:(VTEncodeInfoFlags)infoFlags
+           sampleBuffer:(CMSampleBufferRef)sampleBuffer
+                  width:(int32_t)width
+                 height:(int32_t)height
+           renderTimeMs:(int64_t)renderTimeMs
+              timestamp:(uint32_t)timestamp
+               rotation:(RTCVideoRotation)rotation {
+  if (status != noErr) {
+    RTC_LOG(LS_ERROR) << "h265 encode failed.";
+    return;
+  }
+  if (infoFlags & kVTEncodeInfo_FrameDropped) {
+    RTC_LOG(LS_INFO) << "h265 encoder dropped a frame.";
+    return;
+  }
+
+  BOOL isKeyframe = NO;
+  CFArrayRef attachments =
+      CMSampleBufferGetSampleAttachmentsArray(sampleBuffer, 0);
+  if (attachments != nullptr && CFArrayGetCount(attachments)) {
+    CFDictionaryRef attachment =
+        static_cast<CFDictionaryRef>(CFArrayGetValueAtIndex(attachments, 0));
+    isKeyframe =
+        !CFDictionaryContainsKey(attachment, kCMSampleAttachmentKey_NotSync);
+  }
+
+  if (isKeyframe) {
+    RTC_LOG(LS_INFO) << "Generated keyframe";
+  }
+
+  // Convert the sample buffer into a buffer suitable for RTP packetization.
+  // TODO(tkchin): Allocate buffers through a pool.
+  std::unique_ptr<rtc::Buffer> buffer(new rtc::Buffer());
+  RTC_OBJC_TYPE(RTCRtpFragmentationHeader) * header;
+  {
+    std::unique_ptr<webrtc::RTPFragmentationHeader> header_cpp;
+    bool result = H265CMSampleBufferToAnnexBBuffer(sampleBuffer, isKeyframe,
+                                                   buffer.get(), &header_cpp);
+    header = [[RTC_OBJC_TYPE(RTCRtpFragmentationHeader) alloc]
+        initWithNativeFragmentationHeader:header_cpp.get()];
+    if (!result) {
+      RTC_LOG(LS_ERROR) << "Failed to convert sample buffer.";
+      return;
+    }
+  }
+
+  RTC_OBJC_TYPE(RTCEncodedImage)* frame = [[RTC_OBJC_TYPE(RTCEncodedImage) alloc] init];
+  frame.buffer = [NSData dataWithBytesNoCopy:buffer->data()
+                                      length:buffer->size()
+                                freeWhenDone:NO];
+  frame.encodedWidth = width;
+  frame.encodedHeight = height;
+  frame.completeFrame = YES;
+  frame.frameType =
+      isKeyframe ? RTCFrameTypeVideoFrameKey : RTCFrameTypeVideoFrameDelta;
+  frame.captureTimeMs = renderTimeMs;
+  frame.timeStamp = timestamp;
+  frame.rotation = rotation;
+  frame.contentType = (_mode == RTCVideoCodecModeScreensharing)
+                          ? RTCVideoContentTypeScreenshare
+                          : RTCVideoContentTypeUnspecified;
+  frame.flags = webrtc::VideoSendTiming::kInvalid;
+
+  // FIXME: QP is ignored because there is no H.265 bitstream parser.
+
+  BOOL res = _callback(frame, [[RTC_OBJC_TYPE(RTCCodecSpecificInfoH265) alloc] init], header);
+  if (!res) {
+    RTC_LOG(LS_ERROR) << "Encode callback failed.";
+    return;
+  }
+  _bitrateAdjuster->Update(frame.buffer.length);
+}
+
+- (nullable RTC_OBJC_TYPE(RTCVideoEncoderQpThresholds) *)scalingSettings {
+  return [[RTC_OBJC_TYPE(RTCVideoEncoderQpThresholds) alloc]
+      initWithThresholdsLow:kLowh265QpThreshold
+                       high:kHighh265QpThreshold];
+}
+
+@end
\ No newline at end of file
diff --git a/sdk/objc/components/video_codec/nalu_rewriter.cc b/sdk/objc/components/video_codec/nalu_rewriter.cc
index dc258d6064..2621689bc7 100644
--- a/sdk/objc/components/video_codec/nalu_rewriter.cc
+++ b/sdk/objc/components/video_codec/nalu_rewriter.cc
@@ -248,6 +248,227 @@ bool H264AnnexBBufferToCMSampleBuffer(const uint8_t* annexb_buffer,
   return true;
 }
 
+bool H265CMSampleBufferToAnnexBBuffer(
+    CMSampleBufferRef hvcc_sample_buffer,
+    bool is_keyframe,
+    rtc::Buffer* annexb_buffer,
+    std::unique_ptr<RTPFragmentationHeader> *out_header) {
+  RTC_DCHECK(hvcc_sample_buffer);
+  RTC_DCHECK(out_header);
+  out_header->reset(nullptr);
+
+  // Get format description from the sample buffer.
+  CMVideoFormatDescriptionRef description =
+      CMSampleBufferGetFormatDescription(hvcc_sample_buffer);
+  if (description == nullptr) {
+    RTC_LOG(LS_ERROR) << "Failed to get sample buffer's description.";
+    return false;
+  }
+
+  // Get parameter set information.
+  int nalu_header_size = 0;
+  size_t param_set_count = 0;
+  OSStatus status = CMVideoFormatDescriptionGetHEVCParameterSetAtIndex(
+      description, 0, nullptr, nullptr, &param_set_count, &nalu_header_size);
+  if (status != noErr) {
+    RTC_LOG(LS_ERROR) << "Failed to get parameter set.";
+    return false;
+  }
+  RTC_CHECK_EQ(nalu_header_size, kAvccHeaderByteSize);
+  RTC_DCHECK_EQ(param_set_count, 3);
+
+  // Truncate any previous data in the buffer without changing its capacity.
+  annexb_buffer->SetSize(0);
+
+  size_t nalu_offset = 0;
+  std::vector<size_t> frag_offsets;
+  std::vector<size_t> frag_lengths;
+
+  // Place all parameter sets at the front of buffer.
+  if (is_keyframe) {
+    size_t param_set_size = 0;
+    const uint8_t* param_set = nullptr;
+    for (size_t i = 0; i < param_set_count; ++i) {
+      status = CMVideoFormatDescriptionGetHEVCParameterSetAtIndex(
+          description, i, &param_set, &param_set_size, nullptr, nullptr);
+      if (status != noErr) {
+        RTC_LOG(LS_ERROR) << "Failed to get parameter set.";
+        return false;
+      }
+      // Update buffer.
+      annexb_buffer->AppendData(kAnnexBHeaderBytes, sizeof(kAnnexBHeaderBytes));
+      annexb_buffer->AppendData(reinterpret_cast<const char*>(param_set),
+                                param_set_size);
+      // Update fragmentation.
+      frag_offsets.push_back(nalu_offset + sizeof(kAnnexBHeaderBytes));
+      frag_lengths.push_back(param_set_size);
+      nalu_offset += sizeof(kAnnexBHeaderBytes) + param_set_size;
+    }
+  }
+
+  // Get block buffer from the sample buffer.
+  CMBlockBufferRef block_buffer =
+      CMSampleBufferGetDataBuffer(hvcc_sample_buffer);
+  if (block_buffer == nullptr) {
+    RTC_LOG(LS_ERROR) << "Failed to get sample buffer's block buffer.";
+    return false;
+  }
+  CMBlockBufferRef contiguous_buffer = nullptr;
+  // Make sure block buffer is contiguous.
+  if (!CMBlockBufferIsRangeContiguous(block_buffer, 0, 0)) {
+    status = CMBlockBufferCreateContiguous(
+        nullptr, block_buffer, nullptr, nullptr, 0, 0, 0, &contiguous_buffer);
+    if (status != noErr) {
+      RTC_LOG(LS_ERROR) << "Failed to flatten non-contiguous block buffer: "
+                        << status;
+      return false;
+    }
+  } else {
+    contiguous_buffer = block_buffer;
+    // Retain to make cleanup easier.
+    CFRetain(contiguous_buffer);
+    block_buffer = nullptr;
+  }
+
+  // Now copy the actual data.
+  char* data_ptr = nullptr;
+  size_t block_buffer_size = CMBlockBufferGetDataLength(contiguous_buffer);
+  status = CMBlockBufferGetDataPointer(contiguous_buffer, 0, nullptr, nullptr,
+                                       &data_ptr);
+  if (status != noErr) {
+    RTC_LOG(LS_ERROR) << "Failed to get block buffer data.";
+    CFRelease(contiguous_buffer);
+    return false;
+  }
+  size_t bytes_remaining = block_buffer_size;
+  while (bytes_remaining > 0) {
+    // The size type here must match |nalu_header_size|, we expect 4 bytes.
+    // Read the length of the next packet of data. Must convert from big endian
+    // to host endian.
+    RTC_DCHECK_GE(bytes_remaining, (size_t)nalu_header_size);
+    uint32_t* uint32_data_ptr = reinterpret_cast<uint32_t*>(data_ptr);
+    uint32_t packet_size = CFSwapInt32BigToHost(*uint32_data_ptr);
+    // Update buffer.
+    annexb_buffer->AppendData(kAnnexBHeaderBytes, sizeof(kAnnexBHeaderBytes));
+    annexb_buffer->AppendData(data_ptr + nalu_header_size, packet_size);
+    // Update fragmentation.
+    frag_offsets.push_back(nalu_offset + sizeof(kAnnexBHeaderBytes));
+    frag_lengths.push_back(packet_size);
+    nalu_offset += sizeof(kAnnexBHeaderBytes) + packet_size;
+
+    size_t bytes_written = packet_size + sizeof(kAnnexBHeaderBytes);
+    bytes_remaining -= bytes_written;
+    data_ptr += bytes_written;
+  }
+  RTC_DCHECK_EQ(bytes_remaining, (size_t)0);
+
+  std::unique_ptr<RTPFragmentationHeader> header(new RTPFragmentationHeader());
+  header->VerifyAndAllocateFragmentationHeader(frag_offsets.size());
+  RTC_DCHECK_EQ(frag_lengths.size(), frag_offsets.size());
+  for (size_t i = 0; i < frag_offsets.size(); ++i) {
+    header->fragmentationOffset[i] = frag_offsets[i];
+    header->fragmentationLength[i] = frag_lengths[i];
+  }
+  *out_header = std::move(header);
+  CFRelease(contiguous_buffer);
+  return true;
+}
+
+bool H265AnnexBBufferToCMSampleBuffer(const uint8_t* annexb_buffer,
+                                      size_t annexb_buffer_size,
+                                      CMVideoFormatDescriptionRef video_format,
+                                      CMSampleBufferRef* out_sample_buffer) {
+  RTC_DCHECK(annexb_buffer);
+  RTC_DCHECK(out_sample_buffer);
+  RTC_DCHECK(video_format);
+  *out_sample_buffer = nullptr;
+
+  AnnexBBufferReader reader(annexb_buffer, annexb_buffer_size);
+  if (reader.SeekToNextNaluOfType(H265::kVps)) {
+    // Buffer contains an SPS NALU - skip it and the following PPS
+    const uint8_t* data;
+    size_t data_len;
+    if (!reader.ReadNalu(&data, &data_len)) {
+      RTC_LOG(LS_ERROR) << "Failed to read VPS";
+      return false;
+    }
+    if (!reader.ReadNalu(&data, &data_len)) {
+      RTC_LOG(LS_ERROR) << "Failed to read SPS";
+      return false;
+    }
+    if (!reader.ReadNalu(&data, &data_len)) {
+      RTC_LOG(LS_ERROR) << "Failed to read PPS";
+      return false;
+    }
+  } else {
+    // No SPS NALU - start reading from the first NALU in the buffer
+    reader.SeekToStart();
+  }
+
+  // Allocate memory as a block buffer.
+  // TODO(tkchin): figure out how to use a pool.
+  CMBlockBufferRef block_buffer = nullptr;
+  OSStatus status = CMBlockBufferCreateWithMemoryBlock(
+      nullptr, nullptr, reader.BytesRemaining(), nullptr, nullptr, 0,
+      reader.BytesRemaining(), kCMBlockBufferAssureMemoryNowFlag,
+      &block_buffer);
+  if (status != kCMBlockBufferNoErr) {
+    RTC_LOG(LS_ERROR) << "Failed to create block buffer.";
+    return false;
+  }
+
+  // Make sure block buffer is contiguous.
+  CMBlockBufferRef contiguous_buffer = nullptr;
+  if (!CMBlockBufferIsRangeContiguous(block_buffer, 0, 0)) {
+    status = CMBlockBufferCreateContiguous(
+        nullptr, block_buffer, nullptr, nullptr, 0, 0, 0, &contiguous_buffer);
+    if (status != noErr) {
+      RTC_LOG(LS_ERROR) << "Failed to flatten non-contiguous block buffer: "
+                        << status;
+      CFRelease(block_buffer);
+      return false;
+    }
+  } else {
+    contiguous_buffer = block_buffer;
+    block_buffer = nullptr;
+  }
+
+  // Get a raw pointer into allocated memory.
+  size_t block_buffer_size = 0;
+  char* data_ptr = nullptr;
+  status = CMBlockBufferGetDataPointer(contiguous_buffer, 0, nullptr,
+                                       &block_buffer_size, &data_ptr);
+  if (status != kCMBlockBufferNoErr) {
+    RTC_LOG(LS_ERROR) << "Failed to get block buffer data pointer.";
+    CFRelease(contiguous_buffer);
+    return false;
+  }
+  RTC_DCHECK(block_buffer_size == reader.BytesRemaining());
+
+  // Write Avcc NALUs into block buffer memory.
+  AvccBufferWriter writer(reinterpret_cast<uint8_t*>(data_ptr),
+                          block_buffer_size);
+  while (reader.BytesRemaining() > 0) {
+    const uint8_t* nalu_data_ptr = nullptr;
+    size_t nalu_data_size = 0;
+    if (reader.ReadNalu(&nalu_data_ptr, &nalu_data_size)) {
+      writer.WriteNalu(nalu_data_ptr, nalu_data_size);
+    }
+  }
+
+  // Create sample buffer.
+  status = CMSampleBufferCreate(nullptr, contiguous_buffer, true, nullptr,
+                                nullptr, video_format, 1, 0, nullptr, 0,
+                                nullptr, out_sample_buffer);
+  if (status != noErr) {
+    RTC_LOG(LS_ERROR) << "Failed to create sample buffer.";
+    CFRelease(contiguous_buffer);
+    return false;
+  }
+  CFRelease(contiguous_buffer);
+  return true;
+}
+
 CMVideoFormatDescriptionRef CreateVideoFormatDescription(
     const uint8_t* annexb_buffer,
     size_t annexb_buffer_size) {
@@ -278,6 +499,41 @@ CMVideoFormatDescriptionRef CreateVideoFormatDescription(
   return description;
 }
 
+CMVideoFormatDescriptionRef CreateH265VideoFormatDescription(
+    const uint8_t* annexb_buffer,
+    size_t annexb_buffer_size) {
+  const uint8_t* param_set_ptrs[3] = {};
+  size_t param_set_sizes[3] = {};
+  AnnexBBufferReader reader(annexb_buffer, annexb_buffer_size);
+  // Skip everyting before the VPS, then read the VPS, SPS and PPS
+  if (!reader.SeekToNextNaluOfType(H265::kVps)) {
+    return nullptr;
+  }
+  if (!reader.ReadNalu(&param_set_ptrs[0], &param_set_sizes[0])) {
+    RTC_LOG(LS_ERROR) << "Failed to read VPS";
+    return nullptr;
+  }
+  if (!reader.ReadNalu(&param_set_ptrs[1], &param_set_sizes[1])) {
+    RTC_LOG(LS_ERROR) << "Failed to read SPS";
+    return nullptr;
+  }
+  if (!reader.ReadNalu(&param_set_ptrs[2], &param_set_sizes[2])) {
+    RTC_LOG(LS_ERROR) << "Failed to read PPS";
+    return nullptr;
+  }
+
+  // Parse the SPS and PPS into a CMVideoFormatDescription.
+  CMVideoFormatDescriptionRef description = nullptr;
+  OSStatus status = CMVideoFormatDescriptionCreateFromHEVCParameterSets(
+      kCFAllocatorDefault, 3, param_set_ptrs, param_set_sizes, 4, nullptr,
+      &description);
+  if (status != noErr) {
+    RTC_LOG(LS_ERROR) << "Failed to create video format description.";
+    return nullptr;
+  }
+  return description;
+}
+
 AnnexBBufferReader::AnnexBBufferReader(const uint8_t* annexb_buffer,
                                        size_t length)
     : start_(annexb_buffer), length_(length) {
@@ -324,6 +580,17 @@ bool AnnexBBufferReader::SeekToNextNaluOfType(NaluType type) {
   }
   return false;
 }
+
+bool AnnexBBufferReader::SeekToNextNaluOfType(H265::NaluType type) {
+  for (; offset_ != offsets_.end(); ++offset_) {
+    if (offset_->payload_size < 1)
+      continue;
+    if (H265::ParseNaluType(*(start_ + offset_->payload_start_offset)) == type)
+      return true;
+  }
+  return false;
+}
+
 AvccBufferWriter::AvccBufferWriter(uint8_t* const avcc_buffer, size_t length)
     : start_(avcc_buffer), offset_(0), length_(length) {
   RTC_DCHECK(avcc_buffer);
diff --git a/sdk/objc/components/video_codec/nalu_rewriter.h b/sdk/objc/components/video_codec/nalu_rewriter.h
index a0c1aa90af..657a0f0988 100644
--- a/sdk/objc/components/video_codec/nalu_rewriter.h
+++ b/sdk/objc/components/video_codec/nalu_rewriter.h
@@ -18,6 +18,7 @@
 #include <vector>
 
 #include "common_video/h264/h264_common.h"
+#include "common_video/h265/h265_common.h"
 #include "modules/include/module_common_types.h"
 #include "rtc_base/buffer.h"
 
@@ -47,6 +48,28 @@ bool H264AnnexBBufferToCMSampleBuffer(const uint8_t* annexb_buffer,
                                       CMSampleBufferRef* out_sample_buffer,
                                       CMMemoryPoolRef memory_pool);
 
+// Converts a sample buffer emitted from the VideoToolbox encoder into a buffer
+// suitable for RTP. The sample buffer is in hvcc format whereas the rtp buffer
+// needs to be in Annex B format. Data is written directly to |annexb_buffer|
+// and a new RTPFragmentationHeader is returned in |out_header|.
+bool H265CMSampleBufferToAnnexBBuffer(
+    CMSampleBufferRef hvcc_sample_buffer,
+    bool is_keyframe,
+    rtc::Buffer* annexb_buffer,
+    std::unique_ptr<RTPFragmentationHeader> *out_header)
+    __OSX_AVAILABLE_STARTING(__MAC_10_12, __IPHONE_11_0);
+ 
+// Converts a buffer received from RTP into a sample buffer suitable for the
+// VideoToolbox decoder. The RTP buffer is in annex b format whereas the sample
+// buffer is in hvcc format.
+// If |is_keyframe| is true then |video_format| is ignored since the format will
+// be read from the buffer. Otherwise |video_format| must be provided.
+// Caller is responsible for releasing the created sample buffer.
+bool H265AnnexBBufferToCMSampleBuffer(const uint8_t* annexb_buffer,
+                                      size_t annexb_buffer_size,
+                                      CMVideoFormatDescriptionRef video_format,
+                                      CMSampleBufferRef* out_sample_buffer);
+
 // Returns a video format description created from the sps/pps information in
 // the Annex B buffer. If there is no such information, nullptr is returned.
 // The caller is responsible for releasing the description.
@@ -54,6 +77,10 @@ CMVideoFormatDescriptionRef CreateVideoFormatDescription(
     const uint8_t* annexb_buffer,
     size_t annexb_buffer_size);
 
+CMVideoFormatDescriptionRef CreateH265VideoFormatDescription(
+    const uint8_t* annexb_buffer,
+    size_t annexb_buffer_size);
+
 // Helper class for reading NALUs from an RTP Annex B buffer.
 class AnnexBBufferReader final {
  public:
@@ -79,6 +106,8 @@ class AnnexBBufferReader final {
   // reached the end instead
   bool SeekToNextNaluOfType(H264::NaluType type);
 
+  bool SeekToNextNaluOfType(H265::NaluType type);
+
  private:
   // Returns the the next offset that contains NALU data.
   size_t FindNextNaluHeader(const uint8_t* start,
diff --git a/sdk/objc/native/src/objc_video_encoder_factory.mm b/sdk/objc/native/src/objc_video_encoder_factory.mm
index b54945f49e..30ce22f163 100644
--- a/sdk/objc/native/src/objc_video_encoder_factory.mm
+++ b/sdk/objc/native/src/objc_video_encoder_factory.mm
@@ -16,6 +16,7 @@
 #import "base/RTCVideoEncoder.h"
 #import "base/RTCVideoEncoderFactory.h"
 #import "components/video_codec/RTCCodecSpecificInfoH264+Private.h"
+#import "components/video_codec/RTCCodecSpecificInfoH265+Private.h"
 #import "sdk/objc/api/peerconnection/RTCEncodedImage+Private.h"
 #import "sdk/objc/api/peerconnection/RTCRtpFragmentationHeader+Private.h"
 #import "sdk/objc/api/peerconnection/RTCVideoCodecInfo+Private.h"
@@ -60,6 +61,9 @@ int32_t RegisterEncodeCompleteCallback(EncodedImageCallback *callback) override
       if ([info isKindOfClass:[RTC_OBJC_TYPE(RTCCodecSpecificInfoH264) class]]) {
         codecSpecificInfo =
             [(RTC_OBJC_TYPE(RTCCodecSpecificInfoH264) *)info nativeCodecSpecificInfo];
+      } else if ([info isKindOfClass:[RTC_OBJC_TYPE(RTCCodecSpecificInfoH265) class]]) {
+        codecSpecificInfo =
+            [(RTC_OBJC_TYPE(RTCCodecSpecificInfoH265) *)info nativeCodecSpecificInfo];
       }
 
       std::unique_ptr<RTPFragmentationHeader> fragmentationHeader =
diff --git a/video/rtp_video_stream_receiver.cc b/video/rtp_video_stream_receiver.cc
index 8bbb5866a0..ab07669bf6 100644
--- a/video/rtp_video_stream_receiver.cc
+++ b/video/rtp_video_stream_receiver.cc
@@ -623,7 +623,22 @@ void RtpVideoStreamReceiver::OnReceivedPayloadData(
         packet->video_payload = std::move(fixed.bitstream);
         break;
     }
-
+  } else if (packet->codec() == kVideoCodecH265) {
+    video_coding::H265VpsSpsPpsTracker::FixedBitstream fixed =
+        h265_tracker_.CopyAndFixBitstream(
+            rtc::MakeArrayView(codec_payload.cdata(), codec_payload.size()),
+            &packet->video_header);
+    switch (fixed.action) {
+      case video_coding::H265VpsSpsPpsTracker::kRequestKeyframe:
+        rtcp_feedback_buffer_.RequestKeyFrame();
+        rtcp_feedback_buffer_.SendBufferedRtcpFeedback();
+        ABSL_FALLTHROUGH_INTENDED;
+      case video_coding::H265VpsSpsPpsTracker::kDrop:
+        return;
+      case video_coding::H265VpsSpsPpsTracker::kInsert:
+        packet->video_payload = std::move(fixed.bitstream);
+        break;
+    }
   } else {
     packet->video_payload = std::move(codec_payload);
   }
diff --git a/video/rtp_video_stream_receiver.h b/video/rtp_video_stream_receiver.h
index 68e23eee53..1eb877a815 100644
--- a/video/rtp_video_stream_receiver.h
+++ b/video/rtp_video_stream_receiver.h
@@ -37,6 +37,7 @@
 #include "modules/rtp_rtcp/source/rtp_video_header.h"
 #include "modules/rtp_rtcp/source/video_rtp_depacketizer.h"
 #include "modules/video_coding/h264_sps_pps_tracker.h"
+#include "modules/video_coding/h265_vps_sps_pps_tracker.h"
 #include "modules/video_coding/loss_notification_controller.h"
 #include "modules/video_coding/packet_buffer.h"
 #include "modules/video_coding/rtp_frame_reference_finder.h"
@@ -361,6 +362,7 @@ class RtpVideoStreamReceiver : public LossNotificationSender,
   std::map<int64_t, uint16_t> last_seq_num_for_pic_id_
       RTC_GUARDED_BY(last_seq_num_cs_);
   video_coding::H264SpsPpsTracker tracker_;
+  video_coding::H265VpsSpsPpsTracker h265_tracker_;
 
   // Maps payload id to the depacketizer.
   std::map<uint8_t, std::unique_ptr<VideoRtpDepacketizer>> payload_type_map_;
diff --git a/video/send_statistics_proxy.cc b/video/send_statistics_proxy.cc
index b5bcbe6bf1..4d9eb130b6 100644
--- a/video/send_statistics_proxy.cc
+++ b/video/send_statistics_proxy.cc
@@ -47,6 +47,7 @@ enum HistogramCodecType {
   kVideoVp8 = 1,
   kVideoVp9 = 2,
   kVideoH264 = 3,
+  kVideoH265 = 4,
   kVideoMax = 64,
 };
 
@@ -74,6 +75,8 @@ HistogramCodecType PayloadNameToHistogramCodecType(
       return kVideoVp9;
     case kVideoCodecH264:
       return kVideoH264;
+    case kVideoCodecH265:
+      return kVideoH265;
     default:
       return kVideoUnknown;
   }
diff --git a/video/video_receive_stream.cc b/video/video_receive_stream.cc
index f1b3fc7b5b..56c0b6de5e 100644
--- a/video/video_receive_stream.cc
+++ b/video/video_receive_stream.cc
@@ -126,6 +126,8 @@ VideoCodec CreateDecoderVideoCodec(const VideoReceiveStream::Decoder& decoder) {
     *(codec.VP9()) = VideoEncoder::GetDefaultVp9Settings();
   } else if (codec.codecType == kVideoCodecH264) {
     *(codec.H264()) = VideoEncoder::GetDefaultH264Settings();
+  } else if (codec.codecType == kVideoCodecH265) {
+    *(codec.H265()) = VideoEncoder::GetDefaultH265Settings();
   } else if (codec.codecType == kVideoCodecMultiplex) {
     VideoReceiveStream::Decoder associated_decoder = decoder;
     associated_decoder.video_format =
diff --git a/video/video_stream_encoder.cc b/video/video_stream_encoder.cc
index 0ed73a3e63..4f0d60ceb8 100644
--- a/video/video_stream_encoder.cc
+++ b/video/video_stream_encoder.cc
@@ -103,6 +103,12 @@ bool RequiresEncoderReset(const VideoCodec& prev_send_codec,
       }
       break;
 
+    case kVideoCodecH265:
+      if (new_send_codec.H265() != prev_send_codec.H265()) {
+        return true;
+      }
+      break;
+
     default:
       break;
   }
@@ -1553,6 +1559,7 @@ EncodedImageCallback::Result VideoStreamEncoder::OnEncodedImage(
   if (codec_specific_info &&
       (codec_specific_info->codecType == kVideoCodecVP8 ||
        codec_specific_info->codecType == kVideoCodecH264 ||
+       codec_specific_info->codecType == kVideoCodecH265 ||
        codec_specific_info->codecType == kVideoCodecGeneric)) {
     simulcast_id = encoded_image.SpatialIndex().value_or(0);
   }
